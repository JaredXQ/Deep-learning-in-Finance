{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "430_group project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "fR5Dd7ZEYLCj"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from sklearn import preprocessing\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import keras\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "id": "b8BWL0X4YLCo"
      },
      "source": [
        "**Read data and transform them to pandas dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "98463e30-4c1b-4c31-a220-06031791fb9f",
        "_uuid": "8f87962ce6f722f6bf59efc882d3a55e42be3223",
        "id": "qRndQ8nmYLCo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1d767caf-5f6b-45b1-f784-7b35241801ee"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ashishpatel26/NYSE-STOCK_MARKET-ANALYSIS-USING-LSTM/master/nyse/prices-split-adjusted.csv\", index_col = 0)\n",
        "df[\"adj close\"] = df.close # Moving close to the last column\n",
        "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "      <th>adj close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-05</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "      <td>125.839996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-06</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "      <td>119.980003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-07</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "      <td>114.949997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-08</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "      <td>116.620003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-11</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "      <td>114.970001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           symbol        open         low        high     volume   adj close\n",
              "date                                                                        \n",
              "2016-01-05   WLTW  123.430000  122.309998  126.250000  2163600.0  125.839996\n",
              "2016-01-06   WLTW  125.239998  119.940002  125.540001  2386400.0  119.980003\n",
              "2016-01-07   WLTW  116.379997  114.930000  119.739998  2489500.0  114.949997\n",
              "2016-01-08   WLTW  115.480003  113.500000  117.440002  2006300.0  116.620003\n",
              "2016-01-11   WLTW  117.010002  114.089996  117.330002  1408600.0  114.970001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b7d93887-d02c-40f6-b44b-ab51ee464351",
        "_uuid": "d5ac916f35cedc1cb6d8285d84a4ad2b738b8290",
        "id": "hArcFLhgYLCs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f46a5603-fcaf-4e96-af89-1c3dfff0cb1c"
      },
      "source": [
        "df2 = pd.read_csv(\"https://raw.githubusercontent.com/ashishpatel26/NYSE-STOCK_MARKET-ANALYSIS-USING-LSTM/master/nyse/fundamentals.csv\")\n",
        "df2.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Ticker Symbol</th>\n",
              "      <th>Period Ending</th>\n",
              "      <th>Accounts Payable</th>\n",
              "      <th>Accounts Receivable</th>\n",
              "      <th>Add'l income/expense items</th>\n",
              "      <th>After Tax ROE</th>\n",
              "      <th>Capital Expenditures</th>\n",
              "      <th>Capital Surplus</th>\n",
              "      <th>Cash Ratio</th>\n",
              "      <th>Cash and Cash Equivalents</th>\n",
              "      <th>Changes in Inventories</th>\n",
              "      <th>Common Stocks</th>\n",
              "      <th>Cost of Revenue</th>\n",
              "      <th>Current Ratio</th>\n",
              "      <th>Deferred Asset Charges</th>\n",
              "      <th>Deferred Liability Charges</th>\n",
              "      <th>Depreciation</th>\n",
              "      <th>Earnings Before Interest and Tax</th>\n",
              "      <th>Earnings Before Tax</th>\n",
              "      <th>Effect of Exchange Rate</th>\n",
              "      <th>Equity Earnings/Loss Unconsolidated Subsidiary</th>\n",
              "      <th>Fixed Assets</th>\n",
              "      <th>Goodwill</th>\n",
              "      <th>Gross Margin</th>\n",
              "      <th>Gross Profit</th>\n",
              "      <th>Income Tax</th>\n",
              "      <th>Intangible Assets</th>\n",
              "      <th>Interest Expense</th>\n",
              "      <th>Inventory</th>\n",
              "      <th>Investments</th>\n",
              "      <th>Liabilities</th>\n",
              "      <th>Long-Term Debt</th>\n",
              "      <th>Long-Term Investments</th>\n",
              "      <th>Minority Interest</th>\n",
              "      <th>Misc. Stocks</th>\n",
              "      <th>Net Borrowings</th>\n",
              "      <th>Net Cash Flow</th>\n",
              "      <th>Net Cash Flow-Operating</th>\n",
              "      <th>Net Cash Flows-Financing</th>\n",
              "      <th>Net Cash Flows-Investing</th>\n",
              "      <th>Net Income</th>\n",
              "      <th>Net Income Adjustments</th>\n",
              "      <th>Net Income Applicable to Common Shareholders</th>\n",
              "      <th>Net Income-Cont. Operations</th>\n",
              "      <th>Net Receivables</th>\n",
              "      <th>Non-Recurring Items</th>\n",
              "      <th>Operating Income</th>\n",
              "      <th>Operating Margin</th>\n",
              "      <th>Other Assets</th>\n",
              "      <th>Other Current Assets</th>\n",
              "      <th>Other Current Liabilities</th>\n",
              "      <th>Other Equity</th>\n",
              "      <th>Other Financing Activities</th>\n",
              "      <th>Other Investing Activities</th>\n",
              "      <th>Other Liabilities</th>\n",
              "      <th>Other Operating Activities</th>\n",
              "      <th>Other Operating Items</th>\n",
              "      <th>Pre-Tax Margin</th>\n",
              "      <th>Pre-Tax ROE</th>\n",
              "      <th>Profit Margin</th>\n",
              "      <th>Quick Ratio</th>\n",
              "      <th>Research and Development</th>\n",
              "      <th>Retained Earnings</th>\n",
              "      <th>Sale and Purchase of Stock</th>\n",
              "      <th>Sales, General and Admin.</th>\n",
              "      <th>Short-Term Debt / Current Portion of Long-Term Debt</th>\n",
              "      <th>Short-Term Investments</th>\n",
              "      <th>Total Assets</th>\n",
              "      <th>Total Current Assets</th>\n",
              "      <th>Total Current Liabilities</th>\n",
              "      <th>Total Equity</th>\n",
              "      <th>Total Liabilities</th>\n",
              "      <th>Total Liabilities &amp; Equity</th>\n",
              "      <th>Total Revenue</th>\n",
              "      <th>Treasury Stock</th>\n",
              "      <th>For Year</th>\n",
              "      <th>Earnings Per Share</th>\n",
              "      <th>Estimated Shares Outstanding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AAL</td>\n",
              "      <td>2012-12-31</td>\n",
              "      <td>3.068000e+09</td>\n",
              "      <td>-222000000.0</td>\n",
              "      <td>-1.961000e+09</td>\n",
              "      <td>23.0</td>\n",
              "      <td>-1.888000e+09</td>\n",
              "      <td>4.695000e+09</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1.330000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127000000.0</td>\n",
              "      <td>1.049900e+10</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>223000000.0</td>\n",
              "      <td>1.001000e+09</td>\n",
              "      <td>-1.813000e+09</td>\n",
              "      <td>-2.445000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.340200e+10</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>58.0</td>\n",
              "      <td>1.435600e+10</td>\n",
              "      <td>-5.690000e+08</td>\n",
              "      <td>8.690000e+08</td>\n",
              "      <td>632000000.0</td>\n",
              "      <td>5.800000e+08</td>\n",
              "      <td>3.060000e+08</td>\n",
              "      <td>4.730000e+08</td>\n",
              "      <td>7.116000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.020000e+09</td>\n",
              "      <td>197000000.0</td>\n",
              "      <td>1.285000e+09</td>\n",
              "      <td>4.830000e+08</td>\n",
              "      <td>-1.571000e+09</td>\n",
              "      <td>-1.876000e+09</td>\n",
              "      <td>2.050000e+09</td>\n",
              "      <td>-1.876000e+09</td>\n",
              "      <td>-4.084000e+09</td>\n",
              "      <td>1.124000e+09</td>\n",
              "      <td>3.860000e+08</td>\n",
              "      <td>1.480000e+08</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.167000e+09</td>\n",
              "      <td>6.260000e+08</td>\n",
              "      <td>4.524000e+09</td>\n",
              "      <td>-2.980000e+09</td>\n",
              "      <td>1.509000e+09</td>\n",
              "      <td>11000000.0</td>\n",
              "      <td>1.514700e+10</td>\n",
              "      <td>-141000000.0</td>\n",
              "      <td>8.450000e+08</td>\n",
              "      <td>10.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-9.462000e+09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.297700e+10</td>\n",
              "      <td>1.419000e+09</td>\n",
              "      <td>3.412000e+09</td>\n",
              "      <td>2.351000e+10</td>\n",
              "      <td>7.072000e+09</td>\n",
              "      <td>9.011000e+09</td>\n",
              "      <td>-7.987000e+09</td>\n",
              "      <td>2.489100e+10</td>\n",
              "      <td>1.690400e+10</td>\n",
              "      <td>2.485500e+10</td>\n",
              "      <td>-367000000.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>-5.60</td>\n",
              "      <td>3.350000e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AAL</td>\n",
              "      <td>2013-12-31</td>\n",
              "      <td>4.975000e+09</td>\n",
              "      <td>-93000000.0</td>\n",
              "      <td>-2.723000e+09</td>\n",
              "      <td>67.0</td>\n",
              "      <td>-3.114000e+09</td>\n",
              "      <td>1.059200e+10</td>\n",
              "      <td>75.0</td>\n",
              "      <td>2.175000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5000000.0</td>\n",
              "      <td>1.101900e+10</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>935000000.0</td>\n",
              "      <td>1.020000e+09</td>\n",
              "      <td>-1.324000e+09</td>\n",
              "      <td>-2.180000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.925900e+10</td>\n",
              "      <td>4.086000e+09</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1.572400e+10</td>\n",
              "      <td>-3.460000e+08</td>\n",
              "      <td>2.311000e+09</td>\n",
              "      <td>856000000.0</td>\n",
              "      <td>1.012000e+09</td>\n",
              "      <td>-1.181000e+09</td>\n",
              "      <td>-2.350000e+08</td>\n",
              "      <td>1.535300e+10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.208000e+09</td>\n",
              "      <td>660000000.0</td>\n",
              "      <td>6.750000e+08</td>\n",
              "      <td>3.799000e+09</td>\n",
              "      <td>-3.814000e+09</td>\n",
              "      <td>-1.834000e+09</td>\n",
              "      <td>1.873000e+09</td>\n",
              "      <td>-1.834000e+09</td>\n",
              "      <td>-4.489000e+09</td>\n",
              "      <td>1.560000e+09</td>\n",
              "      <td>5.590000e+08</td>\n",
              "      <td>1.399000e+09</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.299000e+09</td>\n",
              "      <td>1.465000e+09</td>\n",
              "      <td>7.385000e+09</td>\n",
              "      <td>-2.032000e+09</td>\n",
              "      <td>1.711000e+09</td>\n",
              "      <td>481000000.0</td>\n",
              "      <td>1.491500e+10</td>\n",
              "      <td>-56000000.0</td>\n",
              "      <td>8.530000e+08</td>\n",
              "      <td>8.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.129600e+10</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.291300e+10</td>\n",
              "      <td>1.446000e+09</td>\n",
              "      <td>8.111000e+09</td>\n",
              "      <td>4.227800e+10</td>\n",
              "      <td>1.432300e+10</td>\n",
              "      <td>1.380600e+10</td>\n",
              "      <td>-2.731000e+09</td>\n",
              "      <td>4.500900e+10</td>\n",
              "      <td>4.227800e+10</td>\n",
              "      <td>2.674300e+10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>-11.25</td>\n",
              "      <td>1.630222e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AAL</td>\n",
              "      <td>2014-12-31</td>\n",
              "      <td>4.668000e+09</td>\n",
              "      <td>-160000000.0</td>\n",
              "      <td>-1.500000e+08</td>\n",
              "      <td>143.0</td>\n",
              "      <td>-5.311000e+09</td>\n",
              "      <td>1.513500e+10</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.768000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7000000.0</td>\n",
              "      <td>1.562000e+10</td>\n",
              "      <td>88.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>829000000.0</td>\n",
              "      <td>1.342000e+09</td>\n",
              "      <td>4.099000e+09</td>\n",
              "      <td>3.212000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.308400e+10</td>\n",
              "      <td>4.091000e+09</td>\n",
              "      <td>63.0</td>\n",
              "      <td>2.703000e+10</td>\n",
              "      <td>3.300000e+08</td>\n",
              "      <td>2.240000e+09</td>\n",
              "      <td>887000000.0</td>\n",
              "      <td>1.004000e+09</td>\n",
              "      <td>1.799000e+09</td>\n",
              "      <td>-1.026000e+09</td>\n",
              "      <td>1.604300e+10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.700000e+08</td>\n",
              "      <td>-146000000.0</td>\n",
              "      <td>3.080000e+09</td>\n",
              "      <td>-3.150000e+08</td>\n",
              "      <td>-2.911000e+09</td>\n",
              "      <td>2.882000e+09</td>\n",
              "      <td>5.420000e+08</td>\n",
              "      <td>2.882000e+09</td>\n",
              "      <td>2.882000e+09</td>\n",
              "      <td>1.771000e+09</td>\n",
              "      <td>8.000000e+08</td>\n",
              "      <td>4.249000e+09</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.060000e+09</td>\n",
              "      <td>8.980000e+08</td>\n",
              "      <td>7.059000e+09</td>\n",
              "      <td>-4.559000e+09</td>\n",
              "      <td>8.170000e+08</td>\n",
              "      <td>601000000.0</td>\n",
              "      <td>1.092800e+10</td>\n",
              "      <td>-500000000.0</td>\n",
              "      <td>1.295000e+09</td>\n",
              "      <td>8.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-8.562000e+09</td>\n",
              "      <td>-1.052000e+09</td>\n",
              "      <td>2.068600e+10</td>\n",
              "      <td>1.677000e+09</td>\n",
              "      <td>6.309000e+09</td>\n",
              "      <td>4.322500e+10</td>\n",
              "      <td>1.175000e+10</td>\n",
              "      <td>1.340400e+10</td>\n",
              "      <td>2.021000e+09</td>\n",
              "      <td>4.120400e+10</td>\n",
              "      <td>4.322500e+10</td>\n",
              "      <td>4.265000e+10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>4.02</td>\n",
              "      <td>7.169154e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AAL</td>\n",
              "      <td>2015-12-31</td>\n",
              "      <td>5.102000e+09</td>\n",
              "      <td>352000000.0</td>\n",
              "      <td>-7.080000e+08</td>\n",
              "      <td>135.0</td>\n",
              "      <td>-6.151000e+09</td>\n",
              "      <td>1.159100e+10</td>\n",
              "      <td>51.0</td>\n",
              "      <td>1.085000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6000000.0</td>\n",
              "      <td>1.109600e+10</td>\n",
              "      <td>73.0</td>\n",
              "      <td>2.477000e+09</td>\n",
              "      <td>667000000.0</td>\n",
              "      <td>1.487000e+09</td>\n",
              "      <td>5.496000e+09</td>\n",
              "      <td>4.616000e+09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.751000e+10</td>\n",
              "      <td>4.091000e+09</td>\n",
              "      <td>73.0</td>\n",
              "      <td>2.989400e+10</td>\n",
              "      <td>-2.994000e+09</td>\n",
              "      <td>2.249000e+09</td>\n",
              "      <td>880000000.0</td>\n",
              "      <td>8.630000e+08</td>\n",
              "      <td>4.430000e+08</td>\n",
              "      <td>-6.330000e+08</td>\n",
              "      <td>1.833000e+10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.856000e+09</td>\n",
              "      <td>-604000000.0</td>\n",
              "      <td>6.249000e+09</td>\n",
              "      <td>-1.259000e+09</td>\n",
              "      <td>-5.594000e+09</td>\n",
              "      <td>7.610000e+09</td>\n",
              "      <td>-2.662000e+09</td>\n",
              "      <td>7.610000e+09</td>\n",
              "      <td>7.610000e+09</td>\n",
              "      <td>1.425000e+09</td>\n",
              "      <td>1.051000e+09</td>\n",
              "      <td>6.204000e+09</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.103000e+09</td>\n",
              "      <td>7.480000e+08</td>\n",
              "      <td>6.272000e+09</td>\n",
              "      <td>-4.732000e+09</td>\n",
              "      <td>9.600000e+07</td>\n",
              "      <td>114000000.0</td>\n",
              "      <td>1.017800e+10</td>\n",
              "      <td>95000000.0</td>\n",
              "      <td>1.364000e+09</td>\n",
              "      <td>11.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.230000e+09</td>\n",
              "      <td>-3.846000e+09</td>\n",
              "      <td>2.127500e+10</td>\n",
              "      <td>2.231000e+09</td>\n",
              "      <td>5.864000e+09</td>\n",
              "      <td>4.841500e+10</td>\n",
              "      <td>9.985000e+09</td>\n",
              "      <td>1.360500e+10</td>\n",
              "      <td>5.635000e+09</td>\n",
              "      <td>4.278000e+10</td>\n",
              "      <td>4.841500e+10</td>\n",
              "      <td>4.099000e+10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>11.39</td>\n",
              "      <td>6.681299e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AAP</td>\n",
              "      <td>2012-12-29</td>\n",
              "      <td>2.409453e+09</td>\n",
              "      <td>-89482000.0</td>\n",
              "      <td>6.000000e+05</td>\n",
              "      <td>32.0</td>\n",
              "      <td>-2.711820e+08</td>\n",
              "      <td>5.202150e+08</td>\n",
              "      <td>23.0</td>\n",
              "      <td>5.981110e+08</td>\n",
              "      <td>-260298000.0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>3.106967e+09</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.895440e+08</td>\n",
              "      <td>6.579150e+08</td>\n",
              "      <td>6.240740e+08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.292547e+09</td>\n",
              "      <td>7.638900e+07</td>\n",
              "      <td>50.0</td>\n",
              "      <td>3.098036e+09</td>\n",
              "      <td>2.364040e+08</td>\n",
              "      <td>2.884500e+07</td>\n",
              "      <td>33841000.0</td>\n",
              "      <td>2.308609e+09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.263230e+08</td>\n",
              "      <td>6.044610e+08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.774450e+08</td>\n",
              "      <td>540210000.0</td>\n",
              "      <td>6.852810e+08</td>\n",
              "      <td>1.279070e+08</td>\n",
              "      <td>-2.729780e+08</td>\n",
              "      <td>3.876700e+08</td>\n",
              "      <td>2.331100e+07</td>\n",
              "      <td>3.876700e+08</td>\n",
              "      <td>3.876700e+08</td>\n",
              "      <td>2.298660e+08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.573150e+08</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.183300e+07</td>\n",
              "      <td>4.761400e+07</td>\n",
              "      <td>1.495580e+08</td>\n",
              "      <td>2.667000e+06</td>\n",
              "      <td>-3.349900e+07</td>\n",
              "      <td>-1796000.0</td>\n",
              "      <td>2.390210e+08</td>\n",
              "      <td>8213000.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.149000e+08</td>\n",
              "      <td>-1.860000e+07</td>\n",
              "      <td>2.440721e+09</td>\n",
              "      <td>6.270000e+05</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.613814e+09</td>\n",
              "      <td>3.184200e+09</td>\n",
              "      <td>2.559638e+09</td>\n",
              "      <td>1.210694e+09</td>\n",
              "      <td>3.403120e+09</td>\n",
              "      <td>4.613814e+09</td>\n",
              "      <td>6.205003e+09</td>\n",
              "      <td>-27095000.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.29</td>\n",
              "      <td>7.328355e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 Ticker Symbol  ... Earnings Per Share  Estimated Shares Outstanding\n",
              "0           0           AAL  ...              -5.60                  3.350000e+08\n",
              "1           1           AAL  ...             -11.25                  1.630222e+08\n",
              "2           2           AAL  ...               4.02                  7.169154e+08\n",
              "3           3           AAL  ...              11.39                  6.681299e+08\n",
              "4           4           AAP  ...               5.29                  7.328355e+07\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e9ef6e7d-bdf1-49bc-b410-7ce23ea94363",
        "_uuid": "e62f8d1640f622ed28eb9b6414ae80716347ecac",
        "id": "tOpzPgvAYLC0"
      },
      "source": [
        "**Extract all symbols from the list**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "5bcb7190-f04b-4d9b-b326-78ec0b04c85c",
        "_uuid": "53cb26feb9de5ec569acd9205ae6540d5421c380",
        "id": "4qtp75QHYLC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5091faf0-f859-4323-ddf0-465315a284e4"
      },
      "source": [
        "symbols = list(set(df.symbol))\n",
        "len(symbols)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "501"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "f2794d85-8805-43e8-bff1-2ba9f0b9bcb8",
        "_uuid": "c33aa99b40f86a45476d8ae4a9043464baac8e05",
        "id": "0I9J1149YLC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1db920c6-0952-4f53-9db3-5fac1cfdc984"
      },
      "source": [
        "symbols[:11]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ES', 'NLSN', 'PNW', 'SYY', 'NTRS', 'MTB', 'HP', 'DPS', 'NFLX', 'MON', 'MUR']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "49e30b05-8198-4b48-badd-e7dc87e87a29",
        "_uuid": "8ffedca5e373f998976474533a9b537592aa7717",
        "id": "No-cna2KYLC6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "10a2b2d1-16ae-49cb-a3b7-2d9f286c103f"
      },
      "source": [
        "df = df[df.symbol == 'GOOG']\n",
        "df.drop(['symbol'],1,inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "      <th>adj close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>312.304948</td>\n",
              "      <td>310.955001</td>\n",
              "      <td>313.580158</td>\n",
              "      <td>3927000.0</td>\n",
              "      <td>312.205308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>312.419511</td>\n",
              "      <td>309.610028</td>\n",
              "      <td>312.748278</td>\n",
              "      <td>6031900.0</td>\n",
              "      <td>310.830459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>311.761979</td>\n",
              "      <td>302.048370</td>\n",
              "      <td>311.761979</td>\n",
              "      <td>7987100.0</td>\n",
              "      <td>302.994813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>303.562685</td>\n",
              "      <td>295.218951</td>\n",
              "      <td>303.861575</td>\n",
              "      <td>12876600.0</td>\n",
              "      <td>295.941242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>294.895159</td>\n",
              "      <td>293.455551</td>\n",
              "      <td>300.499172</td>\n",
              "      <td>9483900.0</td>\n",
              "      <td>299.886470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  open         low        high      volume   adj close\n",
              "date                                                                  \n",
              "2010-01-04  312.304948  310.955001  313.580158   3927000.0  312.205308\n",
              "2010-01-05  312.419511  309.610028  312.748278   6031900.0  310.830459\n",
              "2010-01-06  311.761979  302.048370  311.761979   7987100.0  302.994813\n",
              "2010-01-07  303.562685  295.218951  303.861575  12876600.0  295.941242\n",
              "2010-01-08  294.895159  293.455551  300.499172   9483900.0  299.886470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YY9QXV0SYLC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "abfb23e5-aa07-44d1-c074-e3e51686b1db"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1762 entries, 2010-01-04 to 2016-12-30\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   open       1762 non-null   float64\n",
            " 1   low        1762 non-null   float64\n",
            " 2   high       1762 non-null   float64\n",
            " 3   volume     1762 non-null   float64\n",
            " 4   adj close  1762 non-null   float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 82.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "ba1e7e86-37c9-4db4-91ea-b0fea4c473b3",
        "_uuid": "c9e00e4497abcd967935a3bace2c3c3197644445",
        "id": "FmMwO-_TYLDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a5fcee2e-f13e-4526-c6ec-afcfd53d5075"
      },
      "source": [
        "df.plot(figsize=(23,8),title = \"Google Stock Price Analysis\")\n",
        "plt.subplot(411)\n",
        "plt.plot(df.open, label='Original')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(df.low, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(df.high,label='Seasonality')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(df.volume, label='Residuals')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ffc8e87df837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2103\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2104\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0;31m# that have been set by `fig.align_xlabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2004\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2005\u001b[0m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2006\u001b[0;31m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2007\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m             \u001b[0mbboxes2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdpi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0;31m# Ensure that values is a 2d array (but remember whether\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;31m# we started with a 1d or 2d array).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f27b7f54-92e8-4121-99c4-17f62da8a130",
        "_uuid": "1338c7184d5f99ed69403abac24362828ddd8243",
        "collapsed": true,
        "id": "Pzjug_73YLDE"
      },
      "source": [
        "**Normalize the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7182c9d258d4eff3c9f2bec5304a912372f6c884",
        "id": "sWBDTcWfYLDE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "outputId": "120f0a15-e6b8-4e81-ff95-917d17a2396e"
      },
      "source": [
        "def normalize_data(df):\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
        "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
        "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
        "    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n",
        "    df['adj close'] = min_max_scaler.fit_transform(df['adj close'].values.reshape(-1,1))\n",
        "    return df\n",
        "df = normalize_data(df)\n",
        "df.plot(figsize=(23,10))\n",
        "plt.show()\n",
        "plt.subplot(411)\n",
        "plt.plot(df.open, label='Original')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(df.low, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(df.high,label='Seasonality')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(df.volume, label='Residuals')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1656x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a6629fae3b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2588\u001b[0m                 \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_title_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2531\u001b[0m                 if (ax.xaxis.get_ticks_position() in ['top', 'unknown']\n\u001b[1;32m   2532\u001b[0m                         or ax.xaxis.get_label_position() == 'top'):\n\u001b[0;32m-> 2533\u001b[0;31m                     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m                     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(\n\u001b[0;32m-> 1192\u001b[0;31m                     ticks_to_draw, renderer)\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_offset_text_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabelBoxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticklabelBoxes2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclean_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 w, h, d = renderer.get_text_width_height_descent(\n\u001b[0;32m--> 300\u001b[0;31m                     clean_line, self._fontproperties, ismath=ismath)\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_width_height\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# width and height of unrotated string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[0;34m(self, prop)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfont\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mefficiency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \"\"\"\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mfindfont\u001b[0;34m(self, prop, fontext, directory, fallback_to_default, rebuild_if_missing)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         return self._findfont_cached(\n\u001b[1;32m   1224\u001b[0m             \u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfallback_to_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild_if_missing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             rc_params)\n\u001b[0m\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         l = (tuple(self.get_family()),\n\u001b[0m\u001b[1;32m    665\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mget_family\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fontconfig_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_family\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \"\"\"\n\u001b[1;32m    681\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mfont\u001b[0m \u001b[0mnames\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcomprise\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfont\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a883ec73e29b01f9edbe9d4b5eeac03fbbadd165",
        "id": "kSavzMv2YLDH"
      },
      "source": [
        "**Create Training Set and Testing Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a479f544ebcb4f098f019dd8adaba7822c736f92",
        "id": "NLoQqq-GYLDH"
      },
      "source": [
        "del df['volume']\n",
        "def load_data(stock, window):\n",
        "    data = stock.to_numpy() \n",
        "    result = []\n",
        "    \n",
        "    for index in range(len(data) - window): # maxmimum date = lastest date - sequence length\n",
        "        result.append(data[index: index + window]) # index : index + n days\n",
        "    \n",
        "    result = np.array(result).reshape(4*window, -1)\n",
        "    row = round(0.9 * result.shape[1]) # 90% split\n",
        "    \n",
        "    x_train = result[:, :int(row)] \n",
        "    y_train = data[window:window+int(row),3].reshape(-1, 1)\n",
        "    \n",
        "    x_test = result[:, int(row):] \n",
        "    y_test = data[window+int(row):,3].reshape(-1, 1)  \n",
        "\n",
        "    return [x_train, y_train, x_test, y_test]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzFV2rSNYLDK"
      },
      "source": [
        "x_train, y_train, x_test, y_test = load_data(df.iloc[:1760,:], 10)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EJ99eBNYLDM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "35937e7b-0fb7-4e09-fb00-4494e907752d"
      },
      "source": [
        "x_train.shape\n",
        "y_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1575, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "996d78fdfb6912bb07d5eebccf7ee717ad92fb95",
        "id": "y3MdeR_EYLDO"
      },
      "source": [
        "## **Build the structure of model**  \n",
        " \n",
        "* **epochs** = 10000  \n",
        "* **DNN** 256  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLyYpm9HYLDO"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3IxJyM9YLDR"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(10, activation='relu', input_shape=(40,)))\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6gqjqhJYLDT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "71951473-b6fe-43d6-9d4b-0a2f4a337790"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                410       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 641\n",
            "Trainable params: 641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlTBiSHxYLDX"
      },
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer = optimizers.SGD(learning_rate=0.01),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXtwcN-VYLDZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fc232239-4424-430d-bab9-83f49fbdfc0f"
      },
      "source": [
        "hist = model.fit(x_train.T, y_train, batch_size=x_train.size, epochs=10000, validation_data=(x_test.T, y_test))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 7501/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0463 - accuracy: 6.3492e-04 - val_loss: 0.2300 - val_accuracy: 0.0000e+00\n",
            "Epoch 7502/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2299 - val_accuracy: 0.0000e+00\n",
            "Epoch 7503/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2299 - val_accuracy: 0.0000e+00\n",
            "Epoch 7504/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2298 - val_accuracy: 0.0000e+00\n",
            "Epoch 7505/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2298 - val_accuracy: 0.0000e+00\n",
            "Epoch 7506/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2298 - val_accuracy: 0.0000e+00\n",
            "Epoch 7507/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2297 - val_accuracy: 0.0000e+00\n",
            "Epoch 7508/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2297 - val_accuracy: 0.0000e+00\n",
            "Epoch 7509/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2296 - val_accuracy: 0.0000e+00\n",
            "Epoch 7510/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2296 - val_accuracy: 0.0000e+00\n",
            "Epoch 7511/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0462 - accuracy: 6.3492e-04 - val_loss: 0.2296 - val_accuracy: 0.0000e+00\n",
            "Epoch 7512/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2295 - val_accuracy: 0.0000e+00\n",
            "Epoch 7513/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2295 - val_accuracy: 0.0000e+00\n",
            "Epoch 7514/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2294 - val_accuracy: 0.0000e+00\n",
            "Epoch 7515/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2294 - val_accuracy: 0.0000e+00\n",
            "Epoch 7516/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2293 - val_accuracy: 0.0000e+00\n",
            "Epoch 7517/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2293 - val_accuracy: 0.0000e+00\n",
            "Epoch 7518/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2293 - val_accuracy: 0.0000e+00\n",
            "Epoch 7519/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2292 - val_accuracy: 0.0000e+00\n",
            "Epoch 7520/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2292 - val_accuracy: 0.0000e+00\n",
            "Epoch 7521/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0461 - accuracy: 6.3492e-04 - val_loss: 0.2291 - val_accuracy: 0.0000e+00\n",
            "Epoch 7522/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2291 - val_accuracy: 0.0000e+00\n",
            "Epoch 7523/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2291 - val_accuracy: 0.0000e+00\n",
            "Epoch 7524/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2290 - val_accuracy: 0.0000e+00\n",
            "Epoch 7525/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2290 - val_accuracy: 0.0000e+00\n",
            "Epoch 7526/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2289 - val_accuracy: 0.0000e+00\n",
            "Epoch 7527/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2289 - val_accuracy: 0.0000e+00\n",
            "Epoch 7528/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2288 - val_accuracy: 0.0000e+00\n",
            "Epoch 7529/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2288 - val_accuracy: 0.0000e+00\n",
            "Epoch 7530/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2288 - val_accuracy: 0.0000e+00\n",
            "Epoch 7531/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0460 - accuracy: 6.3492e-04 - val_loss: 0.2287 - val_accuracy: 0.0000e+00\n",
            "Epoch 7532/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2287 - val_accuracy: 0.0000e+00\n",
            "Epoch 7533/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2286 - val_accuracy: 0.0000e+00\n",
            "Epoch 7534/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2286 - val_accuracy: 0.0000e+00\n",
            "Epoch 7535/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2285 - val_accuracy: 0.0000e+00\n",
            "Epoch 7536/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2285 - val_accuracy: 0.0000e+00\n",
            "Epoch 7537/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2285 - val_accuracy: 0.0000e+00\n",
            "Epoch 7538/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2284 - val_accuracy: 0.0000e+00\n",
            "Epoch 7539/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2284 - val_accuracy: 0.0000e+00\n",
            "Epoch 7540/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0459 - accuracy: 6.3492e-04 - val_loss: 0.2283 - val_accuracy: 0.0000e+00\n",
            "Epoch 7541/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2283 - val_accuracy: 0.0000e+00\n",
            "Epoch 7542/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2282 - val_accuracy: 0.0000e+00\n",
            "Epoch 7543/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2282 - val_accuracy: 0.0000e+00\n",
            "Epoch 7544/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2282 - val_accuracy: 0.0000e+00\n",
            "Epoch 7545/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2281 - val_accuracy: 0.0000e+00\n",
            "Epoch 7546/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2281 - val_accuracy: 0.0000e+00\n",
            "Epoch 7547/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2280 - val_accuracy: 0.0000e+00\n",
            "Epoch 7548/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2280 - val_accuracy: 0.0000e+00\n",
            "Epoch 7549/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2279 - val_accuracy: 0.0000e+00\n",
            "Epoch 7550/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0458 - accuracy: 6.3492e-04 - val_loss: 0.2279 - val_accuracy: 0.0000e+00\n",
            "Epoch 7551/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2279 - val_accuracy: 0.0000e+00\n",
            "Epoch 7552/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2278 - val_accuracy: 0.0000e+00\n",
            "Epoch 7553/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2278 - val_accuracy: 0.0000e+00\n",
            "Epoch 7554/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2277 - val_accuracy: 0.0000e+00\n",
            "Epoch 7555/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2277 - val_accuracy: 0.0000e+00\n",
            "Epoch 7556/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2276 - val_accuracy: 0.0000e+00\n",
            "Epoch 7557/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2276 - val_accuracy: 0.0000e+00\n",
            "Epoch 7558/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2275 - val_accuracy: 0.0000e+00\n",
            "Epoch 7559/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2275 - val_accuracy: 0.0000e+00\n",
            "Epoch 7560/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0457 - accuracy: 6.3492e-04 - val_loss: 0.2275 - val_accuracy: 0.0000e+00\n",
            "Epoch 7561/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2274 - val_accuracy: 0.0000e+00\n",
            "Epoch 7562/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2274 - val_accuracy: 0.0000e+00\n",
            "Epoch 7563/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2273 - val_accuracy: 0.0000e+00\n",
            "Epoch 7564/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2273 - val_accuracy: 0.0000e+00\n",
            "Epoch 7565/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2272 - val_accuracy: 0.0000e+00\n",
            "Epoch 7566/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2272 - val_accuracy: 0.0000e+00\n",
            "Epoch 7567/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2272 - val_accuracy: 0.0000e+00\n",
            "Epoch 7568/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2271 - val_accuracy: 0.0000e+00\n",
            "Epoch 7569/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0456 - accuracy: 6.3492e-04 - val_loss: 0.2271 - val_accuracy: 0.0000e+00\n",
            "Epoch 7570/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2270 - val_accuracy: 0.0000e+00\n",
            "Epoch 7571/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2270 - val_accuracy: 0.0000e+00\n",
            "Epoch 7572/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2269 - val_accuracy: 0.0000e+00\n",
            "Epoch 7573/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2269 - val_accuracy: 0.0000e+00\n",
            "Epoch 7574/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2268 - val_accuracy: 0.0000e+00\n",
            "Epoch 7575/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2268 - val_accuracy: 0.0000e+00\n",
            "Epoch 7576/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2268 - val_accuracy: 0.0000e+00\n",
            "Epoch 7577/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2267 - val_accuracy: 0.0000e+00\n",
            "Epoch 7578/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2267 - val_accuracy: 0.0000e+00\n",
            "Epoch 7579/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0455 - accuracy: 6.3492e-04 - val_loss: 0.2266 - val_accuracy: 0.0000e+00\n",
            "Epoch 7580/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2266 - val_accuracy: 0.0000e+00\n",
            "Epoch 7581/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2265 - val_accuracy: 0.0000e+00\n",
            "Epoch 7582/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2265 - val_accuracy: 0.0000e+00\n",
            "Epoch 7583/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2264 - val_accuracy: 0.0000e+00\n",
            "Epoch 7584/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2264 - val_accuracy: 0.0000e+00\n",
            "Epoch 7585/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2264 - val_accuracy: 0.0000e+00\n",
            "Epoch 7586/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2263 - val_accuracy: 0.0000e+00\n",
            "Epoch 7587/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2263 - val_accuracy: 0.0000e+00\n",
            "Epoch 7588/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0454 - accuracy: 6.3492e-04 - val_loss: 0.2262 - val_accuracy: 0.0000e+00\n",
            "Epoch 7589/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2262 - val_accuracy: 0.0000e+00\n",
            "Epoch 7590/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2261 - val_accuracy: 0.0000e+00\n",
            "Epoch 7591/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2261 - val_accuracy: 0.0000e+00\n",
            "Epoch 7592/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2260 - val_accuracy: 0.0000e+00\n",
            "Epoch 7593/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2260 - val_accuracy: 0.0000e+00\n",
            "Epoch 7594/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2260 - val_accuracy: 0.0000e+00\n",
            "Epoch 7595/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2259 - val_accuracy: 0.0000e+00\n",
            "Epoch 7596/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2259 - val_accuracy: 0.0000e+00\n",
            "Epoch 7597/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2258 - val_accuracy: 0.0000e+00\n",
            "Epoch 7598/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0453 - accuracy: 6.3492e-04 - val_loss: 0.2258 - val_accuracy: 0.0000e+00\n",
            "Epoch 7599/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2257 - val_accuracy: 0.0000e+00\n",
            "Epoch 7600/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2257 - val_accuracy: 0.0000e+00\n",
            "Epoch 7601/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2256 - val_accuracy: 0.0000e+00\n",
            "Epoch 7602/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2256 - val_accuracy: 0.0000e+00\n",
            "Epoch 7603/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2256 - val_accuracy: 0.0000e+00\n",
            "Epoch 7604/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2255 - val_accuracy: 0.0000e+00\n",
            "Epoch 7605/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2255 - val_accuracy: 0.0000e+00\n",
            "Epoch 7606/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2254 - val_accuracy: 0.0000e+00\n",
            "Epoch 7607/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0452 - accuracy: 6.3492e-04 - val_loss: 0.2254 - val_accuracy: 0.0000e+00\n",
            "Epoch 7608/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2253 - val_accuracy: 0.0000e+00\n",
            "Epoch 7609/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2253 - val_accuracy: 0.0000e+00\n",
            "Epoch 7610/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2252 - val_accuracy: 0.0000e+00\n",
            "Epoch 7611/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2252 - val_accuracy: 0.0000e+00\n",
            "Epoch 7612/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2252 - val_accuracy: 0.0000e+00\n",
            "Epoch 7613/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2251 - val_accuracy: 0.0000e+00\n",
            "Epoch 7614/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2251 - val_accuracy: 0.0000e+00\n",
            "Epoch 7615/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2250 - val_accuracy: 0.0000e+00\n",
            "Epoch 7616/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0451 - accuracy: 6.3492e-04 - val_loss: 0.2250 - val_accuracy: 0.0000e+00\n",
            "Epoch 7617/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2249 - val_accuracy: 0.0000e+00\n",
            "Epoch 7618/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2249 - val_accuracy: 0.0000e+00\n",
            "Epoch 7619/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2248 - val_accuracy: 0.0000e+00\n",
            "Epoch 7620/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2248 - val_accuracy: 0.0000e+00\n",
            "Epoch 7621/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2247 - val_accuracy: 0.0000e+00\n",
            "Epoch 7622/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2247 - val_accuracy: 0.0000e+00\n",
            "Epoch 7623/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2246 - val_accuracy: 0.0000e+00\n",
            "Epoch 7624/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2246 - val_accuracy: 0.0000e+00\n",
            "Epoch 7625/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2246 - val_accuracy: 0.0000e+00\n",
            "Epoch 7626/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0450 - accuracy: 6.3492e-04 - val_loss: 0.2245 - val_accuracy: 0.0000e+00\n",
            "Epoch 7627/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2245 - val_accuracy: 0.0000e+00\n",
            "Epoch 7628/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2244 - val_accuracy: 0.0000e+00\n",
            "Epoch 7629/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2244 - val_accuracy: 0.0000e+00\n",
            "Epoch 7630/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2243 - val_accuracy: 0.0000e+00\n",
            "Epoch 7631/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2243 - val_accuracy: 0.0000e+00\n",
            "Epoch 7632/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2242 - val_accuracy: 0.0000e+00\n",
            "Epoch 7633/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2242 - val_accuracy: 0.0000e+00\n",
            "Epoch 7634/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2241 - val_accuracy: 0.0000e+00\n",
            "Epoch 7635/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0449 - accuracy: 6.3492e-04 - val_loss: 0.2241 - val_accuracy: 0.0000e+00\n",
            "Epoch 7636/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2241 - val_accuracy: 0.0000e+00\n",
            "Epoch 7637/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2240 - val_accuracy: 0.0000e+00\n",
            "Epoch 7638/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2240 - val_accuracy: 0.0000e+00\n",
            "Epoch 7639/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2239 - val_accuracy: 0.0000e+00\n",
            "Epoch 7640/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2239 - val_accuracy: 0.0000e+00\n",
            "Epoch 7641/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2238 - val_accuracy: 0.0000e+00\n",
            "Epoch 7642/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2238 - val_accuracy: 0.0000e+00\n",
            "Epoch 7643/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2237 - val_accuracy: 0.0000e+00\n",
            "Epoch 7644/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0448 - accuracy: 6.3492e-04 - val_loss: 0.2237 - val_accuracy: 0.0000e+00\n",
            "Epoch 7645/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2236 - val_accuracy: 0.0000e+00\n",
            "Epoch 7646/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2236 - val_accuracy: 0.0000e+00\n",
            "Epoch 7647/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2236 - val_accuracy: 0.0000e+00\n",
            "Epoch 7648/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2235 - val_accuracy: 0.0000e+00\n",
            "Epoch 7649/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2235 - val_accuracy: 0.0000e+00\n",
            "Epoch 7650/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2234 - val_accuracy: 0.0000e+00\n",
            "Epoch 7651/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2234 - val_accuracy: 0.0000e+00\n",
            "Epoch 7652/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2233 - val_accuracy: 0.0000e+00\n",
            "Epoch 7653/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0447 - accuracy: 6.3492e-04 - val_loss: 0.2233 - val_accuracy: 0.0000e+00\n",
            "Epoch 7654/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2232 - val_accuracy: 0.0000e+00\n",
            "Epoch 7655/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2232 - val_accuracy: 0.0000e+00\n",
            "Epoch 7656/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2231 - val_accuracy: 0.0000e+00\n",
            "Epoch 7657/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2231 - val_accuracy: 0.0000e+00\n",
            "Epoch 7658/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2230 - val_accuracy: 0.0000e+00\n",
            "Epoch 7659/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2230 - val_accuracy: 0.0000e+00\n",
            "Epoch 7660/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2229 - val_accuracy: 0.0000e+00\n",
            "Epoch 7661/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2229 - val_accuracy: 0.0000e+00\n",
            "Epoch 7662/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0446 - accuracy: 6.3492e-04 - val_loss: 0.2229 - val_accuracy: 0.0000e+00\n",
            "Epoch 7663/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2228 - val_accuracy: 0.0000e+00\n",
            "Epoch 7664/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2228 - val_accuracy: 0.0000e+00\n",
            "Epoch 7665/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2227 - val_accuracy: 0.0000e+00\n",
            "Epoch 7666/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2227 - val_accuracy: 0.0000e+00\n",
            "Epoch 7667/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2226 - val_accuracy: 0.0000e+00\n",
            "Epoch 7668/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2226 - val_accuracy: 0.0000e+00\n",
            "Epoch 7669/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2225 - val_accuracy: 0.0000e+00\n",
            "Epoch 7670/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2225 - val_accuracy: 0.0000e+00\n",
            "Epoch 7671/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0445 - accuracy: 6.3492e-04 - val_loss: 0.2224 - val_accuracy: 0.0000e+00\n",
            "Epoch 7672/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2224 - val_accuracy: 0.0000e+00\n",
            "Epoch 7673/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2223 - val_accuracy: 0.0000e+00\n",
            "Epoch 7674/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2223 - val_accuracy: 0.0000e+00\n",
            "Epoch 7675/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2222 - val_accuracy: 0.0000e+00\n",
            "Epoch 7676/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2222 - val_accuracy: 0.0000e+00\n",
            "Epoch 7677/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2221 - val_accuracy: 0.0000e+00\n",
            "Epoch 7678/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2221 - val_accuracy: 0.0000e+00\n",
            "Epoch 7679/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2221 - val_accuracy: 0.0000e+00\n",
            "Epoch 7680/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0444 - accuracy: 6.3492e-04 - val_loss: 0.2220 - val_accuracy: 0.0000e+00\n",
            "Epoch 7681/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2220 - val_accuracy: 0.0000e+00\n",
            "Epoch 7682/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2219 - val_accuracy: 0.0000e+00\n",
            "Epoch 7683/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2219 - val_accuracy: 0.0000e+00\n",
            "Epoch 7684/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2218 - val_accuracy: 0.0000e+00\n",
            "Epoch 7685/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2218 - val_accuracy: 0.0000e+00\n",
            "Epoch 7686/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2217 - val_accuracy: 0.0000e+00\n",
            "Epoch 7687/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2217 - val_accuracy: 0.0000e+00\n",
            "Epoch 7688/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2216 - val_accuracy: 0.0000e+00\n",
            "Epoch 7689/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0443 - accuracy: 6.3492e-04 - val_loss: 0.2216 - val_accuracy: 0.0000e+00\n",
            "Epoch 7690/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2215 - val_accuracy: 0.0000e+00\n",
            "Epoch 7691/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2215 - val_accuracy: 0.0000e+00\n",
            "Epoch 7692/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2214 - val_accuracy: 0.0000e+00\n",
            "Epoch 7693/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2214 - val_accuracy: 0.0000e+00\n",
            "Epoch 7694/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2213 - val_accuracy: 0.0000e+00\n",
            "Epoch 7695/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2213 - val_accuracy: 0.0000e+00\n",
            "Epoch 7696/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2213 - val_accuracy: 0.0000e+00\n",
            "Epoch 7697/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2212 - val_accuracy: 0.0000e+00\n",
            "Epoch 7698/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0442 - accuracy: 6.3492e-04 - val_loss: 0.2212 - val_accuracy: 0.0000e+00\n",
            "Epoch 7699/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2211 - val_accuracy: 0.0000e+00\n",
            "Epoch 7700/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2211 - val_accuracy: 0.0000e+00\n",
            "Epoch 7701/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2210 - val_accuracy: 0.0000e+00\n",
            "Epoch 7702/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2210 - val_accuracy: 0.0000e+00\n",
            "Epoch 7703/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2209 - val_accuracy: 0.0000e+00\n",
            "Epoch 7704/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2209 - val_accuracy: 0.0000e+00\n",
            "Epoch 7705/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2208 - val_accuracy: 0.0000e+00\n",
            "Epoch 7706/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2208 - val_accuracy: 0.0000e+00\n",
            "Epoch 7707/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0441 - accuracy: 6.3492e-04 - val_loss: 0.2208 - val_accuracy: 0.0000e+00\n",
            "Epoch 7708/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2207 - val_accuracy: 0.0000e+00\n",
            "Epoch 7709/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2207 - val_accuracy: 0.0000e+00\n",
            "Epoch 7710/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2206 - val_accuracy: 0.0000e+00\n",
            "Epoch 7711/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2206 - val_accuracy: 0.0000e+00\n",
            "Epoch 7712/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2205 - val_accuracy: 0.0000e+00\n",
            "Epoch 7713/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2205 - val_accuracy: 0.0000e+00\n",
            "Epoch 7714/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2204 - val_accuracy: 0.0000e+00\n",
            "Epoch 7715/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2204 - val_accuracy: 0.0000e+00\n",
            "Epoch 7716/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0440 - accuracy: 6.3492e-04 - val_loss: 0.2204 - val_accuracy: 0.0000e+00\n",
            "Epoch 7717/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0439 - accuracy: 6.3492e-04 - val_loss: 0.2203 - val_accuracy: 0.0000e+00\n",
            "Epoch 7718/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0439 - accuracy: 6.3492e-04 - val_loss: 0.2203 - val_accuracy: 0.0000e+00\n",
            "Epoch 7719/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0439 - accuracy: 6.3492e-04 - val_loss: 0.2202 - val_accuracy: 0.0000e+00\n",
            "Epoch 7720/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0439 - accuracy: 6.3492e-04 - val_loss: 0.2202 - val_accuracy: 0.0000e+00\n",
            "Epoch 7721/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0439 - accuracy: 6.3492e-04 - val_loss: 0.2201 - val_accuracy: 0.0000e+00\n",
            "Epoch 7722/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0439 - accuracy: 6.3492e-04 - val_loss: 0.2201 - val_accuracy: 0.0000e+00\n",
            "Epoch 7723/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0439 - accuracy: 6.3492e-04 - val_loss: 0.2200 - val_accuracy: 0.0000e+00\n",
            "Epoch 7724/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0439 - accuracy: 6.3492e-04 - val_loss: 0.2200 - val_accuracy: 0.0000e+00\n",
            "Epoch 7725/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2200 - val_accuracy: 0.0000e+00\n",
            "Epoch 7726/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2199 - val_accuracy: 0.0000e+00\n",
            "Epoch 7727/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2199 - val_accuracy: 0.0000e+00\n",
            "Epoch 7728/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2198 - val_accuracy: 0.0000e+00\n",
            "Epoch 7729/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2198 - val_accuracy: 0.0000e+00\n",
            "Epoch 7730/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2197 - val_accuracy: 0.0000e+00\n",
            "Epoch 7731/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2197 - val_accuracy: 0.0000e+00\n",
            "Epoch 7732/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2196 - val_accuracy: 0.0000e+00\n",
            "Epoch 7733/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0438 - accuracy: 6.3492e-04 - val_loss: 0.2196 - val_accuracy: 0.0000e+00\n",
            "Epoch 7734/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 7735/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 7736/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 7737/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2194 - val_accuracy: 0.0000e+00\n",
            "Epoch 7738/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2194 - val_accuracy: 0.0000e+00\n",
            "Epoch 7739/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2193 - val_accuracy: 0.0000e+00\n",
            "Epoch 7740/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2193 - val_accuracy: 0.0000e+00\n",
            "Epoch 7741/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 7742/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0437 - accuracy: 6.3492e-04 - val_loss: 0.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 7743/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0436 - accuracy: 6.3492e-04 - val_loss: 0.2191 - val_accuracy: 0.0000e+00\n",
            "Epoch 7744/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0436 - accuracy: 6.3492e-04 - val_loss: 0.2191 - val_accuracy: 0.0000e+00\n",
            "Epoch 7745/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0436 - accuracy: 6.3492e-04 - val_loss: 0.2190 - val_accuracy: 0.0000e+00\n",
            "Epoch 7746/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0436 - accuracy: 6.3492e-04 - val_loss: 0.2190 - val_accuracy: 0.0000e+00\n",
            "Epoch 7747/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0436 - accuracy: 6.3492e-04 - val_loss: 0.2189 - val_accuracy: 0.0000e+00\n",
            "Epoch 7748/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0436 - accuracy: 6.3492e-04 - val_loss: 0.2189 - val_accuracy: 0.0000e+00\n",
            "Epoch 7749/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0436 - accuracy: 6.3492e-04 - val_loss: 0.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 7750/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0436 - accuracy: 6.3492e-04 - val_loss: 0.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 7751/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 7752/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2187 - val_accuracy: 0.0000e+00\n",
            "Epoch 7753/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2187 - val_accuracy: 0.0000e+00\n",
            "Epoch 7754/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2186 - val_accuracy: 0.0000e+00\n",
            "Epoch 7755/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2186 - val_accuracy: 0.0000e+00\n",
            "Epoch 7756/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2185 - val_accuracy: 0.0000e+00\n",
            "Epoch 7757/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2185 - val_accuracy: 0.0000e+00\n",
            "Epoch 7758/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2184 - val_accuracy: 0.0000e+00\n",
            "Epoch 7759/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0435 - accuracy: 6.3492e-04 - val_loss: 0.2184 - val_accuracy: 0.0000e+00\n",
            "Epoch 7760/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2183 - val_accuracy: 0.0000e+00\n",
            "Epoch 7761/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2183 - val_accuracy: 0.0000e+00\n",
            "Epoch 7762/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2182 - val_accuracy: 0.0000e+00\n",
            "Epoch 7763/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2182 - val_accuracy: 0.0000e+00\n",
            "Epoch 7764/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2181 - val_accuracy: 0.0000e+00\n",
            "Epoch 7765/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2181 - val_accuracy: 0.0000e+00\n",
            "Epoch 7766/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2180 - val_accuracy: 0.0000e+00\n",
            "Epoch 7767/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2180 - val_accuracy: 0.0000e+00\n",
            "Epoch 7768/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0434 - accuracy: 6.3492e-04 - val_loss: 0.2179 - val_accuracy: 0.0000e+00\n",
            "Epoch 7769/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0433 - accuracy: 6.3492e-04 - val_loss: 0.2179 - val_accuracy: 0.0000e+00\n",
            "Epoch 7770/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0433 - accuracy: 6.3492e-04 - val_loss: 0.2178 - val_accuracy: 0.0000e+00\n",
            "Epoch 7771/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0433 - accuracy: 6.3492e-04 - val_loss: 0.2178 - val_accuracy: 0.0000e+00\n",
            "Epoch 7772/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0433 - accuracy: 6.3492e-04 - val_loss: 0.2178 - val_accuracy: 0.0000e+00\n",
            "Epoch 7773/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0433 - accuracy: 6.3492e-04 - val_loss: 0.2177 - val_accuracy: 0.0000e+00\n",
            "Epoch 7774/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0433 - accuracy: 6.3492e-04 - val_loss: 0.2177 - val_accuracy: 0.0000e+00\n",
            "Epoch 7775/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0433 - accuracy: 6.3492e-04 - val_loss: 0.2176 - val_accuracy: 0.0000e+00\n",
            "Epoch 7776/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0433 - accuracy: 6.3492e-04 - val_loss: 0.2176 - val_accuracy: 0.0000e+00\n",
            "Epoch 7777/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2175 - val_accuracy: 0.0000e+00\n",
            "Epoch 7778/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2175 - val_accuracy: 0.0000e+00\n",
            "Epoch 7779/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2174 - val_accuracy: 0.0000e+00\n",
            "Epoch 7780/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2174 - val_accuracy: 0.0000e+00\n",
            "Epoch 7781/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2173 - val_accuracy: 0.0000e+00\n",
            "Epoch 7782/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2173 - val_accuracy: 0.0000e+00\n",
            "Epoch 7783/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2172 - val_accuracy: 0.0000e+00\n",
            "Epoch 7784/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2172 - val_accuracy: 0.0000e+00\n",
            "Epoch 7785/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0432 - accuracy: 6.3492e-04 - val_loss: 0.2171 - val_accuracy: 0.0000e+00\n",
            "Epoch 7786/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0431 - accuracy: 6.3492e-04 - val_loss: 0.2171 - val_accuracy: 0.0000e+00\n",
            "Epoch 7787/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0431 - accuracy: 6.3492e-04 - val_loss: 0.2170 - val_accuracy: 0.0000e+00\n",
            "Epoch 7788/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0431 - accuracy: 6.3492e-04 - val_loss: 0.2170 - val_accuracy: 0.0000e+00\n",
            "Epoch 7789/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0431 - accuracy: 6.3492e-04 - val_loss: 0.2169 - val_accuracy: 0.0000e+00\n",
            "Epoch 7790/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0431 - accuracy: 6.3492e-04 - val_loss: 0.2169 - val_accuracy: 0.0000e+00\n",
            "Epoch 7791/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0431 - accuracy: 6.3492e-04 - val_loss: 0.2168 - val_accuracy: 0.0000e+00\n",
            "Epoch 7792/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0431 - accuracy: 6.3492e-04 - val_loss: 0.2168 - val_accuracy: 0.0000e+00\n",
            "Epoch 7793/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0431 - accuracy: 6.3492e-04 - val_loss: 0.2167 - val_accuracy: 0.0000e+00\n",
            "Epoch 7794/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0430 - accuracy: 6.3492e-04 - val_loss: 0.2167 - val_accuracy: 0.0000e+00\n",
            "Epoch 7795/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0430 - accuracy: 6.3492e-04 - val_loss: 0.2166 - val_accuracy: 0.0000e+00\n",
            "Epoch 7796/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0430 - accuracy: 6.3492e-04 - val_loss: 0.2166 - val_accuracy: 0.0000e+00\n",
            "Epoch 7797/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0430 - accuracy: 6.3492e-04 - val_loss: 0.2165 - val_accuracy: 0.0000e+00\n",
            "Epoch 7798/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0430 - accuracy: 6.3492e-04 - val_loss: 0.2165 - val_accuracy: 0.0000e+00\n",
            "Epoch 7799/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0430 - accuracy: 6.3492e-04 - val_loss: 0.2164 - val_accuracy: 0.0000e+00\n",
            "Epoch 7800/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0430 - accuracy: 6.3492e-04 - val_loss: 0.2164 - val_accuracy: 0.0000e+00\n",
            "Epoch 7801/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0430 - accuracy: 6.3492e-04 - val_loss: 0.2163 - val_accuracy: 0.0000e+00\n",
            "Epoch 7802/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2163 - val_accuracy: 0.0000e+00\n",
            "Epoch 7803/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2162 - val_accuracy: 0.0000e+00\n",
            "Epoch 7804/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2162 - val_accuracy: 0.0000e+00\n",
            "Epoch 7805/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2161 - val_accuracy: 0.0000e+00\n",
            "Epoch 7806/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2161 - val_accuracy: 0.0000e+00\n",
            "Epoch 7807/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2160 - val_accuracy: 0.0000e+00\n",
            "Epoch 7808/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2160 - val_accuracy: 0.0000e+00\n",
            "Epoch 7809/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2159 - val_accuracy: 0.0000e+00\n",
            "Epoch 7810/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0429 - accuracy: 6.3492e-04 - val_loss: 0.2159 - val_accuracy: 0.0000e+00\n",
            "Epoch 7811/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0428 - accuracy: 6.3492e-04 - val_loss: 0.2158 - val_accuracy: 0.0000e+00\n",
            "Epoch 7812/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0428 - accuracy: 6.3492e-04 - val_loss: 0.2158 - val_accuracy: 0.0000e+00\n",
            "Epoch 7813/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0428 - accuracy: 6.3492e-04 - val_loss: 0.2157 - val_accuracy: 0.0000e+00\n",
            "Epoch 7814/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0428 - accuracy: 6.3492e-04 - val_loss: 0.2157 - val_accuracy: 0.0000e+00\n",
            "Epoch 7815/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0428 - accuracy: 6.3492e-04 - val_loss: 0.2156 - val_accuracy: 0.0000e+00\n",
            "Epoch 7816/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0428 - accuracy: 6.3492e-04 - val_loss: 0.2156 - val_accuracy: 0.0000e+00\n",
            "Epoch 7817/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0428 - accuracy: 6.3492e-04 - val_loss: 0.2156 - val_accuracy: 0.0000e+00\n",
            "Epoch 7818/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0428 - accuracy: 6.3492e-04 - val_loss: 0.2155 - val_accuracy: 0.0000e+00\n",
            "Epoch 7819/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0427 - accuracy: 6.3492e-04 - val_loss: 0.2155 - val_accuracy: 0.0000e+00\n",
            "Epoch 7820/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0427 - accuracy: 6.3492e-04 - val_loss: 0.2154 - val_accuracy: 0.0000e+00\n",
            "Epoch 7821/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0427 - accuracy: 6.3492e-04 - val_loss: 0.2154 - val_accuracy: 0.0000e+00\n",
            "Epoch 7822/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0427 - accuracy: 6.3492e-04 - val_loss: 0.2153 - val_accuracy: 0.0000e+00\n",
            "Epoch 7823/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0427 - accuracy: 6.3492e-04 - val_loss: 0.2153 - val_accuracy: 0.0000e+00\n",
            "Epoch 7824/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0427 - accuracy: 6.3492e-04 - val_loss: 0.2152 - val_accuracy: 0.0000e+00\n",
            "Epoch 7825/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0427 - accuracy: 6.3492e-04 - val_loss: 0.2152 - val_accuracy: 0.0000e+00\n",
            "Epoch 7826/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0427 - accuracy: 6.3492e-04 - val_loss: 0.2151 - val_accuracy: 0.0000e+00\n",
            "Epoch 7827/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2151 - val_accuracy: 0.0000e+00\n",
            "Epoch 7828/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2150 - val_accuracy: 0.0000e+00\n",
            "Epoch 7829/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2150 - val_accuracy: 0.0000e+00\n",
            "Epoch 7830/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2149 - val_accuracy: 0.0000e+00\n",
            "Epoch 7831/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2149 - val_accuracy: 0.0000e+00\n",
            "Epoch 7832/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2148 - val_accuracy: 0.0000e+00\n",
            "Epoch 7833/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2148 - val_accuracy: 0.0000e+00\n",
            "Epoch 7834/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2147 - val_accuracy: 0.0000e+00\n",
            "Epoch 7835/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0426 - accuracy: 6.3492e-04 - val_loss: 0.2147 - val_accuracy: 0.0000e+00\n",
            "Epoch 7836/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0425 - accuracy: 6.3492e-04 - val_loss: 0.2146 - val_accuracy: 0.0000e+00\n",
            "Epoch 7837/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0425 - accuracy: 6.3492e-04 - val_loss: 0.2146 - val_accuracy: 0.0000e+00\n",
            "Epoch 7838/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0425 - accuracy: 6.3492e-04 - val_loss: 0.2145 - val_accuracy: 0.0000e+00\n",
            "Epoch 7839/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0425 - accuracy: 6.3492e-04 - val_loss: 0.2145 - val_accuracy: 0.0000e+00\n",
            "Epoch 7840/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0425 - accuracy: 6.3492e-04 - val_loss: 0.2144 - val_accuracy: 0.0000e+00\n",
            "Epoch 7841/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0425 - accuracy: 6.3492e-04 - val_loss: 0.2144 - val_accuracy: 0.0000e+00\n",
            "Epoch 7842/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0425 - accuracy: 6.3492e-04 - val_loss: 0.2143 - val_accuracy: 0.0000e+00\n",
            "Epoch 7843/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0425 - accuracy: 6.3492e-04 - val_loss: 0.2143 - val_accuracy: 0.0000e+00\n",
            "Epoch 7844/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0424 - accuracy: 6.3492e-04 - val_loss: 0.2142 - val_accuracy: 0.0000e+00\n",
            "Epoch 7845/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0424 - accuracy: 6.3492e-04 - val_loss: 0.2142 - val_accuracy: 0.0000e+00\n",
            "Epoch 7846/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0424 - accuracy: 6.3492e-04 - val_loss: 0.2141 - val_accuracy: 0.0000e+00\n",
            "Epoch 7847/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0424 - accuracy: 6.3492e-04 - val_loss: 0.2141 - val_accuracy: 0.0000e+00\n",
            "Epoch 7848/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0424 - accuracy: 6.3492e-04 - val_loss: 0.2140 - val_accuracy: 0.0000e+00\n",
            "Epoch 7849/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0424 - accuracy: 6.3492e-04 - val_loss: 0.2140 - val_accuracy: 0.0000e+00\n",
            "Epoch 7850/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0424 - accuracy: 6.3492e-04 - val_loss: 0.2139 - val_accuracy: 0.0000e+00\n",
            "Epoch 7851/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0424 - accuracy: 6.3492e-04 - val_loss: 0.2139 - val_accuracy: 0.0000e+00\n",
            "Epoch 7852/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0423 - accuracy: 6.3492e-04 - val_loss: 0.2138 - val_accuracy: 0.0000e+00\n",
            "Epoch 7853/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0423 - accuracy: 6.3492e-04 - val_loss: 0.2138 - val_accuracy: 0.0000e+00\n",
            "Epoch 7854/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0423 - accuracy: 6.3492e-04 - val_loss: 0.2137 - val_accuracy: 0.0000e+00\n",
            "Epoch 7855/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0423 - accuracy: 6.3492e-04 - val_loss: 0.2137 - val_accuracy: 0.0000e+00\n",
            "Epoch 7856/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0423 - accuracy: 6.3492e-04 - val_loss: 0.2136 - val_accuracy: 0.0000e+00\n",
            "Epoch 7857/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0423 - accuracy: 6.3492e-04 - val_loss: 0.2136 - val_accuracy: 0.0000e+00\n",
            "Epoch 7858/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0423 - accuracy: 6.3492e-04 - val_loss: 0.2135 - val_accuracy: 0.0000e+00\n",
            "Epoch 7859/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0423 - accuracy: 6.3492e-04 - val_loss: 0.2135 - val_accuracy: 0.0000e+00\n",
            "Epoch 7860/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0422 - accuracy: 6.3492e-04 - val_loss: 0.2134 - val_accuracy: 0.0000e+00\n",
            "Epoch 7861/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0422 - accuracy: 6.3492e-04 - val_loss: 0.2134 - val_accuracy: 0.0000e+00\n",
            "Epoch 7862/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0422 - accuracy: 6.3492e-04 - val_loss: 0.2134 - val_accuracy: 0.0000e+00\n",
            "Epoch 7863/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0422 - accuracy: 6.3492e-04 - val_loss: 0.2133 - val_accuracy: 0.0000e+00\n",
            "Epoch 7864/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0422 - accuracy: 6.3492e-04 - val_loss: 0.2133 - val_accuracy: 0.0000e+00\n",
            "Epoch 7865/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0422 - accuracy: 6.3492e-04 - val_loss: 0.2132 - val_accuracy: 0.0000e+00\n",
            "Epoch 7866/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0422 - accuracy: 6.3492e-04 - val_loss: 0.2132 - val_accuracy: 0.0000e+00\n",
            "Epoch 7867/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0422 - accuracy: 6.3492e-04 - val_loss: 0.2131 - val_accuracy: 0.0000e+00\n",
            "Epoch 7868/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2131 - val_accuracy: 0.0000e+00\n",
            "Epoch 7869/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2130 - val_accuracy: 0.0000e+00\n",
            "Epoch 7870/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2130 - val_accuracy: 0.0000e+00\n",
            "Epoch 7871/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2129 - val_accuracy: 0.0000e+00\n",
            "Epoch 7872/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2129 - val_accuracy: 0.0000e+00\n",
            "Epoch 7873/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2128 - val_accuracy: 0.0000e+00\n",
            "Epoch 7874/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2128 - val_accuracy: 0.0000e+00\n",
            "Epoch 7875/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2127 - val_accuracy: 0.0000e+00\n",
            "Epoch 7876/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0421 - accuracy: 6.3492e-04 - val_loss: 0.2127 - val_accuracy: 0.0000e+00\n",
            "Epoch 7877/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0420 - accuracy: 6.3492e-04 - val_loss: 0.2126 - val_accuracy: 0.0000e+00\n",
            "Epoch 7878/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0420 - accuracy: 6.3492e-04 - val_loss: 0.2126 - val_accuracy: 0.0000e+00\n",
            "Epoch 7879/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0420 - accuracy: 6.3492e-04 - val_loss: 0.2125 - val_accuracy: 0.0000e+00\n",
            "Epoch 7880/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0420 - accuracy: 6.3492e-04 - val_loss: 0.2125 - val_accuracy: 0.0000e+00\n",
            "Epoch 7881/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0420 - accuracy: 6.3492e-04 - val_loss: 0.2124 - val_accuracy: 0.0000e+00\n",
            "Epoch 7882/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0420 - accuracy: 6.3492e-04 - val_loss: 0.2124 - val_accuracy: 0.0000e+00\n",
            "Epoch 7883/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0420 - accuracy: 6.3492e-04 - val_loss: 0.2123 - val_accuracy: 0.0000e+00\n",
            "Epoch 7884/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0420 - accuracy: 6.3492e-04 - val_loss: 0.2123 - val_accuracy: 0.0000e+00\n",
            "Epoch 7885/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0419 - accuracy: 6.3492e-04 - val_loss: 0.2122 - val_accuracy: 0.0000e+00\n",
            "Epoch 7886/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0419 - accuracy: 6.3492e-04 - val_loss: 0.2122 - val_accuracy: 0.0000e+00\n",
            "Epoch 7887/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0419 - accuracy: 6.3492e-04 - val_loss: 0.2121 - val_accuracy: 0.0000e+00\n",
            "Epoch 7888/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0419 - accuracy: 6.3492e-04 - val_loss: 0.2121 - val_accuracy: 0.0000e+00\n",
            "Epoch 7889/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0419 - accuracy: 6.3492e-04 - val_loss: 0.2120 - val_accuracy: 0.0000e+00\n",
            "Epoch 7890/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0419 - accuracy: 6.3492e-04 - val_loss: 0.2120 - val_accuracy: 0.0000e+00\n",
            "Epoch 7891/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0419 - accuracy: 6.3492e-04 - val_loss: 0.2119 - val_accuracy: 0.0000e+00\n",
            "Epoch 7892/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0419 - accuracy: 6.3492e-04 - val_loss: 0.2119 - val_accuracy: 0.0000e+00\n",
            "Epoch 7893/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0418 - accuracy: 6.3492e-04 - val_loss: 0.2118 - val_accuracy: 0.0000e+00\n",
            "Epoch 7894/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0418 - accuracy: 6.3492e-04 - val_loss: 0.2118 - val_accuracy: 0.0000e+00\n",
            "Epoch 7895/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0418 - accuracy: 6.3492e-04 - val_loss: 0.2117 - val_accuracy: 0.0000e+00\n",
            "Epoch 7896/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0418 - accuracy: 6.3492e-04 - val_loss: 0.2117 - val_accuracy: 0.0000e+00\n",
            "Epoch 7897/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0418 - accuracy: 6.3492e-04 - val_loss: 0.2116 - val_accuracy: 0.0000e+00\n",
            "Epoch 7898/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0418 - accuracy: 6.3492e-04 - val_loss: 0.2116 - val_accuracy: 0.0000e+00\n",
            "Epoch 7899/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0418 - accuracy: 6.3492e-04 - val_loss: 0.2115 - val_accuracy: 0.0000e+00\n",
            "Epoch 7900/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0418 - accuracy: 6.3492e-04 - val_loss: 0.2115 - val_accuracy: 0.0000e+00\n",
            "Epoch 7901/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0417 - accuracy: 6.3492e-04 - val_loss: 0.2114 - val_accuracy: 0.0000e+00\n",
            "Epoch 7902/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0417 - accuracy: 6.3492e-04 - val_loss: 0.2114 - val_accuracy: 0.0000e+00\n",
            "Epoch 7903/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0417 - accuracy: 6.3492e-04 - val_loss: 0.2113 - val_accuracy: 0.0000e+00\n",
            "Epoch 7904/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0417 - accuracy: 6.3492e-04 - val_loss: 0.2113 - val_accuracy: 0.0000e+00\n",
            "Epoch 7905/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0417 - accuracy: 6.3492e-04 - val_loss: 0.2112 - val_accuracy: 0.0000e+00\n",
            "Epoch 7906/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0417 - accuracy: 6.3492e-04 - val_loss: 0.2112 - val_accuracy: 0.0000e+00\n",
            "Epoch 7907/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0417 - accuracy: 6.3492e-04 - val_loss: 0.2111 - val_accuracy: 0.0000e+00\n",
            "Epoch 7908/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0417 - accuracy: 6.3492e-04 - val_loss: 0.2111 - val_accuracy: 0.0000e+00\n",
            "Epoch 7909/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0416 - accuracy: 6.3492e-04 - val_loss: 0.2110 - val_accuracy: 0.0000e+00\n",
            "Epoch 7910/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0416 - accuracy: 6.3492e-04 - val_loss: 0.2110 - val_accuracy: 0.0000e+00\n",
            "Epoch 7911/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0416 - accuracy: 6.3492e-04 - val_loss: 0.2109 - val_accuracy: 0.0000e+00\n",
            "Epoch 7912/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0416 - accuracy: 6.3492e-04 - val_loss: 0.2109 - val_accuracy: 0.0000e+00\n",
            "Epoch 7913/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0416 - accuracy: 6.3492e-04 - val_loss: 0.2108 - val_accuracy: 0.0000e+00\n",
            "Epoch 7914/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0416 - accuracy: 6.3492e-04 - val_loss: 0.2108 - val_accuracy: 0.0000e+00\n",
            "Epoch 7915/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0416 - accuracy: 6.3492e-04 - val_loss: 0.2107 - val_accuracy: 0.0000e+00\n",
            "Epoch 7916/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0416 - accuracy: 6.3492e-04 - val_loss: 0.2107 - val_accuracy: 0.0000e+00\n",
            "Epoch 7917/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0415 - accuracy: 6.3492e-04 - val_loss: 0.2106 - val_accuracy: 0.0000e+00\n",
            "Epoch 7918/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0415 - accuracy: 6.3492e-04 - val_loss: 0.2106 - val_accuracy: 0.0000e+00\n",
            "Epoch 7919/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0415 - accuracy: 6.3492e-04 - val_loss: 0.2105 - val_accuracy: 0.0000e+00\n",
            "Epoch 7920/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0415 - accuracy: 6.3492e-04 - val_loss: 0.2105 - val_accuracy: 0.0000e+00\n",
            "Epoch 7921/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0415 - accuracy: 6.3492e-04 - val_loss: 0.2104 - val_accuracy: 0.0000e+00\n",
            "Epoch 7922/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0415 - accuracy: 6.3492e-04 - val_loss: 0.2104 - val_accuracy: 0.0000e+00\n",
            "Epoch 7923/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0415 - accuracy: 6.3492e-04 - val_loss: 0.2103 - val_accuracy: 0.0000e+00\n",
            "Epoch 7924/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0414 - accuracy: 6.3492e-04 - val_loss: 0.2103 - val_accuracy: 0.0000e+00\n",
            "Epoch 7925/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0414 - accuracy: 6.3492e-04 - val_loss: 0.2102 - val_accuracy: 0.0000e+00\n",
            "Epoch 7926/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0414 - accuracy: 6.3492e-04 - val_loss: 0.2102 - val_accuracy: 0.0000e+00\n",
            "Epoch 7927/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0414 - accuracy: 6.3492e-04 - val_loss: 0.2101 - val_accuracy: 0.0000e+00\n",
            "Epoch 7928/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0414 - accuracy: 6.3492e-04 - val_loss: 0.2101 - val_accuracy: 0.0000e+00\n",
            "Epoch 7929/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0414 - accuracy: 6.3492e-04 - val_loss: 0.2100 - val_accuracy: 0.0000e+00\n",
            "Epoch 7930/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0414 - accuracy: 6.3492e-04 - val_loss: 0.2100 - val_accuracy: 0.0000e+00\n",
            "Epoch 7931/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0414 - accuracy: 6.3492e-04 - val_loss: 0.2099 - val_accuracy: 0.0000e+00\n",
            "Epoch 7932/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0413 - accuracy: 6.3492e-04 - val_loss: 0.2098 - val_accuracy: 0.0000e+00\n",
            "Epoch 7933/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0413 - accuracy: 6.3492e-04 - val_loss: 0.2098 - val_accuracy: 0.0000e+00\n",
            "Epoch 7934/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0413 - accuracy: 6.3492e-04 - val_loss: 0.2097 - val_accuracy: 0.0000e+00\n",
            "Epoch 7935/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0413 - accuracy: 6.3492e-04 - val_loss: 0.2097 - val_accuracy: 0.0000e+00\n",
            "Epoch 7936/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0413 - accuracy: 6.3492e-04 - val_loss: 0.2096 - val_accuracy: 0.0000e+00\n",
            "Epoch 7937/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0413 - accuracy: 6.3492e-04 - val_loss: 0.2096 - val_accuracy: 0.0000e+00\n",
            "Epoch 7938/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0413 - accuracy: 6.3492e-04 - val_loss: 0.2095 - val_accuracy: 0.0000e+00\n",
            "Epoch 7939/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0413 - accuracy: 6.3492e-04 - val_loss: 0.2095 - val_accuracy: 0.0000e+00\n",
            "Epoch 7940/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0412 - accuracy: 6.3492e-04 - val_loss: 0.2094 - val_accuracy: 0.0000e+00\n",
            "Epoch 7941/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0412 - accuracy: 6.3492e-04 - val_loss: 0.2094 - val_accuracy: 0.0000e+00\n",
            "Epoch 7942/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0412 - accuracy: 6.3492e-04 - val_loss: 0.2093 - val_accuracy: 0.0000e+00\n",
            "Epoch 7943/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0412 - accuracy: 6.3492e-04 - val_loss: 0.2093 - val_accuracy: 0.0000e+00\n",
            "Epoch 7944/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0412 - accuracy: 6.3492e-04 - val_loss: 0.2092 - val_accuracy: 0.0000e+00\n",
            "Epoch 7945/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0412 - accuracy: 6.3492e-04 - val_loss: 0.2092 - val_accuracy: 0.0000e+00\n",
            "Epoch 7946/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0412 - accuracy: 6.3492e-04 - val_loss: 0.2091 - val_accuracy: 0.0000e+00\n",
            "Epoch 7947/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0412 - accuracy: 6.3492e-04 - val_loss: 0.2091 - val_accuracy: 0.0000e+00\n",
            "Epoch 7948/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0411 - accuracy: 6.3492e-04 - val_loss: 0.2090 - val_accuracy: 0.0000e+00\n",
            "Epoch 7949/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0411 - accuracy: 6.3492e-04 - val_loss: 0.2090 - val_accuracy: 0.0000e+00\n",
            "Epoch 7950/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0411 - accuracy: 6.3492e-04 - val_loss: 0.2089 - val_accuracy: 0.0000e+00\n",
            "Epoch 7951/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0411 - accuracy: 6.3492e-04 - val_loss: 0.2089 - val_accuracy: 0.0000e+00\n",
            "Epoch 7952/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0411 - accuracy: 6.3492e-04 - val_loss: 0.2088 - val_accuracy: 0.0000e+00\n",
            "Epoch 7953/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0411 - accuracy: 6.3492e-04 - val_loss: 0.2088 - val_accuracy: 0.0000e+00\n",
            "Epoch 7954/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0411 - accuracy: 6.3492e-04 - val_loss: 0.2087 - val_accuracy: 0.0000e+00\n",
            "Epoch 7955/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0411 - accuracy: 6.3492e-04 - val_loss: 0.2087 - val_accuracy: 0.0000e+00\n",
            "Epoch 7956/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0410 - accuracy: 6.3492e-04 - val_loss: 0.2086 - val_accuracy: 0.0000e+00\n",
            "Epoch 7957/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0410 - accuracy: 6.3492e-04 - val_loss: 0.2086 - val_accuracy: 0.0000e+00\n",
            "Epoch 7958/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0410 - accuracy: 6.3492e-04 - val_loss: 0.2085 - val_accuracy: 0.0000e+00\n",
            "Epoch 7959/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0410 - accuracy: 6.3492e-04 - val_loss: 0.2084 - val_accuracy: 0.0000e+00\n",
            "Epoch 7960/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0410 - accuracy: 6.3492e-04 - val_loss: 0.2084 - val_accuracy: 0.0000e+00\n",
            "Epoch 7961/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0410 - accuracy: 6.3492e-04 - val_loss: 0.2083 - val_accuracy: 0.0000e+00\n",
            "Epoch 7962/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0410 - accuracy: 6.3492e-04 - val_loss: 0.2083 - val_accuracy: 0.0000e+00\n",
            "Epoch 7963/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0409 - accuracy: 6.3492e-04 - val_loss: 0.2082 - val_accuracy: 0.0000e+00\n",
            "Epoch 7964/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0409 - accuracy: 6.3492e-04 - val_loss: 0.2082 - val_accuracy: 0.0000e+00\n",
            "Epoch 7965/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0409 - accuracy: 6.3492e-04 - val_loss: 0.2081 - val_accuracy: 0.0000e+00\n",
            "Epoch 7966/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0409 - accuracy: 6.3492e-04 - val_loss: 0.2081 - val_accuracy: 0.0000e+00\n",
            "Epoch 7967/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0409 - accuracy: 6.3492e-04 - val_loss: 0.2080 - val_accuracy: 0.0000e+00\n",
            "Epoch 7968/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0409 - accuracy: 6.3492e-04 - val_loss: 0.2080 - val_accuracy: 0.0000e+00\n",
            "Epoch 7969/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0409 - accuracy: 6.3492e-04 - val_loss: 0.2079 - val_accuracy: 0.0000e+00\n",
            "Epoch 7970/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0409 - accuracy: 6.3492e-04 - val_loss: 0.2079 - val_accuracy: 0.0000e+00\n",
            "Epoch 7971/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0408 - accuracy: 6.3492e-04 - val_loss: 0.2078 - val_accuracy: 0.0000e+00\n",
            "Epoch 7972/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0408 - accuracy: 6.3492e-04 - val_loss: 0.2078 - val_accuracy: 0.0000e+00\n",
            "Epoch 7973/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0408 - accuracy: 6.3492e-04 - val_loss: 0.2077 - val_accuracy: 0.0000e+00\n",
            "Epoch 7974/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0408 - accuracy: 6.3492e-04 - val_loss: 0.2077 - val_accuracy: 0.0000e+00\n",
            "Epoch 7975/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0408 - accuracy: 6.3492e-04 - val_loss: 0.2076 - val_accuracy: 0.0000e+00\n",
            "Epoch 7976/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0408 - accuracy: 6.3492e-04 - val_loss: 0.2076 - val_accuracy: 0.0000e+00\n",
            "Epoch 7977/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0408 - accuracy: 6.3492e-04 - val_loss: 0.2075 - val_accuracy: 0.0000e+00\n",
            "Epoch 7978/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0408 - accuracy: 6.3492e-04 - val_loss: 0.2075 - val_accuracy: 0.0000e+00\n",
            "Epoch 7979/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0407 - accuracy: 6.3492e-04 - val_loss: 0.2074 - val_accuracy: 0.0000e+00\n",
            "Epoch 7980/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0407 - accuracy: 6.3492e-04 - val_loss: 0.2074 - val_accuracy: 0.0000e+00\n",
            "Epoch 7981/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0407 - accuracy: 6.3492e-04 - val_loss: 0.2073 - val_accuracy: 0.0000e+00\n",
            "Epoch 7982/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0407 - accuracy: 6.3492e-04 - val_loss: 0.2073 - val_accuracy: 0.0000e+00\n",
            "Epoch 7983/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0407 - accuracy: 6.3492e-04 - val_loss: 0.2072 - val_accuracy: 0.0000e+00\n",
            "Epoch 7984/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0407 - accuracy: 6.3492e-04 - val_loss: 0.2072 - val_accuracy: 0.0000e+00\n",
            "Epoch 7985/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0407 - accuracy: 6.3492e-04 - val_loss: 0.2071 - val_accuracy: 0.0000e+00\n",
            "Epoch 7986/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0407 - accuracy: 6.3492e-04 - val_loss: 0.2070 - val_accuracy: 0.0000e+00\n",
            "Epoch 7987/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0406 - accuracy: 6.3492e-04 - val_loss: 0.2070 - val_accuracy: 0.0000e+00\n",
            "Epoch 7988/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0406 - accuracy: 6.3492e-04 - val_loss: 0.2069 - val_accuracy: 0.0000e+00\n",
            "Epoch 7989/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0406 - accuracy: 6.3492e-04 - val_loss: 0.2069 - val_accuracy: 0.0000e+00\n",
            "Epoch 7990/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0406 - accuracy: 6.3492e-04 - val_loss: 0.2068 - val_accuracy: 0.0000e+00\n",
            "Epoch 7991/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0406 - accuracy: 6.3492e-04 - val_loss: 0.2068 - val_accuracy: 0.0000e+00\n",
            "Epoch 7992/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0406 - accuracy: 6.3492e-04 - val_loss: 0.2067 - val_accuracy: 0.0000e+00\n",
            "Epoch 7993/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0406 - accuracy: 6.3492e-04 - val_loss: 0.2067 - val_accuracy: 0.0000e+00\n",
            "Epoch 7994/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0405 - accuracy: 6.3492e-04 - val_loss: 0.2066 - val_accuracy: 0.0000e+00\n",
            "Epoch 7995/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0405 - accuracy: 6.3492e-04 - val_loss: 0.2066 - val_accuracy: 0.0000e+00\n",
            "Epoch 7996/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0405 - accuracy: 6.3492e-04 - val_loss: 0.2065 - val_accuracy: 0.0000e+00\n",
            "Epoch 7997/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0405 - accuracy: 6.3492e-04 - val_loss: 0.2065 - val_accuracy: 0.0000e+00\n",
            "Epoch 7998/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0405 - accuracy: 6.3492e-04 - val_loss: 0.2064 - val_accuracy: 0.0000e+00\n",
            "Epoch 7999/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0405 - accuracy: 6.3492e-04 - val_loss: 0.2064 - val_accuracy: 0.0000e+00\n",
            "Epoch 8000/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0405 - accuracy: 6.3492e-04 - val_loss: 0.2063 - val_accuracy: 0.0000e+00\n",
            "Epoch 8001/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0405 - accuracy: 6.3492e-04 - val_loss: 0.2063 - val_accuracy: 0.0000e+00\n",
            "Epoch 8002/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0404 - accuracy: 6.3492e-04 - val_loss: 0.2062 - val_accuracy: 0.0000e+00\n",
            "Epoch 8003/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 6.3492e-04 - val_loss: 0.2061 - val_accuracy: 0.0000e+00\n",
            "Epoch 8004/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 6.3492e-04 - val_loss: 0.2061 - val_accuracy: 0.0000e+00\n",
            "Epoch 8005/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 6.3492e-04 - val_loss: 0.2060 - val_accuracy: 0.0000e+00\n",
            "Epoch 8006/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0404 - accuracy: 6.3492e-04 - val_loss: 0.2060 - val_accuracy: 0.0000e+00\n",
            "Epoch 8007/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0404 - accuracy: 6.3492e-04 - val_loss: 0.2059 - val_accuracy: 0.0000e+00\n",
            "Epoch 8008/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0404 - accuracy: 6.3492e-04 - val_loss: 0.2059 - val_accuracy: 0.0000e+00\n",
            "Epoch 8009/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0403 - accuracy: 6.3492e-04 - val_loss: 0.2058 - val_accuracy: 0.0000e+00\n",
            "Epoch 8010/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0403 - accuracy: 6.3492e-04 - val_loss: 0.2058 - val_accuracy: 0.0000e+00\n",
            "Epoch 8011/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0403 - accuracy: 6.3492e-04 - val_loss: 0.2057 - val_accuracy: 0.0000e+00\n",
            "Epoch 8012/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0403 - accuracy: 6.3492e-04 - val_loss: 0.2057 - val_accuracy: 0.0000e+00\n",
            "Epoch 8013/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0403 - accuracy: 6.3492e-04 - val_loss: 0.2056 - val_accuracy: 0.0000e+00\n",
            "Epoch 8014/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0403 - accuracy: 6.3492e-04 - val_loss: 0.2056 - val_accuracy: 0.0000e+00\n",
            "Epoch 8015/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0403 - accuracy: 6.3492e-04 - val_loss: 0.2055 - val_accuracy: 0.0000e+00\n",
            "Epoch 8016/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0403 - accuracy: 6.3492e-04 - val_loss: 0.2055 - val_accuracy: 0.0000e+00\n",
            "Epoch 8017/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0402 - accuracy: 6.3492e-04 - val_loss: 0.2054 - val_accuracy: 0.0000e+00\n",
            "Epoch 8018/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0402 - accuracy: 6.3492e-04 - val_loss: 0.2054 - val_accuracy: 0.0000e+00\n",
            "Epoch 8019/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0402 - accuracy: 6.3492e-04 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
            "Epoch 8020/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0402 - accuracy: 6.3492e-04 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
            "Epoch 8021/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0402 - accuracy: 6.3492e-04 - val_loss: 0.2052 - val_accuracy: 0.0000e+00\n",
            "Epoch 8022/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0402 - accuracy: 6.3492e-04 - val_loss: 0.2052 - val_accuracy: 0.0000e+00\n",
            "Epoch 8023/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0402 - accuracy: 6.3492e-04 - val_loss: 0.2051 - val_accuracy: 0.0000e+00\n",
            "Epoch 8024/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0402 - accuracy: 6.3492e-04 - val_loss: 0.2051 - val_accuracy: 0.0000e+00\n",
            "Epoch 8025/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0401 - accuracy: 6.3492e-04 - val_loss: 0.2050 - val_accuracy: 0.0000e+00\n",
            "Epoch 8026/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0401 - accuracy: 6.3492e-04 - val_loss: 0.2050 - val_accuracy: 0.0000e+00\n",
            "Epoch 8027/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0401 - accuracy: 6.3492e-04 - val_loss: 0.2049 - val_accuracy: 0.0000e+00\n",
            "Epoch 8028/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0401 - accuracy: 6.3492e-04 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 8029/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0401 - accuracy: 6.3492e-04 - val_loss: 0.2048 - val_accuracy: 0.0000e+00\n",
            "Epoch 8030/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0401 - accuracy: 6.3492e-04 - val_loss: 0.2047 - val_accuracy: 0.0000e+00\n",
            "Epoch 8031/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0401 - accuracy: 6.3492e-04 - val_loss: 0.2047 - val_accuracy: 0.0000e+00\n",
            "Epoch 8032/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0400 - accuracy: 6.3492e-04 - val_loss: 0.2046 - val_accuracy: 0.0000e+00\n",
            "Epoch 8033/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0400 - accuracy: 6.3492e-04 - val_loss: 0.2046 - val_accuracy: 0.0000e+00\n",
            "Epoch 8034/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0400 - accuracy: 6.3492e-04 - val_loss: 0.2045 - val_accuracy: 0.0000e+00\n",
            "Epoch 8035/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0400 - accuracy: 6.3492e-04 - val_loss: 0.2045 - val_accuracy: 0.0000e+00\n",
            "Epoch 8036/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0400 - accuracy: 6.3492e-04 - val_loss: 0.2044 - val_accuracy: 0.0000e+00\n",
            "Epoch 8037/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0400 - accuracy: 6.3492e-04 - val_loss: 0.2044 - val_accuracy: 0.0000e+00\n",
            "Epoch 8038/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0400 - accuracy: 6.3492e-04 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 8039/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0399 - accuracy: 6.3492e-04 - val_loss: 0.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 8040/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0399 - accuracy: 6.3492e-04 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 8041/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0399 - accuracy: 6.3492e-04 - val_loss: 0.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 8042/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0399 - accuracy: 6.3492e-04 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 8043/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0399 - accuracy: 6.3492e-04 - val_loss: 0.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 8044/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0399 - accuracy: 6.3492e-04 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 8045/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0399 - accuracy: 6.3492e-04 - val_loss: 0.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 8046/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0399 - accuracy: 6.3492e-04 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 8047/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0398 - accuracy: 6.3492e-04 - val_loss: 0.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 8048/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0398 - accuracy: 6.3492e-04 - val_loss: 0.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 8049/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0398 - accuracy: 6.3492e-04 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 8050/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0398 - accuracy: 6.3492e-04 - val_loss: 0.2037 - val_accuracy: 0.0000e+00\n",
            "Epoch 8051/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0398 - accuracy: 6.3492e-04 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 8052/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0398 - accuracy: 6.3492e-04 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
            "Epoch 8053/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0398 - accuracy: 6.3492e-04 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 8054/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0397 - accuracy: 6.3492e-04 - val_loss: 0.2035 - val_accuracy: 0.0000e+00\n",
            "Epoch 8055/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0397 - accuracy: 6.3492e-04 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 8056/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0397 - accuracy: 6.3492e-04 - val_loss: 0.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 8057/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0397 - accuracy: 6.3492e-04 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 8058/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0397 - accuracy: 6.3492e-04 - val_loss: 0.2033 - val_accuracy: 0.0000e+00\n",
            "Epoch 8059/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0397 - accuracy: 6.3492e-04 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 8060/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0397 - accuracy: 6.3492e-04 - val_loss: 0.2032 - val_accuracy: 0.0000e+00\n",
            "Epoch 8061/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0397 - accuracy: 6.3492e-04 - val_loss: 0.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 8062/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0396 - accuracy: 6.3492e-04 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 8063/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0396 - accuracy: 6.3492e-04 - val_loss: 0.2030 - val_accuracy: 0.0000e+00\n",
            "Epoch 8064/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0396 - accuracy: 6.3492e-04 - val_loss: 0.2029 - val_accuracy: 0.0000e+00\n",
            "Epoch 8065/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0396 - accuracy: 6.3492e-04 - val_loss: 0.2029 - val_accuracy: 0.0000e+00\n",
            "Epoch 8066/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0396 - accuracy: 6.3492e-04 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 8067/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0396 - accuracy: 6.3492e-04 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 8068/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0396 - accuracy: 6.3492e-04 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 8069/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0395 - accuracy: 6.3492e-04 - val_loss: 0.2027 - val_accuracy: 0.0000e+00\n",
            "Epoch 8070/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0395 - accuracy: 6.3492e-04 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 8071/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0395 - accuracy: 6.3492e-04 - val_loss: 0.2026 - val_accuracy: 0.0000e+00\n",
            "Epoch 8072/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0395 - accuracy: 6.3492e-04 - val_loss: 0.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 8073/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0395 - accuracy: 6.3492e-04 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 8074/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0395 - accuracy: 6.3492e-04 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 8075/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0395 - accuracy: 6.3492e-04 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 8076/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0395 - accuracy: 6.3492e-04 - val_loss: 0.2023 - val_accuracy: 0.0000e+00\n",
            "Epoch 8077/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0394 - accuracy: 6.3492e-04 - val_loss: 0.2022 - val_accuracy: 0.0000e+00\n",
            "Epoch 8078/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0394 - accuracy: 6.3492e-04 - val_loss: 0.2022 - val_accuracy: 0.0000e+00\n",
            "Epoch 8079/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0394 - accuracy: 6.3492e-04 - val_loss: 0.2021 - val_accuracy: 0.0000e+00\n",
            "Epoch 8080/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0394 - accuracy: 6.3492e-04 - val_loss: 0.2021 - val_accuracy: 0.0000e+00\n",
            "Epoch 8081/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0394 - accuracy: 6.3492e-04 - val_loss: 0.2020 - val_accuracy: 0.0000e+00\n",
            "Epoch 8082/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0394 - accuracy: 6.3492e-04 - val_loss: 0.2020 - val_accuracy: 0.0000e+00\n",
            "Epoch 8083/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0394 - accuracy: 6.3492e-04 - val_loss: 0.2019 - val_accuracy: 0.0000e+00\n",
            "Epoch 8084/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0393 - accuracy: 6.3492e-04 - val_loss: 0.2019 - val_accuracy: 0.0000e+00\n",
            "Epoch 8085/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0393 - accuracy: 6.3492e-04 - val_loss: 0.2018 - val_accuracy: 0.0000e+00\n",
            "Epoch 8086/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0393 - accuracy: 6.3492e-04 - val_loss: 0.2018 - val_accuracy: 0.0000e+00\n",
            "Epoch 8087/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0393 - accuracy: 6.3492e-04 - val_loss: 0.2017 - val_accuracy: 0.0000e+00\n",
            "Epoch 8088/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0393 - accuracy: 6.3492e-04 - val_loss: 0.2017 - val_accuracy: 0.0000e+00\n",
            "Epoch 8089/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0393 - accuracy: 6.3492e-04 - val_loss: 0.2016 - val_accuracy: 0.0000e+00\n",
            "Epoch 8090/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0393 - accuracy: 6.3492e-04 - val_loss: 0.2016 - val_accuracy: 0.0000e+00\n",
            "Epoch 8091/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0392 - accuracy: 6.3492e-04 - val_loss: 0.2015 - val_accuracy: 0.0000e+00\n",
            "Epoch 8092/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0392 - accuracy: 6.3492e-04 - val_loss: 0.2014 - val_accuracy: 0.0000e+00\n",
            "Epoch 8093/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0392 - accuracy: 6.3492e-04 - val_loss: 0.2014 - val_accuracy: 0.0000e+00\n",
            "Epoch 8094/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0392 - accuracy: 6.3492e-04 - val_loss: 0.2013 - val_accuracy: 0.0000e+00\n",
            "Epoch 8095/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0392 - accuracy: 6.3492e-04 - val_loss: 0.2013 - val_accuracy: 0.0000e+00\n",
            "Epoch 8096/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0392 - accuracy: 6.3492e-04 - val_loss: 0.2012 - val_accuracy: 0.0000e+00\n",
            "Epoch 8097/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0392 - accuracy: 6.3492e-04 - val_loss: 0.2012 - val_accuracy: 0.0000e+00\n",
            "Epoch 8098/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0392 - accuracy: 6.3492e-04 - val_loss: 0.2011 - val_accuracy: 0.0000e+00\n",
            "Epoch 8099/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0391 - accuracy: 6.3492e-04 - val_loss: 0.2011 - val_accuracy: 0.0000e+00\n",
            "Epoch 8100/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0391 - accuracy: 6.3492e-04 - val_loss: 0.2010 - val_accuracy: 0.0000e+00\n",
            "Epoch 8101/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0391 - accuracy: 6.3492e-04 - val_loss: 0.2009 - val_accuracy: 0.0000e+00\n",
            "Epoch 8102/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0391 - accuracy: 6.3492e-04 - val_loss: 0.2009 - val_accuracy: 0.0000e+00\n",
            "Epoch 8103/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0391 - accuracy: 6.3492e-04 - val_loss: 0.2008 - val_accuracy: 0.0000e+00\n",
            "Epoch 8104/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0391 - accuracy: 6.3492e-04 - val_loss: 0.2008 - val_accuracy: 0.0000e+00\n",
            "Epoch 8105/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0391 - accuracy: 6.3492e-04 - val_loss: 0.2007 - val_accuracy: 0.0000e+00\n",
            "Epoch 8106/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0390 - accuracy: 6.3492e-04 - val_loss: 0.2007 - val_accuracy: 0.0000e+00\n",
            "Epoch 8107/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0390 - accuracy: 6.3492e-04 - val_loss: 0.2006 - val_accuracy: 0.0000e+00\n",
            "Epoch 8108/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0390 - accuracy: 6.3492e-04 - val_loss: 0.2006 - val_accuracy: 0.0000e+00\n",
            "Epoch 8109/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0390 - accuracy: 6.3492e-04 - val_loss: 0.2005 - val_accuracy: 0.0000e+00\n",
            "Epoch 8110/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0390 - accuracy: 6.3492e-04 - val_loss: 0.2005 - val_accuracy: 0.0000e+00\n",
            "Epoch 8111/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0390 - accuracy: 6.3492e-04 - val_loss: 0.2004 - val_accuracy: 0.0000e+00\n",
            "Epoch 8112/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0390 - accuracy: 6.3492e-04 - val_loss: 0.2003 - val_accuracy: 0.0000e+00\n",
            "Epoch 8113/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0389 - accuracy: 6.3492e-04 - val_loss: 0.2003 - val_accuracy: 0.0000e+00\n",
            "Epoch 8114/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0389 - accuracy: 6.3492e-04 - val_loss: 0.2002 - val_accuracy: 0.0000e+00\n",
            "Epoch 8115/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0389 - accuracy: 6.3492e-04 - val_loss: 0.2002 - val_accuracy: 0.0000e+00\n",
            "Epoch 8116/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0389 - accuracy: 6.3492e-04 - val_loss: 0.2001 - val_accuracy: 0.0000e+00\n",
            "Epoch 8117/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0389 - accuracy: 6.3492e-04 - val_loss: 0.2001 - val_accuracy: 0.0000e+00\n",
            "Epoch 8118/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0389 - accuracy: 6.3492e-04 - val_loss: 0.2000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8119/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0389 - accuracy: 6.3492e-04 - val_loss: 0.2000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8120/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0388 - accuracy: 6.3492e-04 - val_loss: 0.1999 - val_accuracy: 0.0000e+00\n",
            "Epoch 8121/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0388 - accuracy: 6.3492e-04 - val_loss: 0.1998 - val_accuracy: 0.0000e+00\n",
            "Epoch 8122/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0388 - accuracy: 6.3492e-04 - val_loss: 0.1998 - val_accuracy: 0.0000e+00\n",
            "Epoch 8123/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0388 - accuracy: 6.3492e-04 - val_loss: 0.1997 - val_accuracy: 0.0000e+00\n",
            "Epoch 8124/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0388 - accuracy: 6.3492e-04 - val_loss: 0.1997 - val_accuracy: 0.0000e+00\n",
            "Epoch 8125/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0388 - accuracy: 6.3492e-04 - val_loss: 0.1996 - val_accuracy: 0.0000e+00\n",
            "Epoch 8126/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0388 - accuracy: 6.3492e-04 - val_loss: 0.1996 - val_accuracy: 0.0000e+00\n",
            "Epoch 8127/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0388 - accuracy: 6.3492e-04 - val_loss: 0.1995 - val_accuracy: 0.0000e+00\n",
            "Epoch 8128/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 6.3492e-04 - val_loss: 0.1995 - val_accuracy: 0.0000e+00\n",
            "Epoch 8129/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 6.3492e-04 - val_loss: 0.1994 - val_accuracy: 0.0000e+00\n",
            "Epoch 8130/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 6.3492e-04 - val_loss: 0.1994 - val_accuracy: 0.0000e+00\n",
            "Epoch 8131/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0387 - accuracy: 6.3492e-04 - val_loss: 0.1993 - val_accuracy: 0.0000e+00\n",
            "Epoch 8132/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 6.3492e-04 - val_loss: 0.1992 - val_accuracy: 0.0000e+00\n",
            "Epoch 8133/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0387 - accuracy: 6.3492e-04 - val_loss: 0.1992 - val_accuracy: 0.0000e+00\n",
            "Epoch 8134/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 6.3492e-04 - val_loss: 0.1991 - val_accuracy: 0.0000e+00\n",
            "Epoch 8135/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0386 - accuracy: 6.3492e-04 - val_loss: 0.1991 - val_accuracy: 0.0000e+00\n",
            "Epoch 8136/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0386 - accuracy: 6.3492e-04 - val_loss: 0.1990 - val_accuracy: 0.0000e+00\n",
            "Epoch 8137/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0386 - accuracy: 6.3492e-04 - val_loss: 0.1990 - val_accuracy: 0.0000e+00\n",
            "Epoch 8138/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0386 - accuracy: 6.3492e-04 - val_loss: 0.1989 - val_accuracy: 0.0000e+00\n",
            "Epoch 8139/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0386 - accuracy: 6.3492e-04 - val_loss: 0.1989 - val_accuracy: 0.0000e+00\n",
            "Epoch 8140/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0386 - accuracy: 6.3492e-04 - val_loss: 0.1988 - val_accuracy: 0.0000e+00\n",
            "Epoch 8141/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0386 - accuracy: 6.3492e-04 - val_loss: 0.1988 - val_accuracy: 0.0000e+00\n",
            "Epoch 8142/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0385 - accuracy: 6.3492e-04 - val_loss: 0.1987 - val_accuracy: 0.0000e+00\n",
            "Epoch 8143/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0385 - accuracy: 6.3492e-04 - val_loss: 0.1986 - val_accuracy: 0.0000e+00\n",
            "Epoch 8144/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0385 - accuracy: 6.3492e-04 - val_loss: 0.1986 - val_accuracy: 0.0000e+00\n",
            "Epoch 8145/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0385 - accuracy: 6.3492e-04 - val_loss: 0.1985 - val_accuracy: 0.0000e+00\n",
            "Epoch 8146/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0385 - accuracy: 6.3492e-04 - val_loss: 0.1985 - val_accuracy: 0.0000e+00\n",
            "Epoch 8147/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0385 - accuracy: 6.3492e-04 - val_loss: 0.1984 - val_accuracy: 0.0000e+00\n",
            "Epoch 8148/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0385 - accuracy: 6.3492e-04 - val_loss: 0.1984 - val_accuracy: 0.0000e+00\n",
            "Epoch 8149/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0384 - accuracy: 6.3492e-04 - val_loss: 0.1983 - val_accuracy: 0.0000e+00\n",
            "Epoch 8150/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0384 - accuracy: 6.3492e-04 - val_loss: 0.1983 - val_accuracy: 0.0000e+00\n",
            "Epoch 8151/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0384 - accuracy: 6.3492e-04 - val_loss: 0.1982 - val_accuracy: 0.0000e+00\n",
            "Epoch 8152/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0384 - accuracy: 6.3492e-04 - val_loss: 0.1982 - val_accuracy: 0.0000e+00\n",
            "Epoch 8153/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0384 - accuracy: 6.3492e-04 - val_loss: 0.1981 - val_accuracy: 0.0000e+00\n",
            "Epoch 8154/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0384 - accuracy: 6.3492e-04 - val_loss: 0.1980 - val_accuracy: 0.0000e+00\n",
            "Epoch 8155/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0384 - accuracy: 6.3492e-04 - val_loss: 0.1980 - val_accuracy: 0.0000e+00\n",
            "Epoch 8156/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0383 - accuracy: 6.3492e-04 - val_loss: 0.1979 - val_accuracy: 0.0000e+00\n",
            "Epoch 8157/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0383 - accuracy: 6.3492e-04 - val_loss: 0.1979 - val_accuracy: 0.0000e+00\n",
            "Epoch 8158/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0383 - accuracy: 6.3492e-04 - val_loss: 0.1978 - val_accuracy: 0.0000e+00\n",
            "Epoch 8159/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0383 - accuracy: 6.3492e-04 - val_loss: 0.1978 - val_accuracy: 0.0000e+00\n",
            "Epoch 8160/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0383 - accuracy: 6.3492e-04 - val_loss: 0.1977 - val_accuracy: 0.0000e+00\n",
            "Epoch 8161/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0383 - accuracy: 6.3492e-04 - val_loss: 0.1976 - val_accuracy: 0.0000e+00\n",
            "Epoch 8162/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0383 - accuracy: 6.3492e-04 - val_loss: 0.1976 - val_accuracy: 0.0000e+00\n",
            "Epoch 8163/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0382 - accuracy: 6.3492e-04 - val_loss: 0.1975 - val_accuracy: 0.0000e+00\n",
            "Epoch 8164/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0382 - accuracy: 6.3492e-04 - val_loss: 0.1975 - val_accuracy: 0.0000e+00\n",
            "Epoch 8165/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0382 - accuracy: 6.3492e-04 - val_loss: 0.1974 - val_accuracy: 0.0000e+00\n",
            "Epoch 8166/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0382 - accuracy: 6.3492e-04 - val_loss: 0.1974 - val_accuracy: 0.0000e+00\n",
            "Epoch 8167/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0382 - accuracy: 6.3492e-04 - val_loss: 0.1973 - val_accuracy: 0.0000e+00\n",
            "Epoch 8168/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0382 - accuracy: 6.3492e-04 - val_loss: 0.1972 - val_accuracy: 0.0000e+00\n",
            "Epoch 8169/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0382 - accuracy: 6.3492e-04 - val_loss: 0.1972 - val_accuracy: 0.0000e+00\n",
            "Epoch 8170/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0381 - accuracy: 6.3492e-04 - val_loss: 0.1971 - val_accuracy: 0.0000e+00\n",
            "Epoch 8171/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0381 - accuracy: 6.3492e-04 - val_loss: 0.1971 - val_accuracy: 0.0000e+00\n",
            "Epoch 8172/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0381 - accuracy: 6.3492e-04 - val_loss: 0.1970 - val_accuracy: 0.0000e+00\n",
            "Epoch 8173/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0381 - accuracy: 6.3492e-04 - val_loss: 0.1970 - val_accuracy: 0.0000e+00\n",
            "Epoch 8174/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0381 - accuracy: 6.3492e-04 - val_loss: 0.1969 - val_accuracy: 0.0000e+00\n",
            "Epoch 8175/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0381 - accuracy: 6.3492e-04 - val_loss: 0.1968 - val_accuracy: 0.0000e+00\n",
            "Epoch 8176/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0381 - accuracy: 6.3492e-04 - val_loss: 0.1968 - val_accuracy: 0.0000e+00\n",
            "Epoch 8177/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0380 - accuracy: 6.3492e-04 - val_loss: 0.1967 - val_accuracy: 0.0000e+00\n",
            "Epoch 8178/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0380 - accuracy: 6.3492e-04 - val_loss: 0.1967 - val_accuracy: 0.0000e+00\n",
            "Epoch 8179/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0380 - accuracy: 6.3492e-04 - val_loss: 0.1966 - val_accuracy: 0.0000e+00\n",
            "Epoch 8180/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0380 - accuracy: 6.3492e-04 - val_loss: 0.1966 - val_accuracy: 0.0000e+00\n",
            "Epoch 8181/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0380 - accuracy: 6.3492e-04 - val_loss: 0.1965 - val_accuracy: 0.0000e+00\n",
            "Epoch 8182/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0380 - accuracy: 6.3492e-04 - val_loss: 0.1964 - val_accuracy: 0.0000e+00\n",
            "Epoch 8183/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0380 - accuracy: 6.3492e-04 - val_loss: 0.1964 - val_accuracy: 0.0000e+00\n",
            "Epoch 8184/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0380 - accuracy: 6.3492e-04 - val_loss: 0.1964 - val_accuracy: 0.0000e+00\n",
            "Epoch 8185/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0379 - accuracy: 6.3492e-04 - val_loss: 0.1963 - val_accuracy: 0.0000e+00\n",
            "Epoch 8186/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0379 - accuracy: 6.3492e-04 - val_loss: 0.1963 - val_accuracy: 0.0000e+00\n",
            "Epoch 8187/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0379 - accuracy: 6.3492e-04 - val_loss: 0.1962 - val_accuracy: 0.0000e+00\n",
            "Epoch 8188/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0379 - accuracy: 6.3492e-04 - val_loss: 0.1962 - val_accuracy: 0.0000e+00\n",
            "Epoch 8189/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0379 - accuracy: 6.3492e-04 - val_loss: 0.1961 - val_accuracy: 0.0000e+00\n",
            "Epoch 8190/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0379 - accuracy: 6.3492e-04 - val_loss: 0.1961 - val_accuracy: 0.0000e+00\n",
            "Epoch 8191/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0379 - accuracy: 6.3492e-04 - val_loss: 0.1960 - val_accuracy: 0.0000e+00\n",
            "Epoch 8192/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0378 - accuracy: 6.3492e-04 - val_loss: 0.1960 - val_accuracy: 0.0000e+00\n",
            "Epoch 8193/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0378 - accuracy: 6.3492e-04 - val_loss: 0.1959 - val_accuracy: 0.0000e+00\n",
            "Epoch 8194/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0378 - accuracy: 6.3492e-04 - val_loss: 0.1958 - val_accuracy: 0.0000e+00\n",
            "Epoch 8195/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0378 - accuracy: 6.3492e-04 - val_loss: 0.1958 - val_accuracy: 0.0000e+00\n",
            "Epoch 8196/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0378 - accuracy: 6.3492e-04 - val_loss: 0.1957 - val_accuracy: 0.0000e+00\n",
            "Epoch 8197/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0378 - accuracy: 6.3492e-04 - val_loss: 0.1957 - val_accuracy: 0.0000e+00\n",
            "Epoch 8198/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0378 - accuracy: 6.3492e-04 - val_loss: 0.1956 - val_accuracy: 0.0000e+00\n",
            "Epoch 8199/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0377 - accuracy: 6.3492e-04 - val_loss: 0.1956 - val_accuracy: 0.0000e+00\n",
            "Epoch 8200/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0377 - accuracy: 6.3492e-04 - val_loss: 0.1956 - val_accuracy: 0.0000e+00\n",
            "Epoch 8201/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0377 - accuracy: 6.3492e-04 - val_loss: 0.1955 - val_accuracy: 0.0000e+00\n",
            "Epoch 8202/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0377 - accuracy: 6.3492e-04 - val_loss: 0.1955 - val_accuracy: 0.0000e+00\n",
            "Epoch 8203/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0377 - accuracy: 6.3492e-04 - val_loss: 0.1954 - val_accuracy: 0.0000e+00\n",
            "Epoch 8204/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0377 - accuracy: 6.3492e-04 - val_loss: 0.1954 - val_accuracy: 0.0000e+00\n",
            "Epoch 8205/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0377 - accuracy: 6.3492e-04 - val_loss: 0.1953 - val_accuracy: 0.0000e+00\n",
            "Epoch 8206/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0376 - accuracy: 6.3492e-04 - val_loss: 0.1953 - val_accuracy: 0.0000e+00\n",
            "Epoch 8207/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0376 - accuracy: 6.3492e-04 - val_loss: 0.1952 - val_accuracy: 0.0000e+00\n",
            "Epoch 8208/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0376 - accuracy: 6.3492e-04 - val_loss: 0.1952 - val_accuracy: 0.0000e+00\n",
            "Epoch 8209/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0376 - accuracy: 6.3492e-04 - val_loss: 0.1952 - val_accuracy: 0.0000e+00\n",
            "Epoch 8210/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0376 - accuracy: 6.3492e-04 - val_loss: 0.1951 - val_accuracy: 0.0000e+00\n",
            "Epoch 8211/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0376 - accuracy: 6.3492e-04 - val_loss: 0.1951 - val_accuracy: 0.0000e+00\n",
            "Epoch 8212/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0376 - accuracy: 6.3492e-04 - val_loss: 0.1950 - val_accuracy: 0.0000e+00\n",
            "Epoch 8213/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0375 - accuracy: 6.3492e-04 - val_loss: 0.1950 - val_accuracy: 0.0000e+00\n",
            "Epoch 8214/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0375 - accuracy: 6.3492e-04 - val_loss: 0.1949 - val_accuracy: 0.0000e+00\n",
            "Epoch 8215/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0375 - accuracy: 6.3492e-04 - val_loss: 0.1949 - val_accuracy: 0.0000e+00\n",
            "Epoch 8216/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0375 - accuracy: 6.3492e-04 - val_loss: 0.1948 - val_accuracy: 0.0000e+00\n",
            "Epoch 8217/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0375 - accuracy: 6.3492e-04 - val_loss: 0.1948 - val_accuracy: 0.0000e+00\n",
            "Epoch 8218/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0375 - accuracy: 6.3492e-04 - val_loss: 0.1947 - val_accuracy: 0.0000e+00\n",
            "Epoch 8219/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0375 - accuracy: 6.3492e-04 - val_loss: 0.1947 - val_accuracy: 0.0000e+00\n",
            "Epoch 8220/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0374 - accuracy: 6.3492e-04 - val_loss: 0.1946 - val_accuracy: 0.0000e+00\n",
            "Epoch 8221/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0374 - accuracy: 6.3492e-04 - val_loss: 0.1946 - val_accuracy: 0.0000e+00\n",
            "Epoch 8222/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0374 - accuracy: 6.3492e-04 - val_loss: 0.1945 - val_accuracy: 0.0000e+00\n",
            "Epoch 8223/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0374 - accuracy: 6.3492e-04 - val_loss: 0.1945 - val_accuracy: 0.0000e+00\n",
            "Epoch 8224/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0374 - accuracy: 6.3492e-04 - val_loss: 0.1944 - val_accuracy: 0.0000e+00\n",
            "Epoch 8225/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0374 - accuracy: 6.3492e-04 - val_loss: 0.1944 - val_accuracy: 0.0000e+00\n",
            "Epoch 8226/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0374 - accuracy: 6.3492e-04 - val_loss: 0.1944 - val_accuracy: 0.0000e+00\n",
            "Epoch 8227/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0373 - accuracy: 6.3492e-04 - val_loss: 0.1943 - val_accuracy: 0.0000e+00\n",
            "Epoch 8228/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0373 - accuracy: 6.3492e-04 - val_loss: 0.1943 - val_accuracy: 0.0000e+00\n",
            "Epoch 8229/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0373 - accuracy: 6.3492e-04 - val_loss: 0.1942 - val_accuracy: 0.0000e+00\n",
            "Epoch 8230/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0373 - accuracy: 6.3492e-04 - val_loss: 0.1941 - val_accuracy: 0.0000e+00\n",
            "Epoch 8231/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0373 - accuracy: 6.3492e-04 - val_loss: 0.1941 - val_accuracy: 0.0000e+00\n",
            "Epoch 8232/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0373 - accuracy: 6.3492e-04 - val_loss: 0.1941 - val_accuracy: 0.0000e+00\n",
            "Epoch 8233/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0373 - accuracy: 6.3492e-04 - val_loss: 0.1940 - val_accuracy: 0.0000e+00\n",
            "Epoch 8234/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0372 - accuracy: 6.3492e-04 - val_loss: 0.1940 - val_accuracy: 0.0000e+00\n",
            "Epoch 8235/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0372 - accuracy: 6.3492e-04 - val_loss: 0.1939 - val_accuracy: 0.0000e+00\n",
            "Epoch 8236/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0372 - accuracy: 6.3492e-04 - val_loss: 0.1939 - val_accuracy: 0.0000e+00\n",
            "Epoch 8237/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0372 - accuracy: 6.3492e-04 - val_loss: 0.1939 - val_accuracy: 0.0000e+00\n",
            "Epoch 8238/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0372 - accuracy: 6.3492e-04 - val_loss: 0.1938 - val_accuracy: 0.0000e+00\n",
            "Epoch 8239/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0372 - accuracy: 6.3492e-04 - val_loss: 0.1938 - val_accuracy: 0.0000e+00\n",
            "Epoch 8240/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0372 - accuracy: 6.3492e-04 - val_loss: 0.1937 - val_accuracy: 0.0000e+00\n",
            "Epoch 8241/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0372 - accuracy: 6.3492e-04 - val_loss: 0.1937 - val_accuracy: 0.0000e+00\n",
            "Epoch 8242/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0371 - accuracy: 6.3492e-04 - val_loss: 0.1936 - val_accuracy: 0.0000e+00\n",
            "Epoch 8243/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0371 - accuracy: 6.3492e-04 - val_loss: 0.1936 - val_accuracy: 0.0000e+00\n",
            "Epoch 8244/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0371 - accuracy: 6.3492e-04 - val_loss: 0.1936 - val_accuracy: 0.0000e+00\n",
            "Epoch 8245/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0371 - accuracy: 6.3492e-04 - val_loss: 0.1935 - val_accuracy: 0.0000e+00\n",
            "Epoch 8246/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0371 - accuracy: 6.3492e-04 - val_loss: 0.1935 - val_accuracy: 0.0000e+00\n",
            "Epoch 8247/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0371 - accuracy: 6.3492e-04 - val_loss: 0.1935 - val_accuracy: 0.0000e+00\n",
            "Epoch 8248/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0371 - accuracy: 6.3492e-04 - val_loss: 0.1934 - val_accuracy: 0.0000e+00\n",
            "Epoch 8249/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0370 - accuracy: 6.3492e-04 - val_loss: 0.1934 - val_accuracy: 0.0000e+00\n",
            "Epoch 8250/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0370 - accuracy: 6.3492e-04 - val_loss: 0.1933 - val_accuracy: 0.0000e+00\n",
            "Epoch 8251/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0370 - accuracy: 6.3492e-04 - val_loss: 0.1933 - val_accuracy: 0.0000e+00\n",
            "Epoch 8252/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0370 - accuracy: 6.3492e-04 - val_loss: 0.1933 - val_accuracy: 0.0000e+00\n",
            "Epoch 8253/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0370 - accuracy: 6.3492e-04 - val_loss: 0.1932 - val_accuracy: 0.0000e+00\n",
            "Epoch 8254/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0370 - accuracy: 6.3492e-04 - val_loss: 0.1932 - val_accuracy: 0.0000e+00\n",
            "Epoch 8255/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0370 - accuracy: 6.3492e-04 - val_loss: 0.1932 - val_accuracy: 0.0000e+00\n",
            "Epoch 8256/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0369 - accuracy: 6.3492e-04 - val_loss: 0.1931 - val_accuracy: 0.0000e+00\n",
            "Epoch 8257/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0369 - accuracy: 6.3492e-04 - val_loss: 0.1931 - val_accuracy: 0.0000e+00\n",
            "Epoch 8258/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0369 - accuracy: 6.3492e-04 - val_loss: 0.1930 - val_accuracy: 0.0000e+00\n",
            "Epoch 8259/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0369 - accuracy: 6.3492e-04 - val_loss: 0.1930 - val_accuracy: 0.0000e+00\n",
            "Epoch 8260/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0369 - accuracy: 6.3492e-04 - val_loss: 0.1930 - val_accuracy: 0.0000e+00\n",
            "Epoch 8261/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0369 - accuracy: 6.3492e-04 - val_loss: 0.1929 - val_accuracy: 0.0000e+00\n",
            "Epoch 8262/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0369 - accuracy: 6.3492e-04 - val_loss: 0.1929 - val_accuracy: 0.0000e+00\n",
            "Epoch 8263/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 6.3492e-04 - val_loss: 0.1929 - val_accuracy: 0.0000e+00\n",
            "Epoch 8264/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0368 - accuracy: 6.3492e-04 - val_loss: 0.1928 - val_accuracy: 0.0000e+00\n",
            "Epoch 8265/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 6.3492e-04 - val_loss: 0.1928 - val_accuracy: 0.0000e+00\n",
            "Epoch 8266/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0368 - accuracy: 6.3492e-04 - val_loss: 0.1927 - val_accuracy: 0.0000e+00\n",
            "Epoch 8267/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0368 - accuracy: 6.3492e-04 - val_loss: 0.1927 - val_accuracy: 0.0000e+00\n",
            "Epoch 8268/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 6.3492e-04 - val_loss: 0.1927 - val_accuracy: 0.0000e+00\n",
            "Epoch 8269/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0368 - accuracy: 6.3492e-04 - val_loss: 0.1926 - val_accuracy: 0.0000e+00\n",
            "Epoch 8270/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0367 - accuracy: 6.3492e-04 - val_loss: 0.1926 - val_accuracy: 0.0000e+00\n",
            "Epoch 8271/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0367 - accuracy: 6.3492e-04 - val_loss: 0.1925 - val_accuracy: 0.0000e+00\n",
            "Epoch 8272/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0367 - accuracy: 6.3492e-04 - val_loss: 0.1925 - val_accuracy: 0.0000e+00\n",
            "Epoch 8273/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0367 - accuracy: 6.3492e-04 - val_loss: 0.1925 - val_accuracy: 0.0000e+00\n",
            "Epoch 8274/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0367 - accuracy: 6.3492e-04 - val_loss: 0.1924 - val_accuracy: 0.0000e+00\n",
            "Epoch 8275/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0367 - accuracy: 6.3492e-04 - val_loss: 0.1924 - val_accuracy: 0.0000e+00\n",
            "Epoch 8276/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0367 - accuracy: 6.3492e-04 - val_loss: 0.1924 - val_accuracy: 0.0000e+00\n",
            "Epoch 8277/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0366 - accuracy: 6.3492e-04 - val_loss: 0.1923 - val_accuracy: 0.0000e+00\n",
            "Epoch 8278/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0366 - accuracy: 6.3492e-04 - val_loss: 0.1923 - val_accuracy: 0.0000e+00\n",
            "Epoch 8279/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0366 - accuracy: 6.3492e-04 - val_loss: 0.1923 - val_accuracy: 0.0000e+00\n",
            "Epoch 8280/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0366 - accuracy: 6.3492e-04 - val_loss: 0.1922 - val_accuracy: 0.0000e+00\n",
            "Epoch 8281/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0366 - accuracy: 6.3492e-04 - val_loss: 0.1922 - val_accuracy: 0.0000e+00\n",
            "Epoch 8282/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0366 - accuracy: 6.3492e-04 - val_loss: 0.1921 - val_accuracy: 0.0000e+00\n",
            "Epoch 8283/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0366 - accuracy: 6.3492e-04 - val_loss: 0.1921 - val_accuracy: 0.0000e+00\n",
            "Epoch 8284/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0366 - accuracy: 6.3492e-04 - val_loss: 0.1921 - val_accuracy: 0.0000e+00\n",
            "Epoch 8285/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0365 - accuracy: 6.3492e-04 - val_loss: 0.1920 - val_accuracy: 0.0000e+00\n",
            "Epoch 8286/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0365 - accuracy: 6.3492e-04 - val_loss: 0.1920 - val_accuracy: 0.0000e+00\n",
            "Epoch 8287/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0365 - accuracy: 6.3492e-04 - val_loss: 0.1919 - val_accuracy: 0.0000e+00\n",
            "Epoch 8288/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0365 - accuracy: 6.3492e-04 - val_loss: 0.1919 - val_accuracy: 0.0000e+00\n",
            "Epoch 8289/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0365 - accuracy: 6.3492e-04 - val_loss: 0.1918 - val_accuracy: 0.0000e+00\n",
            "Epoch 8290/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0365 - accuracy: 6.3492e-04 - val_loss: 0.1918 - val_accuracy: 0.0000e+00\n",
            "Epoch 8291/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0365 - accuracy: 6.3492e-04 - val_loss: 0.1918 - val_accuracy: 0.0000e+00\n",
            "Epoch 8292/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0364 - accuracy: 6.3492e-04 - val_loss: 0.1917 - val_accuracy: 0.0000e+00\n",
            "Epoch 8293/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0364 - accuracy: 6.3492e-04 - val_loss: 0.1917 - val_accuracy: 0.0000e+00\n",
            "Epoch 8294/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0364 - accuracy: 6.3492e-04 - val_loss: 0.1916 - val_accuracy: 0.0000e+00\n",
            "Epoch 8295/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0364 - accuracy: 6.3492e-04 - val_loss: 0.1916 - val_accuracy: 0.0000e+00\n",
            "Epoch 8296/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0364 - accuracy: 6.3492e-04 - val_loss: 0.1915 - val_accuracy: 0.0000e+00\n",
            "Epoch 8297/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0364 - accuracy: 6.3492e-04 - val_loss: 0.1915 - val_accuracy: 0.0000e+00\n",
            "Epoch 8298/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0364 - accuracy: 6.3492e-04 - val_loss: 0.1914 - val_accuracy: 0.0000e+00\n",
            "Epoch 8299/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0363 - accuracy: 6.3492e-04 - val_loss: 0.1914 - val_accuracy: 0.0000e+00\n",
            "Epoch 8300/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0363 - accuracy: 6.3492e-04 - val_loss: 0.1913 - val_accuracy: 0.0000e+00\n",
            "Epoch 8301/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0363 - accuracy: 6.3492e-04 - val_loss: 0.1913 - val_accuracy: 0.0000e+00\n",
            "Epoch 8302/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0363 - accuracy: 6.3492e-04 - val_loss: 0.1913 - val_accuracy: 0.0000e+00\n",
            "Epoch 8303/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0363 - accuracy: 6.3492e-04 - val_loss: 0.1912 - val_accuracy: 0.0000e+00\n",
            "Epoch 8304/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0363 - accuracy: 6.3492e-04 - val_loss: 0.1912 - val_accuracy: 0.0000e+00\n",
            "Epoch 8305/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0363 - accuracy: 6.3492e-04 - val_loss: 0.1911 - val_accuracy: 0.0000e+00\n",
            "Epoch 8306/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0362 - accuracy: 6.3492e-04 - val_loss: 0.1911 - val_accuracy: 0.0000e+00\n",
            "Epoch 8307/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0362 - accuracy: 6.3492e-04 - val_loss: 0.1910 - val_accuracy: 0.0000e+00\n",
            "Epoch 8308/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0362 - accuracy: 6.3492e-04 - val_loss: 0.1910 - val_accuracy: 0.0000e+00\n",
            "Epoch 8309/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0362 - accuracy: 6.3492e-04 - val_loss: 0.1909 - val_accuracy: 0.0000e+00\n",
            "Epoch 8310/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0362 - accuracy: 6.3492e-04 - val_loss: 0.1909 - val_accuracy: 0.0000e+00\n",
            "Epoch 8311/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0362 - accuracy: 6.3492e-04 - val_loss: 0.1908 - val_accuracy: 0.0000e+00\n",
            "Epoch 8312/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0362 - accuracy: 6.3492e-04 - val_loss: 0.1908 - val_accuracy: 0.0000e+00\n",
            "Epoch 8313/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0361 - accuracy: 6.3492e-04 - val_loss: 0.1907 - val_accuracy: 0.0000e+00\n",
            "Epoch 8314/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0361 - accuracy: 6.3492e-04 - val_loss: 0.1907 - val_accuracy: 0.0000e+00\n",
            "Epoch 8315/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0361 - accuracy: 6.3492e-04 - val_loss: 0.1906 - val_accuracy: 0.0000e+00\n",
            "Epoch 8316/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0361 - accuracy: 6.3492e-04 - val_loss: 0.1906 - val_accuracy: 0.0000e+00\n",
            "Epoch 8317/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0361 - accuracy: 6.3492e-04 - val_loss: 0.1905 - val_accuracy: 0.0000e+00\n",
            "Epoch 8318/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0361 - accuracy: 6.3492e-04 - val_loss: 0.1905 - val_accuracy: 0.0000e+00\n",
            "Epoch 8319/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0361 - accuracy: 6.3492e-04 - val_loss: 0.1905 - val_accuracy: 0.0000e+00\n",
            "Epoch 8320/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0360 - accuracy: 6.3492e-04 - val_loss: 0.1904 - val_accuracy: 0.0000e+00\n",
            "Epoch 8321/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0360 - accuracy: 6.3492e-04 - val_loss: 0.1904 - val_accuracy: 0.0000e+00\n",
            "Epoch 8322/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0360 - accuracy: 6.3492e-04 - val_loss: 0.1903 - val_accuracy: 0.0000e+00\n",
            "Epoch 8323/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0360 - accuracy: 6.3492e-04 - val_loss: 0.1903 - val_accuracy: 0.0000e+00\n",
            "Epoch 8324/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0360 - accuracy: 6.3492e-04 - val_loss: 0.1902 - val_accuracy: 0.0000e+00\n",
            "Epoch 8325/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0360 - accuracy: 6.3492e-04 - val_loss: 0.1902 - val_accuracy: 0.0000e+00\n",
            "Epoch 8326/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0360 - accuracy: 6.3492e-04 - val_loss: 0.1901 - val_accuracy: 0.0000e+00\n",
            "Epoch 8327/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0360 - accuracy: 6.3492e-04 - val_loss: 0.1901 - val_accuracy: 0.0000e+00\n",
            "Epoch 8328/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0359 - accuracy: 6.3492e-04 - val_loss: 0.1900 - val_accuracy: 0.0000e+00\n",
            "Epoch 8329/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0359 - accuracy: 6.3492e-04 - val_loss: 0.1900 - val_accuracy: 0.0000e+00\n",
            "Epoch 8330/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0359 - accuracy: 6.3492e-04 - val_loss: 0.1899 - val_accuracy: 0.0000e+00\n",
            "Epoch 8331/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0359 - accuracy: 6.3492e-04 - val_loss: 0.1899 - val_accuracy: 0.0000e+00\n",
            "Epoch 8332/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0359 - accuracy: 6.3492e-04 - val_loss: 0.1898 - val_accuracy: 0.0000e+00\n",
            "Epoch 8333/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0359 - accuracy: 6.3492e-04 - val_loss: 0.1898 - val_accuracy: 0.0000e+00\n",
            "Epoch 8334/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0359 - accuracy: 6.3492e-04 - val_loss: 0.1897 - val_accuracy: 0.0000e+00\n",
            "Epoch 8335/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0358 - accuracy: 6.3492e-04 - val_loss: 0.1897 - val_accuracy: 0.0000e+00\n",
            "Epoch 8336/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0358 - accuracy: 6.3492e-04 - val_loss: 0.1897 - val_accuracy: 0.0000e+00\n",
            "Epoch 8337/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0358 - accuracy: 6.3492e-04 - val_loss: 0.1896 - val_accuracy: 0.0000e+00\n",
            "Epoch 8338/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0358 - accuracy: 6.3492e-04 - val_loss: 0.1896 - val_accuracy: 0.0000e+00\n",
            "Epoch 8339/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0358 - accuracy: 6.3492e-04 - val_loss: 0.1895 - val_accuracy: 0.0000e+00\n",
            "Epoch 8340/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0358 - accuracy: 6.3492e-04 - val_loss: 0.1895 - val_accuracy: 0.0000e+00\n",
            "Epoch 8341/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0358 - accuracy: 6.3492e-04 - val_loss: 0.1895 - val_accuracy: 0.0000e+00\n",
            "Epoch 8342/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0357 - accuracy: 6.3492e-04 - val_loss: 0.1894 - val_accuracy: 0.0000e+00\n",
            "Epoch 8343/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0357 - accuracy: 6.3492e-04 - val_loss: 0.1894 - val_accuracy: 0.0000e+00\n",
            "Epoch 8344/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0357 - accuracy: 6.3492e-04 - val_loss: 0.1893 - val_accuracy: 0.0000e+00\n",
            "Epoch 8345/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0357 - accuracy: 6.3492e-04 - val_loss: 0.1893 - val_accuracy: 0.0000e+00\n",
            "Epoch 8346/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0357 - accuracy: 6.3492e-04 - val_loss: 0.1892 - val_accuracy: 0.0000e+00\n",
            "Epoch 8347/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0357 - accuracy: 6.3492e-04 - val_loss: 0.1892 - val_accuracy: 0.0000e+00\n",
            "Epoch 8348/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0357 - accuracy: 6.3492e-04 - val_loss: 0.1892 - val_accuracy: 0.0000e+00\n",
            "Epoch 8349/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0356 - accuracy: 6.3492e-04 - val_loss: 0.1891 - val_accuracy: 0.0000e+00\n",
            "Epoch 8350/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0356 - accuracy: 6.3492e-04 - val_loss: 0.1891 - val_accuracy: 0.0000e+00\n",
            "Epoch 8351/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0356 - accuracy: 6.3492e-04 - val_loss: 0.1891 - val_accuracy: 0.0000e+00\n",
            "Epoch 8352/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0356 - accuracy: 6.3492e-04 - val_loss: 0.1890 - val_accuracy: 0.0000e+00\n",
            "Epoch 8353/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0356 - accuracy: 6.3492e-04 - val_loss: 0.1890 - val_accuracy: 0.0000e+00\n",
            "Epoch 8354/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0356 - accuracy: 6.3492e-04 - val_loss: 0.1889 - val_accuracy: 0.0000e+00\n",
            "Epoch 8355/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0356 - accuracy: 6.3492e-04 - val_loss: 0.1889 - val_accuracy: 0.0000e+00\n",
            "Epoch 8356/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0355 - accuracy: 6.3492e-04 - val_loss: 0.1889 - val_accuracy: 0.0000e+00\n",
            "Epoch 8357/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0355 - accuracy: 6.3492e-04 - val_loss: 0.1888 - val_accuracy: 0.0000e+00\n",
            "Epoch 8358/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0355 - accuracy: 6.3492e-04 - val_loss: 0.1888 - val_accuracy: 0.0000e+00\n",
            "Epoch 8359/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0355 - accuracy: 6.3492e-04 - val_loss: 0.1888 - val_accuracy: 0.0000e+00\n",
            "Epoch 8360/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0355 - accuracy: 6.3492e-04 - val_loss: 0.1887 - val_accuracy: 0.0000e+00\n",
            "Epoch 8361/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0355 - accuracy: 6.3492e-04 - val_loss: 0.1887 - val_accuracy: 0.0000e+00\n",
            "Epoch 8362/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0355 - accuracy: 6.3492e-04 - val_loss: 0.1887 - val_accuracy: 0.0000e+00\n",
            "Epoch 8363/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0354 - accuracy: 6.3492e-04 - val_loss: 0.1887 - val_accuracy: 0.0000e+00\n",
            "Epoch 8364/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0354 - accuracy: 6.3492e-04 - val_loss: 0.1886 - val_accuracy: 0.0000e+00\n",
            "Epoch 8365/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0354 - accuracy: 6.3492e-04 - val_loss: 0.1886 - val_accuracy: 0.0000e+00\n",
            "Epoch 8366/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0354 - accuracy: 6.3492e-04 - val_loss: 0.1886 - val_accuracy: 0.0000e+00\n",
            "Epoch 8367/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0354 - accuracy: 6.3492e-04 - val_loss: 0.1886 - val_accuracy: 0.0000e+00\n",
            "Epoch 8368/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0354 - accuracy: 6.3492e-04 - val_loss: 0.1885 - val_accuracy: 0.0000e+00\n",
            "Epoch 8369/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0354 - accuracy: 6.3492e-04 - val_loss: 0.1885 - val_accuracy: 0.0000e+00\n",
            "Epoch 8370/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0353 - accuracy: 6.3492e-04 - val_loss: 0.1885 - val_accuracy: 0.0000e+00\n",
            "Epoch 8371/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0353 - accuracy: 6.3492e-04 - val_loss: 0.1884 - val_accuracy: 0.0000e+00\n",
            "Epoch 8372/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0353 - accuracy: 6.3492e-04 - val_loss: 0.1884 - val_accuracy: 0.0000e+00\n",
            "Epoch 8373/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0353 - accuracy: 6.3492e-04 - val_loss: 0.1883 - val_accuracy: 0.0000e+00\n",
            "Epoch 8374/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0353 - accuracy: 6.3492e-04 - val_loss: 0.1883 - val_accuracy: 0.0000e+00\n",
            "Epoch 8375/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0353 - accuracy: 6.3492e-04 - val_loss: 0.1883 - val_accuracy: 0.0000e+00\n",
            "Epoch 8376/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0353 - accuracy: 6.3492e-04 - val_loss: 0.1882 - val_accuracy: 0.0000e+00\n",
            "Epoch 8377/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0353 - accuracy: 6.3492e-04 - val_loss: 0.1882 - val_accuracy: 0.0000e+00\n",
            "Epoch 8378/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0352 - accuracy: 6.3492e-04 - val_loss: 0.1881 - val_accuracy: 0.0000e+00\n",
            "Epoch 8379/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0352 - accuracy: 6.3492e-04 - val_loss: 0.1881 - val_accuracy: 0.0000e+00\n",
            "Epoch 8380/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0352 - accuracy: 6.3492e-04 - val_loss: 0.1881 - val_accuracy: 0.0000e+00\n",
            "Epoch 8381/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0352 - accuracy: 6.3492e-04 - val_loss: 0.1880 - val_accuracy: 0.0000e+00\n",
            "Epoch 8382/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0352 - accuracy: 6.3492e-04 - val_loss: 0.1880 - val_accuracy: 0.0000e+00\n",
            "Epoch 8383/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0352 - accuracy: 6.3492e-04 - val_loss: 0.1880 - val_accuracy: 0.0000e+00\n",
            "Epoch 8384/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0352 - accuracy: 6.3492e-04 - val_loss: 0.1879 - val_accuracy: 0.0000e+00\n",
            "Epoch 8385/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0351 - accuracy: 6.3492e-04 - val_loss: 0.1879 - val_accuracy: 0.0000e+00\n",
            "Epoch 8386/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0351 - accuracy: 6.3492e-04 - val_loss: 0.1879 - val_accuracy: 0.0000e+00\n",
            "Epoch 8387/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0351 - accuracy: 6.3492e-04 - val_loss: 0.1878 - val_accuracy: 0.0000e+00\n",
            "Epoch 8388/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0351 - accuracy: 6.3492e-04 - val_loss: 0.1878 - val_accuracy: 0.0000e+00\n",
            "Epoch 8389/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0351 - accuracy: 6.3492e-04 - val_loss: 0.1878 - val_accuracy: 0.0000e+00\n",
            "Epoch 8390/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0351 - accuracy: 6.3492e-04 - val_loss: 0.1878 - val_accuracy: 0.0000e+00\n",
            "Epoch 8391/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0351 - accuracy: 6.3492e-04 - val_loss: 0.1878 - val_accuracy: 0.0000e+00\n",
            "Epoch 8392/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0350 - accuracy: 6.3492e-04 - val_loss: 0.1877 - val_accuracy: 0.0000e+00\n",
            "Epoch 8393/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0350 - accuracy: 6.3492e-04 - val_loss: 0.1877 - val_accuracy: 0.0000e+00\n",
            "Epoch 8394/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0350 - accuracy: 6.3492e-04 - val_loss: 0.1877 - val_accuracy: 0.0000e+00\n",
            "Epoch 8395/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0350 - accuracy: 6.3492e-04 - val_loss: 0.1877 - val_accuracy: 0.0000e+00\n",
            "Epoch 8396/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0350 - accuracy: 6.3492e-04 - val_loss: 0.1876 - val_accuracy: 0.0000e+00\n",
            "Epoch 8397/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0350 - accuracy: 6.3492e-04 - val_loss: 0.1876 - val_accuracy: 0.0000e+00\n",
            "Epoch 8398/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0350 - accuracy: 6.3492e-04 - val_loss: 0.1876 - val_accuracy: 0.0000e+00\n",
            "Epoch 8399/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0349 - accuracy: 6.3492e-04 - val_loss: 0.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 8400/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0349 - accuracy: 6.3492e-04 - val_loss: 0.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 8401/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0349 - accuracy: 6.3492e-04 - val_loss: 0.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 8402/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0349 - accuracy: 6.3492e-04 - val_loss: 0.1874 - val_accuracy: 0.0000e+00\n",
            "Epoch 8403/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0349 - accuracy: 6.3492e-04 - val_loss: 0.1874 - val_accuracy: 0.0000e+00\n",
            "Epoch 8404/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0349 - accuracy: 6.3492e-04 - val_loss: 0.1873 - val_accuracy: 0.0000e+00\n",
            "Epoch 8405/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0349 - accuracy: 6.3492e-04 - val_loss: 0.1873 - val_accuracy: 0.0000e+00\n",
            "Epoch 8406/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0348 - accuracy: 6.3492e-04 - val_loss: 0.1873 - val_accuracy: 0.0000e+00\n",
            "Epoch 8407/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0348 - accuracy: 6.3492e-04 - val_loss: 0.1872 - val_accuracy: 0.0000e+00\n",
            "Epoch 8408/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0348 - accuracy: 6.3492e-04 - val_loss: 0.1872 - val_accuracy: 0.0000e+00\n",
            "Epoch 8409/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0348 - accuracy: 6.3492e-04 - val_loss: 0.1871 - val_accuracy: 0.0000e+00\n",
            "Epoch 8410/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0348 - accuracy: 6.3492e-04 - val_loss: 0.1871 - val_accuracy: 0.0000e+00\n",
            "Epoch 8411/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0348 - accuracy: 6.3492e-04 - val_loss: 0.1871 - val_accuracy: 0.0000e+00\n",
            "Epoch 8412/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0348 - accuracy: 6.3492e-04 - val_loss: 0.1870 - val_accuracy: 0.0000e+00\n",
            "Epoch 8413/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0348 - accuracy: 6.3492e-04 - val_loss: 0.1870 - val_accuracy: 0.0000e+00\n",
            "Epoch 8414/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0347 - accuracy: 6.3492e-04 - val_loss: 0.1870 - val_accuracy: 0.0000e+00\n",
            "Epoch 8415/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0347 - accuracy: 6.3492e-04 - val_loss: 0.1869 - val_accuracy: 0.0000e+00\n",
            "Epoch 8416/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0347 - accuracy: 6.3492e-04 - val_loss: 0.1869 - val_accuracy: 0.0000e+00\n",
            "Epoch 8417/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0347 - accuracy: 6.3492e-04 - val_loss: 0.1868 - val_accuracy: 0.0000e+00\n",
            "Epoch 8418/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0347 - accuracy: 6.3492e-04 - val_loss: 0.1868 - val_accuracy: 0.0000e+00\n",
            "Epoch 8419/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0347 - accuracy: 6.3492e-04 - val_loss: 0.1867 - val_accuracy: 0.0000e+00\n",
            "Epoch 8420/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0347 - accuracy: 6.3492e-04 - val_loss: 0.1867 - val_accuracy: 0.0000e+00\n",
            "Epoch 8421/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0346 - accuracy: 6.3492e-04 - val_loss: 0.1867 - val_accuracy: 0.0000e+00\n",
            "Epoch 8422/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0346 - accuracy: 6.3492e-04 - val_loss: 0.1866 - val_accuracy: 0.0000e+00\n",
            "Epoch 8423/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0346 - accuracy: 6.3492e-04 - val_loss: 0.1866 - val_accuracy: 0.0000e+00\n",
            "Epoch 8424/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0346 - accuracy: 6.3492e-04 - val_loss: 0.1865 - val_accuracy: 0.0000e+00\n",
            "Epoch 8425/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0346 - accuracy: 6.3492e-04 - val_loss: 0.1865 - val_accuracy: 0.0000e+00\n",
            "Epoch 8426/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0346 - accuracy: 6.3492e-04 - val_loss: 0.1864 - val_accuracy: 0.0000e+00\n",
            "Epoch 8427/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0346 - accuracy: 6.3492e-04 - val_loss: 0.1864 - val_accuracy: 0.0000e+00\n",
            "Epoch 8428/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0345 - accuracy: 6.3492e-04 - val_loss: 0.1863 - val_accuracy: 0.0000e+00\n",
            "Epoch 8429/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0345 - accuracy: 6.3492e-04 - val_loss: 0.1863 - val_accuracy: 0.0000e+00\n",
            "Epoch 8430/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0345 - accuracy: 6.3492e-04 - val_loss: 0.1863 - val_accuracy: 0.0000e+00\n",
            "Epoch 8431/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0345 - accuracy: 6.3492e-04 - val_loss: 0.1862 - val_accuracy: 0.0000e+00\n",
            "Epoch 8432/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0345 - accuracy: 6.3492e-04 - val_loss: 0.1862 - val_accuracy: 0.0000e+00\n",
            "Epoch 8433/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0345 - accuracy: 6.3492e-04 - val_loss: 0.1862 - val_accuracy: 0.0000e+00\n",
            "Epoch 8434/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0345 - accuracy: 6.3492e-04 - val_loss: 0.1861 - val_accuracy: 0.0000e+00\n",
            "Epoch 8435/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0344 - accuracy: 6.3492e-04 - val_loss: 0.1861 - val_accuracy: 0.0000e+00\n",
            "Epoch 8436/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0344 - accuracy: 6.3492e-04 - val_loss: 0.1860 - val_accuracy: 0.0000e+00\n",
            "Epoch 8437/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0344 - accuracy: 6.3492e-04 - val_loss: 0.1860 - val_accuracy: 0.0000e+00\n",
            "Epoch 8438/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0344 - accuracy: 6.3492e-04 - val_loss: 0.1860 - val_accuracy: 0.0000e+00\n",
            "Epoch 8439/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0344 - accuracy: 6.3492e-04 - val_loss: 0.1859 - val_accuracy: 0.0000e+00\n",
            "Epoch 8440/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0344 - accuracy: 6.3492e-04 - val_loss: 0.1859 - val_accuracy: 0.0000e+00\n",
            "Epoch 8441/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0344 - accuracy: 6.3492e-04 - val_loss: 0.1859 - val_accuracy: 0.0000e+00\n",
            "Epoch 8442/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0343 - accuracy: 6.3492e-04 - val_loss: 0.1858 - val_accuracy: 0.0000e+00\n",
            "Epoch 8443/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0343 - accuracy: 6.3492e-04 - val_loss: 0.1858 - val_accuracy: 0.0000e+00\n",
            "Epoch 8444/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0343 - accuracy: 6.3492e-04 - val_loss: 0.1858 - val_accuracy: 0.0000e+00\n",
            "Epoch 8445/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0343 - accuracy: 6.3492e-04 - val_loss: 0.1857 - val_accuracy: 0.0000e+00\n",
            "Epoch 8446/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0343 - accuracy: 6.3492e-04 - val_loss: 0.1857 - val_accuracy: 0.0000e+00\n",
            "Epoch 8447/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0343 - accuracy: 6.3492e-04 - val_loss: 0.1857 - val_accuracy: 0.0000e+00\n",
            "Epoch 8448/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0343 - accuracy: 6.3492e-04 - val_loss: 0.1856 - val_accuracy: 0.0000e+00\n",
            "Epoch 8449/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0343 - accuracy: 6.3492e-04 - val_loss: 0.1856 - val_accuracy: 0.0000e+00\n",
            "Epoch 8450/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0342 - accuracy: 6.3492e-04 - val_loss: 0.1856 - val_accuracy: 0.0000e+00\n",
            "Epoch 8451/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0342 - accuracy: 6.3492e-04 - val_loss: 0.1856 - val_accuracy: 0.0000e+00\n",
            "Epoch 8452/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0342 - accuracy: 6.3492e-04 - val_loss: 0.1855 - val_accuracy: 0.0000e+00\n",
            "Epoch 8453/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0342 - accuracy: 6.3492e-04 - val_loss: 0.1855 - val_accuracy: 0.0000e+00\n",
            "Epoch 8454/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0342 - accuracy: 6.3492e-04 - val_loss: 0.1855 - val_accuracy: 0.0000e+00\n",
            "Epoch 8455/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0342 - accuracy: 6.3492e-04 - val_loss: 0.1854 - val_accuracy: 0.0000e+00\n",
            "Epoch 8456/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0342 - accuracy: 6.3492e-04 - val_loss: 0.1854 - val_accuracy: 0.0000e+00\n",
            "Epoch 8457/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0341 - accuracy: 6.3492e-04 - val_loss: 0.1854 - val_accuracy: 0.0000e+00\n",
            "Epoch 8458/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0341 - accuracy: 6.3492e-04 - val_loss: 0.1853 - val_accuracy: 0.0000e+00\n",
            "Epoch 8459/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0341 - accuracy: 6.3492e-04 - val_loss: 0.1853 - val_accuracy: 0.0000e+00\n",
            "Epoch 8460/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0341 - accuracy: 6.3492e-04 - val_loss: 0.1852 - val_accuracy: 0.0000e+00\n",
            "Epoch 8461/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0341 - accuracy: 6.3492e-04 - val_loss: 0.1852 - val_accuracy: 0.0000e+00\n",
            "Epoch 8462/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0341 - accuracy: 6.3492e-04 - val_loss: 0.1852 - val_accuracy: 0.0000e+00\n",
            "Epoch 8463/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0341 - accuracy: 6.3492e-04 - val_loss: 0.1851 - val_accuracy: 0.0000e+00\n",
            "Epoch 8464/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0340 - accuracy: 6.3492e-04 - val_loss: 0.1851 - val_accuracy: 0.0000e+00\n",
            "Epoch 8465/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0340 - accuracy: 6.3492e-04 - val_loss: 0.1850 - val_accuracy: 0.0000e+00\n",
            "Epoch 8466/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0340 - accuracy: 6.3492e-04 - val_loss: 0.1850 - val_accuracy: 0.0000e+00\n",
            "Epoch 8467/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0340 - accuracy: 6.3492e-04 - val_loss: 0.1850 - val_accuracy: 0.0000e+00\n",
            "Epoch 8468/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0340 - accuracy: 6.3492e-04 - val_loss: 0.1849 - val_accuracy: 0.0000e+00\n",
            "Epoch 8469/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0340 - accuracy: 6.3492e-04 - val_loss: 0.1849 - val_accuracy: 0.0000e+00\n",
            "Epoch 8470/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0340 - accuracy: 6.3492e-04 - val_loss: 0.1849 - val_accuracy: 0.0000e+00\n",
            "Epoch 8471/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0339 - accuracy: 6.3492e-04 - val_loss: 0.1849 - val_accuracy: 0.0000e+00\n",
            "Epoch 8472/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0339 - accuracy: 6.3492e-04 - val_loss: 0.1848 - val_accuracy: 0.0000e+00\n",
            "Epoch 8473/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0339 - accuracy: 6.3492e-04 - val_loss: 0.1848 - val_accuracy: 0.0000e+00\n",
            "Epoch 8474/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0339 - accuracy: 6.3492e-04 - val_loss: 0.1848 - val_accuracy: 0.0000e+00\n",
            "Epoch 8475/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0339 - accuracy: 6.3492e-04 - val_loss: 0.1848 - val_accuracy: 0.0000e+00\n",
            "Epoch 8476/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0339 - accuracy: 6.3492e-04 - val_loss: 0.1847 - val_accuracy: 0.0000e+00\n",
            "Epoch 8477/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0339 - accuracy: 6.3492e-04 - val_loss: 0.1847 - val_accuracy: 0.0000e+00\n",
            "Epoch 8478/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0339 - accuracy: 6.3492e-04 - val_loss: 0.1847 - val_accuracy: 0.0000e+00\n",
            "Epoch 8479/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0338 - accuracy: 6.3492e-04 - val_loss: 0.1846 - val_accuracy: 0.0000e+00\n",
            "Epoch 8480/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0338 - accuracy: 6.3492e-04 - val_loss: 0.1846 - val_accuracy: 0.0000e+00\n",
            "Epoch 8481/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0338 - accuracy: 6.3492e-04 - val_loss: 0.1845 - val_accuracy: 0.0000e+00\n",
            "Epoch 8482/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0338 - accuracy: 6.3492e-04 - val_loss: 0.1845 - val_accuracy: 0.0000e+00\n",
            "Epoch 8483/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0338 - accuracy: 6.3492e-04 - val_loss: 0.1845 - val_accuracy: 0.0000e+00\n",
            "Epoch 8484/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0338 - accuracy: 6.3492e-04 - val_loss: 0.1844 - val_accuracy: 0.0000e+00\n",
            "Epoch 8485/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0338 - accuracy: 6.3492e-04 - val_loss: 0.1844 - val_accuracy: 0.0000e+00\n",
            "Epoch 8486/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0337 - accuracy: 6.3492e-04 - val_loss: 0.1843 - val_accuracy: 0.0000e+00\n",
            "Epoch 8487/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0337 - accuracy: 6.3492e-04 - val_loss: 0.1843 - val_accuracy: 0.0000e+00\n",
            "Epoch 8488/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0337 - accuracy: 6.3492e-04 - val_loss: 0.1842 - val_accuracy: 0.0000e+00\n",
            "Epoch 8489/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0337 - accuracy: 6.3492e-04 - val_loss: 0.1842 - val_accuracy: 0.0000e+00\n",
            "Epoch 8490/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0337 - accuracy: 6.3492e-04 - val_loss: 0.1842 - val_accuracy: 0.0000e+00\n",
            "Epoch 8491/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0337 - accuracy: 6.3492e-04 - val_loss: 0.1841 - val_accuracy: 0.0000e+00\n",
            "Epoch 8492/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0337 - accuracy: 6.3492e-04 - val_loss: 0.1841 - val_accuracy: 0.0000e+00\n",
            "Epoch 8493/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0336 - accuracy: 6.3492e-04 - val_loss: 0.1841 - val_accuracy: 0.0000e+00\n",
            "Epoch 8494/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0336 - accuracy: 6.3492e-04 - val_loss: 0.1840 - val_accuracy: 0.0000e+00\n",
            "Epoch 8495/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0336 - accuracy: 6.3492e-04 - val_loss: 0.1840 - val_accuracy: 0.0000e+00\n",
            "Epoch 8496/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0336 - accuracy: 6.3492e-04 - val_loss: 0.1840 - val_accuracy: 0.0000e+00\n",
            "Epoch 8497/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0336 - accuracy: 6.3492e-04 - val_loss: 0.1839 - val_accuracy: 0.0000e+00\n",
            "Epoch 8498/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0336 - accuracy: 6.3492e-04 - val_loss: 0.1839 - val_accuracy: 0.0000e+00\n",
            "Epoch 8499/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0336 - accuracy: 6.3492e-04 - val_loss: 0.1839 - val_accuracy: 0.0000e+00\n",
            "Epoch 8500/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0336 - accuracy: 6.3492e-04 - val_loss: 0.1838 - val_accuracy: 0.0000e+00\n",
            "Epoch 8501/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0335 - accuracy: 6.3492e-04 - val_loss: 0.1838 - val_accuracy: 0.0000e+00\n",
            "Epoch 8502/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0335 - accuracy: 6.3492e-04 - val_loss: 0.1838 - val_accuracy: 0.0000e+00\n",
            "Epoch 8503/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0335 - accuracy: 6.3492e-04 - val_loss: 0.1838 - val_accuracy: 0.0000e+00\n",
            "Epoch 8504/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0335 - accuracy: 6.3492e-04 - val_loss: 0.1837 - val_accuracy: 0.0000e+00\n",
            "Epoch 8505/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0335 - accuracy: 6.3492e-04 - val_loss: 0.1837 - val_accuracy: 0.0000e+00\n",
            "Epoch 8506/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0335 - accuracy: 6.3492e-04 - val_loss: 0.1836 - val_accuracy: 0.0000e+00\n",
            "Epoch 8507/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0335 - accuracy: 6.3492e-04 - val_loss: 0.1836 - val_accuracy: 0.0000e+00\n",
            "Epoch 8508/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0334 - accuracy: 6.3492e-04 - val_loss: 0.1836 - val_accuracy: 0.0000e+00\n",
            "Epoch 8509/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0334 - accuracy: 6.3492e-04 - val_loss: 0.1835 - val_accuracy: 0.0000e+00\n",
            "Epoch 8510/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0334 - accuracy: 6.3492e-04 - val_loss: 0.1835 - val_accuracy: 0.0000e+00\n",
            "Epoch 8511/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0334 - accuracy: 6.3492e-04 - val_loss: 0.1834 - val_accuracy: 0.0000e+00\n",
            "Epoch 8512/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0334 - accuracy: 6.3492e-04 - val_loss: 0.1834 - val_accuracy: 0.0000e+00\n",
            "Epoch 8513/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0334 - accuracy: 6.3492e-04 - val_loss: 0.1834 - val_accuracy: 0.0000e+00\n",
            "Epoch 8514/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0334 - accuracy: 6.3492e-04 - val_loss: 0.1833 - val_accuracy: 0.0000e+00\n",
            "Epoch 8515/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0333 - accuracy: 6.3492e-04 - val_loss: 0.1833 - val_accuracy: 0.0000e+00\n",
            "Epoch 8516/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0333 - accuracy: 6.3492e-04 - val_loss: 0.1832 - val_accuracy: 0.0000e+00\n",
            "Epoch 8517/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0333 - accuracy: 6.3492e-04 - val_loss: 0.1832 - val_accuracy: 0.0000e+00\n",
            "Epoch 8518/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0333 - accuracy: 6.3492e-04 - val_loss: 0.1831 - val_accuracy: 0.0000e+00\n",
            "Epoch 8519/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0333 - accuracy: 6.3492e-04 - val_loss: 0.1831 - val_accuracy: 0.0000e+00\n",
            "Epoch 8520/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0333 - accuracy: 6.3492e-04 - val_loss: 0.1830 - val_accuracy: 0.0000e+00\n",
            "Epoch 8521/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0333 - accuracy: 6.3492e-04 - val_loss: 0.1830 - val_accuracy: 0.0000e+00\n",
            "Epoch 8522/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0332 - accuracy: 6.3492e-04 - val_loss: 0.1829 - val_accuracy: 0.0000e+00\n",
            "Epoch 8523/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0332 - accuracy: 6.3492e-04 - val_loss: 0.1829 - val_accuracy: 0.0000e+00\n",
            "Epoch 8524/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0332 - accuracy: 6.3492e-04 - val_loss: 0.1828 - val_accuracy: 0.0000e+00\n",
            "Epoch 8525/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0332 - accuracy: 6.3492e-04 - val_loss: 0.1828 - val_accuracy: 0.0000e+00\n",
            "Epoch 8526/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0332 - accuracy: 6.3492e-04 - val_loss: 0.1827 - val_accuracy: 0.0000e+00\n",
            "Epoch 8527/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0332 - accuracy: 6.3492e-04 - val_loss: 0.1827 - val_accuracy: 0.0000e+00\n",
            "Epoch 8528/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0332 - accuracy: 6.3492e-04 - val_loss: 0.1826 - val_accuracy: 0.0000e+00\n",
            "Epoch 8529/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0332 - accuracy: 6.3492e-04 - val_loss: 0.1826 - val_accuracy: 0.0000e+00\n",
            "Epoch 8530/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0331 - accuracy: 6.3492e-04 - val_loss: 0.1825 - val_accuracy: 0.0000e+00\n",
            "Epoch 8531/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0331 - accuracy: 6.3492e-04 - val_loss: 0.1825 - val_accuracy: 0.0000e+00\n",
            "Epoch 8532/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0331 - accuracy: 6.3492e-04 - val_loss: 0.1824 - val_accuracy: 0.0000e+00\n",
            "Epoch 8533/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0331 - accuracy: 6.3492e-04 - val_loss: 0.1824 - val_accuracy: 0.0000e+00\n",
            "Epoch 8534/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0331 - accuracy: 6.3492e-04 - val_loss: 0.1824 - val_accuracy: 0.0000e+00\n",
            "Epoch 8535/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0331 - accuracy: 6.3492e-04 - val_loss: 0.1823 - val_accuracy: 0.0000e+00\n",
            "Epoch 8536/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0331 - accuracy: 6.3492e-04 - val_loss: 0.1823 - val_accuracy: 0.0000e+00\n",
            "Epoch 8537/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0330 - accuracy: 6.3492e-04 - val_loss: 0.1823 - val_accuracy: 0.0000e+00\n",
            "Epoch 8538/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0330 - accuracy: 6.3492e-04 - val_loss: 0.1822 - val_accuracy: 0.0000e+00\n",
            "Epoch 8539/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0330 - accuracy: 6.3492e-04 - val_loss: 0.1822 - val_accuracy: 0.0000e+00\n",
            "Epoch 8540/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0330 - accuracy: 6.3492e-04 - val_loss: 0.1821 - val_accuracy: 0.0000e+00\n",
            "Epoch 8541/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0330 - accuracy: 6.3492e-04 - val_loss: 0.1821 - val_accuracy: 0.0000e+00\n",
            "Epoch 8542/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0330 - accuracy: 6.3492e-04 - val_loss: 0.1820 - val_accuracy: 0.0000e+00\n",
            "Epoch 8543/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0330 - accuracy: 6.3492e-04 - val_loss: 0.1820 - val_accuracy: 0.0000e+00\n",
            "Epoch 8544/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0329 - accuracy: 6.3492e-04 - val_loss: 0.1820 - val_accuracy: 0.0000e+00\n",
            "Epoch 8545/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0329 - accuracy: 6.3492e-04 - val_loss: 0.1819 - val_accuracy: 0.0000e+00\n",
            "Epoch 8546/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0329 - accuracy: 6.3492e-04 - val_loss: 0.1819 - val_accuracy: 0.0000e+00\n",
            "Epoch 8547/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0329 - accuracy: 6.3492e-04 - val_loss: 0.1818 - val_accuracy: 0.0000e+00\n",
            "Epoch 8548/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0329 - accuracy: 6.3492e-04 - val_loss: 0.1818 - val_accuracy: 0.0000e+00\n",
            "Epoch 8549/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0329 - accuracy: 6.3492e-04 - val_loss: 0.1817 - val_accuracy: 0.0000e+00\n",
            "Epoch 8550/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0329 - accuracy: 6.3492e-04 - val_loss: 0.1817 - val_accuracy: 0.0000e+00\n",
            "Epoch 8551/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0329 - accuracy: 6.3492e-04 - val_loss: 0.1816 - val_accuracy: 0.0000e+00\n",
            "Epoch 8552/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0328 - accuracy: 6.3492e-04 - val_loss: 0.1816 - val_accuracy: 0.0000e+00\n",
            "Epoch 8553/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0328 - accuracy: 6.3492e-04 - val_loss: 0.1815 - val_accuracy: 0.0000e+00\n",
            "Epoch 8554/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0328 - accuracy: 6.3492e-04 - val_loss: 0.1815 - val_accuracy: 0.0000e+00\n",
            "Epoch 8555/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0328 - accuracy: 6.3492e-04 - val_loss: 0.1815 - val_accuracy: 0.0000e+00\n",
            "Epoch 8556/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0328 - accuracy: 6.3492e-04 - val_loss: 0.1814 - val_accuracy: 0.0000e+00\n",
            "Epoch 8557/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0328 - accuracy: 6.3492e-04 - val_loss: 0.1814 - val_accuracy: 0.0000e+00\n",
            "Epoch 8558/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0328 - accuracy: 6.3492e-04 - val_loss: 0.1813 - val_accuracy: 0.0000e+00\n",
            "Epoch 8559/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0327 - accuracy: 6.3492e-04 - val_loss: 0.1813 - val_accuracy: 0.0000e+00\n",
            "Epoch 8560/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0327 - accuracy: 6.3492e-04 - val_loss: 0.1813 - val_accuracy: 0.0000e+00\n",
            "Epoch 8561/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0327 - accuracy: 6.3492e-04 - val_loss: 0.1812 - val_accuracy: 0.0000e+00\n",
            "Epoch 8562/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0327 - accuracy: 6.3492e-04 - val_loss: 0.1812 - val_accuracy: 0.0000e+00\n",
            "Epoch 8563/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0327 - accuracy: 6.3492e-04 - val_loss: 0.1812 - val_accuracy: 0.0000e+00\n",
            "Epoch 8564/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0327 - accuracy: 6.3492e-04 - val_loss: 0.1811 - val_accuracy: 0.0000e+00\n",
            "Epoch 8565/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0327 - accuracy: 6.3492e-04 - val_loss: 0.1811 - val_accuracy: 0.0000e+00\n",
            "Epoch 8566/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0326 - accuracy: 6.3492e-04 - val_loss: 0.1811 - val_accuracy: 0.0000e+00\n",
            "Epoch 8567/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0326 - accuracy: 6.3492e-04 - val_loss: 0.1810 - val_accuracy: 0.0000e+00\n",
            "Epoch 8568/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0326 - accuracy: 6.3492e-04 - val_loss: 0.1810 - val_accuracy: 0.0000e+00\n",
            "Epoch 8569/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0326 - accuracy: 6.3492e-04 - val_loss: 0.1809 - val_accuracy: 0.0000e+00\n",
            "Epoch 8570/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0326 - accuracy: 6.3492e-04 - val_loss: 0.1809 - val_accuracy: 0.0000e+00\n",
            "Epoch 8571/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0326 - accuracy: 6.3492e-04 - val_loss: 0.1808 - val_accuracy: 0.0000e+00\n",
            "Epoch 8572/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0326 - accuracy: 6.3492e-04 - val_loss: 0.1808 - val_accuracy: 0.0000e+00\n",
            "Epoch 8573/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0325 - accuracy: 6.3492e-04 - val_loss: 0.1808 - val_accuracy: 0.0000e+00\n",
            "Epoch 8574/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0325 - accuracy: 6.3492e-04 - val_loss: 0.1807 - val_accuracy: 0.0000e+00\n",
            "Epoch 8575/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0325 - accuracy: 6.3492e-04 - val_loss: 0.1807 - val_accuracy: 0.0000e+00\n",
            "Epoch 8576/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0325 - accuracy: 6.3492e-04 - val_loss: 0.1806 - val_accuracy: 0.0000e+00\n",
            "Epoch 8577/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0325 - accuracy: 6.3492e-04 - val_loss: 0.1806 - val_accuracy: 0.0000e+00\n",
            "Epoch 8578/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0325 - accuracy: 6.3492e-04 - val_loss: 0.1805 - val_accuracy: 0.0000e+00\n",
            "Epoch 8579/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0325 - accuracy: 6.3492e-04 - val_loss: 0.1805 - val_accuracy: 0.0000e+00\n",
            "Epoch 8580/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0325 - accuracy: 6.3492e-04 - val_loss: 0.1804 - val_accuracy: 0.0000e+00\n",
            "Epoch 8581/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0324 - accuracy: 6.3492e-04 - val_loss: 0.1804 - val_accuracy: 0.0000e+00\n",
            "Epoch 8582/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0324 - accuracy: 6.3492e-04 - val_loss: 0.1803 - val_accuracy: 0.0000e+00\n",
            "Epoch 8583/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0324 - accuracy: 6.3492e-04 - val_loss: 0.1803 - val_accuracy: 0.0000e+00\n",
            "Epoch 8584/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0324 - accuracy: 6.3492e-04 - val_loss: 0.1802 - val_accuracy: 0.0000e+00\n",
            "Epoch 8585/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0324 - accuracy: 6.3492e-04 - val_loss: 0.1802 - val_accuracy: 0.0000e+00\n",
            "Epoch 8586/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0324 - accuracy: 6.3492e-04 - val_loss: 0.1801 - val_accuracy: 0.0000e+00\n",
            "Epoch 8587/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0324 - accuracy: 6.3492e-04 - val_loss: 0.1801 - val_accuracy: 0.0000e+00\n",
            "Epoch 8588/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0323 - accuracy: 6.3492e-04 - val_loss: 0.1800 - val_accuracy: 0.0000e+00\n",
            "Epoch 8589/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0323 - accuracy: 6.3492e-04 - val_loss: 0.1800 - val_accuracy: 0.0000e+00\n",
            "Epoch 8590/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0323 - accuracy: 6.3492e-04 - val_loss: 0.1799 - val_accuracy: 0.0000e+00\n",
            "Epoch 8591/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0323 - accuracy: 6.3492e-04 - val_loss: 0.1799 - val_accuracy: 0.0000e+00\n",
            "Epoch 8592/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0323 - accuracy: 6.3492e-04 - val_loss: 0.1798 - val_accuracy: 0.0000e+00\n",
            "Epoch 8593/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0323 - accuracy: 6.3492e-04 - val_loss: 0.1798 - val_accuracy: 0.0000e+00\n",
            "Epoch 8594/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0323 - accuracy: 6.3492e-04 - val_loss: 0.1797 - val_accuracy: 0.0000e+00\n",
            "Epoch 8595/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0322 - accuracy: 6.3492e-04 - val_loss: 0.1796 - val_accuracy: 0.0000e+00\n",
            "Epoch 8596/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0322 - accuracy: 6.3492e-04 - val_loss: 0.1796 - val_accuracy: 0.0000e+00\n",
            "Epoch 8597/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0322 - accuracy: 6.3492e-04 - val_loss: 0.1795 - val_accuracy: 0.0000e+00\n",
            "Epoch 8598/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0322 - accuracy: 6.3492e-04 - val_loss: 0.1795 - val_accuracy: 0.0000e+00\n",
            "Epoch 8599/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0322 - accuracy: 6.3492e-04 - val_loss: 0.1794 - val_accuracy: 0.0000e+00\n",
            "Epoch 8600/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0322 - accuracy: 6.3492e-04 - val_loss: 0.1794 - val_accuracy: 0.0000e+00\n",
            "Epoch 8601/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0322 - accuracy: 6.3492e-04 - val_loss: 0.1794 - val_accuracy: 0.0000e+00\n",
            "Epoch 8602/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0322 - accuracy: 6.3492e-04 - val_loss: 0.1793 - val_accuracy: 0.0000e+00\n",
            "Epoch 8603/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0321 - accuracy: 6.3492e-04 - val_loss: 0.1793 - val_accuracy: 0.0000e+00\n",
            "Epoch 8604/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0321 - accuracy: 6.3492e-04 - val_loss: 0.1792 - val_accuracy: 0.0000e+00\n",
            "Epoch 8605/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0321 - accuracy: 6.3492e-04 - val_loss: 0.1792 - val_accuracy: 0.0000e+00\n",
            "Epoch 8606/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0321 - accuracy: 6.3492e-04 - val_loss: 0.1791 - val_accuracy: 0.0000e+00\n",
            "Epoch 8607/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0321 - accuracy: 6.3492e-04 - val_loss: 0.1791 - val_accuracy: 0.0000e+00\n",
            "Epoch 8608/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0321 - accuracy: 6.3492e-04 - val_loss: 0.1790 - val_accuracy: 0.0000e+00\n",
            "Epoch 8609/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0321 - accuracy: 6.3492e-04 - val_loss: 0.1790 - val_accuracy: 0.0000e+00\n",
            "Epoch 8610/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0320 - accuracy: 6.3492e-04 - val_loss: 0.1789 - val_accuracy: 0.0000e+00\n",
            "Epoch 8611/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0320 - accuracy: 6.3492e-04 - val_loss: 0.1789 - val_accuracy: 0.0000e+00\n",
            "Epoch 8612/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0320 - accuracy: 6.3492e-04 - val_loss: 0.1788 - val_accuracy: 0.0000e+00\n",
            "Epoch 8613/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0320 - accuracy: 6.3492e-04 - val_loss: 0.1788 - val_accuracy: 0.0000e+00\n",
            "Epoch 8614/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0320 - accuracy: 6.3492e-04 - val_loss: 0.1787 - val_accuracy: 0.0000e+00\n",
            "Epoch 8615/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0320 - accuracy: 6.3492e-04 - val_loss: 0.1787 - val_accuracy: 0.0000e+00\n",
            "Epoch 8616/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0320 - accuracy: 6.3492e-04 - val_loss: 0.1787 - val_accuracy: 0.0000e+00\n",
            "Epoch 8617/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0319 - accuracy: 6.3492e-04 - val_loss: 0.1786 - val_accuracy: 0.0000e+00\n",
            "Epoch 8618/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0319 - accuracy: 6.3492e-04 - val_loss: 0.1786 - val_accuracy: 0.0000e+00\n",
            "Epoch 8619/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0319 - accuracy: 6.3492e-04 - val_loss: 0.1786 - val_accuracy: 0.0000e+00\n",
            "Epoch 8620/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0319 - accuracy: 6.3492e-04 - val_loss: 0.1785 - val_accuracy: 0.0000e+00\n",
            "Epoch 8621/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0319 - accuracy: 6.3492e-04 - val_loss: 0.1785 - val_accuracy: 0.0000e+00\n",
            "Epoch 8622/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0319 - accuracy: 6.3492e-04 - val_loss: 0.1784 - val_accuracy: 0.0000e+00\n",
            "Epoch 8623/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0319 - accuracy: 6.3492e-04 - val_loss: 0.1784 - val_accuracy: 0.0000e+00\n",
            "Epoch 8624/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0318 - accuracy: 6.3492e-04 - val_loss: 0.1784 - val_accuracy: 0.0000e+00\n",
            "Epoch 8625/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0318 - accuracy: 6.3492e-04 - val_loss: 0.1783 - val_accuracy: 0.0000e+00\n",
            "Epoch 8626/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0318 - accuracy: 6.3492e-04 - val_loss: 0.1783 - val_accuracy: 0.0000e+00\n",
            "Epoch 8627/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0318 - accuracy: 6.3492e-04 - val_loss: 0.1782 - val_accuracy: 0.0000e+00\n",
            "Epoch 8628/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0318 - accuracy: 6.3492e-04 - val_loss: 0.1782 - val_accuracy: 0.0000e+00\n",
            "Epoch 8629/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0318 - accuracy: 6.3492e-04 - val_loss: 0.1782 - val_accuracy: 0.0000e+00\n",
            "Epoch 8630/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0318 - accuracy: 6.3492e-04 - val_loss: 0.1781 - val_accuracy: 0.0000e+00\n",
            "Epoch 8631/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0318 - accuracy: 6.3492e-04 - val_loss: 0.1781 - val_accuracy: 0.0000e+00\n",
            "Epoch 8632/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0317 - accuracy: 6.3492e-04 - val_loss: 0.1780 - val_accuracy: 0.0000e+00\n",
            "Epoch 8633/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0317 - accuracy: 6.3492e-04 - val_loss: 0.1780 - val_accuracy: 0.0000e+00\n",
            "Epoch 8634/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0317 - accuracy: 6.3492e-04 - val_loss: 0.1780 - val_accuracy: 0.0000e+00\n",
            "Epoch 8635/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0317 - accuracy: 6.3492e-04 - val_loss: 0.1779 - val_accuracy: 0.0000e+00\n",
            "Epoch 8636/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0317 - accuracy: 6.3492e-04 - val_loss: 0.1779 - val_accuracy: 0.0000e+00\n",
            "Epoch 8637/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0317 - accuracy: 6.3492e-04 - val_loss: 0.1778 - val_accuracy: 0.0000e+00\n",
            "Epoch 8638/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0317 - accuracy: 6.3492e-04 - val_loss: 0.1778 - val_accuracy: 0.0000e+00\n",
            "Epoch 8639/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0316 - accuracy: 6.3492e-04 - val_loss: 0.1778 - val_accuracy: 0.0000e+00\n",
            "Epoch 8640/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0316 - accuracy: 6.3492e-04 - val_loss: 0.1777 - val_accuracy: 0.0000e+00\n",
            "Epoch 8641/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0316 - accuracy: 6.3492e-04 - val_loss: 0.1777 - val_accuracy: 0.0000e+00\n",
            "Epoch 8642/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0316 - accuracy: 6.3492e-04 - val_loss: 0.1776 - val_accuracy: 0.0000e+00\n",
            "Epoch 8643/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0316 - accuracy: 6.3492e-04 - val_loss: 0.1776 - val_accuracy: 0.0000e+00\n",
            "Epoch 8644/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0316 - accuracy: 6.3492e-04 - val_loss: 0.1776 - val_accuracy: 0.0000e+00\n",
            "Epoch 8645/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0316 - accuracy: 6.3492e-04 - val_loss: 0.1775 - val_accuracy: 0.0000e+00\n",
            "Epoch 8646/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0315 - accuracy: 6.3492e-04 - val_loss: 0.1775 - val_accuracy: 0.0000e+00\n",
            "Epoch 8647/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0315 - accuracy: 6.3492e-04 - val_loss: 0.1775 - val_accuracy: 0.0000e+00\n",
            "Epoch 8648/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0315 - accuracy: 6.3492e-04 - val_loss: 0.1774 - val_accuracy: 0.0000e+00\n",
            "Epoch 8649/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0315 - accuracy: 6.3492e-04 - val_loss: 0.1774 - val_accuracy: 0.0000e+00\n",
            "Epoch 8650/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0315 - accuracy: 6.3492e-04 - val_loss: 0.1774 - val_accuracy: 0.0000e+00\n",
            "Epoch 8651/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0315 - accuracy: 6.3492e-04 - val_loss: 0.1773 - val_accuracy: 0.0000e+00\n",
            "Epoch 8652/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0315 - accuracy: 6.3492e-04 - val_loss: 0.1773 - val_accuracy: 0.0000e+00\n",
            "Epoch 8653/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0315 - accuracy: 6.3492e-04 - val_loss: 0.1772 - val_accuracy: 0.0000e+00\n",
            "Epoch 8654/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0314 - accuracy: 6.3492e-04 - val_loss: 0.1772 - val_accuracy: 0.0000e+00\n",
            "Epoch 8655/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0314 - accuracy: 6.3492e-04 - val_loss: 0.1771 - val_accuracy: 0.0000e+00\n",
            "Epoch 8656/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0314 - accuracy: 6.3492e-04 - val_loss: 0.1771 - val_accuracy: 0.0000e+00\n",
            "Epoch 8657/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0314 - accuracy: 6.3492e-04 - val_loss: 0.1770 - val_accuracy: 0.0000e+00\n",
            "Epoch 8658/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0314 - accuracy: 6.3492e-04 - val_loss: 0.1770 - val_accuracy: 0.0000e+00\n",
            "Epoch 8659/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0314 - accuracy: 6.3492e-04 - val_loss: 0.1770 - val_accuracy: 0.0000e+00\n",
            "Epoch 8660/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0314 - accuracy: 6.3492e-04 - val_loss: 0.1769 - val_accuracy: 0.0000e+00\n",
            "Epoch 8661/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0313 - accuracy: 6.3492e-04 - val_loss: 0.1769 - val_accuracy: 0.0000e+00\n",
            "Epoch 8662/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0313 - accuracy: 6.3492e-04 - val_loss: 0.1768 - val_accuracy: 0.0000e+00\n",
            "Epoch 8663/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0313 - accuracy: 6.3492e-04 - val_loss: 0.1768 - val_accuracy: 0.0000e+00\n",
            "Epoch 8664/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0313 - accuracy: 6.3492e-04 - val_loss: 0.1767 - val_accuracy: 0.0000e+00\n",
            "Epoch 8665/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0313 - accuracy: 6.3492e-04 - val_loss: 0.1766 - val_accuracy: 0.0000e+00\n",
            "Epoch 8666/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0313 - accuracy: 6.3492e-04 - val_loss: 0.1766 - val_accuracy: 0.0000e+00\n",
            "Epoch 8667/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0313 - accuracy: 6.3492e-04 - val_loss: 0.1765 - val_accuracy: 0.0000e+00\n",
            "Epoch 8668/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0312 - accuracy: 6.3492e-04 - val_loss: 0.1765 - val_accuracy: 0.0000e+00\n",
            "Epoch 8669/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0312 - accuracy: 6.3492e-04 - val_loss: 0.1764 - val_accuracy: 0.0000e+00\n",
            "Epoch 8670/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0312 - accuracy: 6.3492e-04 - val_loss: 0.1764 - val_accuracy: 0.0000e+00\n",
            "Epoch 8671/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0312 - accuracy: 6.3492e-04 - val_loss: 0.1763 - val_accuracy: 0.0000e+00\n",
            "Epoch 8672/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0312 - accuracy: 6.3492e-04 - val_loss: 0.1763 - val_accuracy: 0.0000e+00\n",
            "Epoch 8673/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0312 - accuracy: 6.3492e-04 - val_loss: 0.1762 - val_accuracy: 0.0000e+00\n",
            "Epoch 8674/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0312 - accuracy: 6.3492e-04 - val_loss: 0.1762 - val_accuracy: 0.0000e+00\n",
            "Epoch 8675/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0312 - accuracy: 6.3492e-04 - val_loss: 0.1761 - val_accuracy: 0.0000e+00\n",
            "Epoch 8676/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0311 - accuracy: 6.3492e-04 - val_loss: 0.1761 - val_accuracy: 0.0000e+00\n",
            "Epoch 8677/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0311 - accuracy: 6.3492e-04 - val_loss: 0.1761 - val_accuracy: 0.0000e+00\n",
            "Epoch 8678/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0311 - accuracy: 6.3492e-04 - val_loss: 0.1760 - val_accuracy: 0.0000e+00\n",
            "Epoch 8679/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0311 - accuracy: 6.3492e-04 - val_loss: 0.1760 - val_accuracy: 0.0000e+00\n",
            "Epoch 8680/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0311 - accuracy: 6.3492e-04 - val_loss: 0.1759 - val_accuracy: 0.0000e+00\n",
            "Epoch 8681/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0311 - accuracy: 6.3492e-04 - val_loss: 0.1759 - val_accuracy: 0.0000e+00\n",
            "Epoch 8682/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0311 - accuracy: 6.3492e-04 - val_loss: 0.1759 - val_accuracy: 0.0000e+00\n",
            "Epoch 8683/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0310 - accuracy: 6.3492e-04 - val_loss: 0.1758 - val_accuracy: 0.0000e+00\n",
            "Epoch 8684/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0310 - accuracy: 6.3492e-04 - val_loss: 0.1758 - val_accuracy: 0.0000e+00\n",
            "Epoch 8685/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0310 - accuracy: 6.3492e-04 - val_loss: 0.1758 - val_accuracy: 0.0000e+00\n",
            "Epoch 8686/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0310 - accuracy: 6.3492e-04 - val_loss: 0.1757 - val_accuracy: 0.0000e+00\n",
            "Epoch 8687/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0310 - accuracy: 6.3492e-04 - val_loss: 0.1757 - val_accuracy: 0.0000e+00\n",
            "Epoch 8688/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0310 - accuracy: 6.3492e-04 - val_loss: 0.1756 - val_accuracy: 0.0000e+00\n",
            "Epoch 8689/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0310 - accuracy: 6.3492e-04 - val_loss: 0.1756 - val_accuracy: 0.0000e+00\n",
            "Epoch 8690/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0309 - accuracy: 6.3492e-04 - val_loss: 0.1755 - val_accuracy: 0.0000e+00\n",
            "Epoch 8691/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0309 - accuracy: 6.3492e-04 - val_loss: 0.1755 - val_accuracy: 0.0000e+00\n",
            "Epoch 8692/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0309 - accuracy: 6.3492e-04 - val_loss: 0.1754 - val_accuracy: 0.0000e+00\n",
            "Epoch 8693/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0309 - accuracy: 6.3492e-04 - val_loss: 0.1754 - val_accuracy: 0.0000e+00\n",
            "Epoch 8694/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0309 - accuracy: 6.3492e-04 - val_loss: 0.1754 - val_accuracy: 0.0000e+00\n",
            "Epoch 8695/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0309 - accuracy: 6.3492e-04 - val_loss: 0.1753 - val_accuracy: 0.0000e+00\n",
            "Epoch 8696/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0309 - accuracy: 6.3492e-04 - val_loss: 0.1753 - val_accuracy: 0.0000e+00\n",
            "Epoch 8697/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0308 - accuracy: 6.3492e-04 - val_loss: 0.1752 - val_accuracy: 0.0000e+00\n",
            "Epoch 8698/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0308 - accuracy: 6.3492e-04 - val_loss: 0.1752 - val_accuracy: 0.0000e+00\n",
            "Epoch 8699/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0308 - accuracy: 6.3492e-04 - val_loss: 0.1751 - val_accuracy: 0.0000e+00\n",
            "Epoch 8700/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0308 - accuracy: 6.3492e-04 - val_loss: 0.1751 - val_accuracy: 0.0000e+00\n",
            "Epoch 8701/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0308 - accuracy: 6.3492e-04 - val_loss: 0.1750 - val_accuracy: 0.0000e+00\n",
            "Epoch 8702/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0308 - accuracy: 6.3492e-04 - val_loss: 0.1749 - val_accuracy: 0.0000e+00\n",
            "Epoch 8703/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0308 - accuracy: 6.3492e-04 - val_loss: 0.1749 - val_accuracy: 0.0000e+00\n",
            "Epoch 8704/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0308 - accuracy: 6.3492e-04 - val_loss: 0.1748 - val_accuracy: 0.0000e+00\n",
            "Epoch 8705/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0307 - accuracy: 6.3492e-04 - val_loss: 0.1748 - val_accuracy: 0.0000e+00\n",
            "Epoch 8706/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0307 - accuracy: 6.3492e-04 - val_loss: 0.1747 - val_accuracy: 0.0000e+00\n",
            "Epoch 8707/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0307 - accuracy: 6.3492e-04 - val_loss: 0.1747 - val_accuracy: 0.0000e+00\n",
            "Epoch 8708/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0307 - accuracy: 6.3492e-04 - val_loss: 0.1747 - val_accuracy: 0.0000e+00\n",
            "Epoch 8709/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0307 - accuracy: 6.3492e-04 - val_loss: 0.1746 - val_accuracy: 0.0000e+00\n",
            "Epoch 8710/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0307 - accuracy: 6.3492e-04 - val_loss: 0.1746 - val_accuracy: 0.0000e+00\n",
            "Epoch 8711/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0307 - accuracy: 6.3492e-04 - val_loss: 0.1745 - val_accuracy: 0.0000e+00\n",
            "Epoch 8712/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0306 - accuracy: 6.3492e-04 - val_loss: 0.1745 - val_accuracy: 0.0000e+00\n",
            "Epoch 8713/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0306 - accuracy: 6.3492e-04 - val_loss: 0.1744 - val_accuracy: 0.0000e+00\n",
            "Epoch 8714/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0306 - accuracy: 6.3492e-04 - val_loss: 0.1744 - val_accuracy: 0.0000e+00\n",
            "Epoch 8715/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0306 - accuracy: 6.3492e-04 - val_loss: 0.1743 - val_accuracy: 0.0000e+00\n",
            "Epoch 8716/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0306 - accuracy: 6.3492e-04 - val_loss: 0.1743 - val_accuracy: 0.0000e+00\n",
            "Epoch 8717/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0306 - accuracy: 6.3492e-04 - val_loss: 0.1742 - val_accuracy: 0.0000e+00\n",
            "Epoch 8718/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0306 - accuracy: 6.3492e-04 - val_loss: 0.1742 - val_accuracy: 0.0000e+00\n",
            "Epoch 8719/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0305 - accuracy: 6.3492e-04 - val_loss: 0.1741 - val_accuracy: 0.0000e+00\n",
            "Epoch 8720/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0305 - accuracy: 6.3492e-04 - val_loss: 0.1741 - val_accuracy: 0.0000e+00\n",
            "Epoch 8721/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0305 - accuracy: 6.3492e-04 - val_loss: 0.1740 - val_accuracy: 0.0000e+00\n",
            "Epoch 8722/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0305 - accuracy: 6.3492e-04 - val_loss: 0.1740 - val_accuracy: 0.0000e+00\n",
            "Epoch 8723/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0305 - accuracy: 6.3492e-04 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
            "Epoch 8724/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0305 - accuracy: 6.3492e-04 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
            "Epoch 8725/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0305 - accuracy: 6.3492e-04 - val_loss: 0.1738 - val_accuracy: 0.0000e+00\n",
            "Epoch 8726/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0305 - accuracy: 6.3492e-04 - val_loss: 0.1738 - val_accuracy: 0.0000e+00\n",
            "Epoch 8727/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0304 - accuracy: 6.3492e-04 - val_loss: 0.1737 - val_accuracy: 0.0000e+00\n",
            "Epoch 8728/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0304 - accuracy: 6.3492e-04 - val_loss: 0.1736 - val_accuracy: 0.0000e+00\n",
            "Epoch 8729/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0304 - accuracy: 6.3492e-04 - val_loss: 0.1736 - val_accuracy: 0.0000e+00\n",
            "Epoch 8730/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0304 - accuracy: 6.3492e-04 - val_loss: 0.1735 - val_accuracy: 0.0000e+00\n",
            "Epoch 8731/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0304 - accuracy: 6.3492e-04 - val_loss: 0.1735 - val_accuracy: 0.0000e+00\n",
            "Epoch 8732/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0304 - accuracy: 6.3492e-04 - val_loss: 0.1734 - val_accuracy: 0.0000e+00\n",
            "Epoch 8733/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0304 - accuracy: 6.3492e-04 - val_loss: 0.1734 - val_accuracy: 0.0000e+00\n",
            "Epoch 8734/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0303 - accuracy: 6.3492e-04 - val_loss: 0.1733 - val_accuracy: 0.0000e+00\n",
            "Epoch 8735/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0303 - accuracy: 6.3492e-04 - val_loss: 0.1733 - val_accuracy: 0.0000e+00\n",
            "Epoch 8736/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0303 - accuracy: 6.3492e-04 - val_loss: 0.1732 - val_accuracy: 0.0000e+00\n",
            "Epoch 8737/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0303 - accuracy: 6.3492e-04 - val_loss: 0.1732 - val_accuracy: 0.0000e+00\n",
            "Epoch 8738/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0303 - accuracy: 6.3492e-04 - val_loss: 0.1732 - val_accuracy: 0.0000e+00\n",
            "Epoch 8739/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0303 - accuracy: 6.3492e-04 - val_loss: 0.1731 - val_accuracy: 0.0000e+00\n",
            "Epoch 8740/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0303 - accuracy: 6.3492e-04 - val_loss: 0.1731 - val_accuracy: 0.0000e+00\n",
            "Epoch 8741/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0302 - accuracy: 6.3492e-04 - val_loss: 0.1730 - val_accuracy: 0.0000e+00\n",
            "Epoch 8742/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0302 - accuracy: 6.3492e-04 - val_loss: 0.1730 - val_accuracy: 0.0000e+00\n",
            "Epoch 8743/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0302 - accuracy: 6.3492e-04 - val_loss: 0.1729 - val_accuracy: 0.0000e+00\n",
            "Epoch 8744/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0302 - accuracy: 6.3492e-04 - val_loss: 0.1729 - val_accuracy: 0.0000e+00\n",
            "Epoch 8745/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0302 - accuracy: 6.3492e-04 - val_loss: 0.1728 - val_accuracy: 0.0000e+00\n",
            "Epoch 8746/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0302 - accuracy: 6.3492e-04 - val_loss: 0.1728 - val_accuracy: 0.0000e+00\n",
            "Epoch 8747/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0302 - accuracy: 6.3492e-04 - val_loss: 0.1727 - val_accuracy: 0.0000e+00\n",
            "Epoch 8748/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0302 - accuracy: 6.3492e-04 - val_loss: 0.1727 - val_accuracy: 0.0000e+00\n",
            "Epoch 8749/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0301 - accuracy: 6.3492e-04 - val_loss: 0.1726 - val_accuracy: 0.0000e+00\n",
            "Epoch 8750/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0301 - accuracy: 6.3492e-04 - val_loss: 0.1726 - val_accuracy: 0.0000e+00\n",
            "Epoch 8751/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0301 - accuracy: 6.3492e-04 - val_loss: 0.1725 - val_accuracy: 0.0000e+00\n",
            "Epoch 8752/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0301 - accuracy: 6.3492e-04 - val_loss: 0.1725 - val_accuracy: 0.0000e+00\n",
            "Epoch 8753/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0301 - accuracy: 6.3492e-04 - val_loss: 0.1724 - val_accuracy: 0.0000e+00\n",
            "Epoch 8754/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0301 - accuracy: 6.3492e-04 - val_loss: 0.1724 - val_accuracy: 0.0000e+00\n",
            "Epoch 8755/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0301 - accuracy: 6.3492e-04 - val_loss: 0.1723 - val_accuracy: 0.0000e+00\n",
            "Epoch 8756/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0300 - accuracy: 6.3492e-04 - val_loss: 0.1723 - val_accuracy: 0.0000e+00\n",
            "Epoch 8757/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0300 - accuracy: 6.3492e-04 - val_loss: 0.1722 - val_accuracy: 0.0000e+00\n",
            "Epoch 8758/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0300 - accuracy: 6.3492e-04 - val_loss: 0.1722 - val_accuracy: 0.0000e+00\n",
            "Epoch 8759/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0300 - accuracy: 6.3492e-04 - val_loss: 0.1722 - val_accuracy: 0.0000e+00\n",
            "Epoch 8760/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0300 - accuracy: 6.3492e-04 - val_loss: 0.1721 - val_accuracy: 0.0000e+00\n",
            "Epoch 8761/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0300 - accuracy: 6.3492e-04 - val_loss: 0.1721 - val_accuracy: 0.0000e+00\n",
            "Epoch 8762/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0300 - accuracy: 6.3492e-04 - val_loss: 0.1720 - val_accuracy: 0.0000e+00\n",
            "Epoch 8763/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0299 - accuracy: 6.3492e-04 - val_loss: 0.1720 - val_accuracy: 0.0000e+00\n",
            "Epoch 8764/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0299 - accuracy: 6.3492e-04 - val_loss: 0.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 8765/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0299 - accuracy: 6.3492e-04 - val_loss: 0.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 8766/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0299 - accuracy: 6.3492e-04 - val_loss: 0.1718 - val_accuracy: 0.0000e+00\n",
            "Epoch 8767/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0299 - accuracy: 6.3492e-04 - val_loss: 0.1718 - val_accuracy: 0.0000e+00\n",
            "Epoch 8768/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0299 - accuracy: 6.3492e-04 - val_loss: 0.1717 - val_accuracy: 0.0000e+00\n",
            "Epoch 8769/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0299 - accuracy: 6.3492e-04 - val_loss: 0.1717 - val_accuracy: 0.0000e+00\n",
            "Epoch 8770/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0299 - accuracy: 6.3492e-04 - val_loss: 0.1716 - val_accuracy: 0.0000e+00\n",
            "Epoch 8771/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0298 - accuracy: 6.3492e-04 - val_loss: 0.1716 - val_accuracy: 0.0000e+00\n",
            "Epoch 8772/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0298 - accuracy: 6.3492e-04 - val_loss: 0.1715 - val_accuracy: 0.0000e+00\n",
            "Epoch 8773/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0298 - accuracy: 6.3492e-04 - val_loss: 0.1715 - val_accuracy: 0.0000e+00\n",
            "Epoch 8774/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0298 - accuracy: 6.3492e-04 - val_loss: 0.1714 - val_accuracy: 0.0000e+00\n",
            "Epoch 8775/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0298 - accuracy: 6.3492e-04 - val_loss: 0.1714 - val_accuracy: 0.0000e+00\n",
            "Epoch 8776/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0298 - accuracy: 6.3492e-04 - val_loss: 0.1713 - val_accuracy: 0.0000e+00\n",
            "Epoch 8777/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0298 - accuracy: 6.3492e-04 - val_loss: 0.1713 - val_accuracy: 0.0000e+00\n",
            "Epoch 8778/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0297 - accuracy: 6.3492e-04 - val_loss: 0.1712 - val_accuracy: 0.0000e+00\n",
            "Epoch 8779/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0297 - accuracy: 6.3492e-04 - val_loss: 0.1712 - val_accuracy: 0.0000e+00\n",
            "Epoch 8780/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0297 - accuracy: 6.3492e-04 - val_loss: 0.1711 - val_accuracy: 0.0000e+00\n",
            "Epoch 8781/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0297 - accuracy: 6.3492e-04 - val_loss: 0.1711 - val_accuracy: 0.0000e+00\n",
            "Epoch 8782/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0297 - accuracy: 6.3492e-04 - val_loss: 0.1710 - val_accuracy: 0.0000e+00\n",
            "Epoch 8783/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0297 - accuracy: 6.3492e-04 - val_loss: 0.1710 - val_accuracy: 0.0000e+00\n",
            "Epoch 8784/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0297 - accuracy: 6.3492e-04 - val_loss: 0.1709 - val_accuracy: 0.0000e+00\n",
            "Epoch 8785/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0296 - accuracy: 6.3492e-04 - val_loss: 0.1709 - val_accuracy: 0.0000e+00\n",
            "Epoch 8786/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0296 - accuracy: 6.3492e-04 - val_loss: 0.1708 - val_accuracy: 0.0000e+00\n",
            "Epoch 8787/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0296 - accuracy: 6.3492e-04 - val_loss: 0.1708 - val_accuracy: 0.0000e+00\n",
            "Epoch 8788/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0296 - accuracy: 6.3492e-04 - val_loss: 0.1707 - val_accuracy: 0.0000e+00\n",
            "Epoch 8789/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0296 - accuracy: 6.3492e-04 - val_loss: 0.1707 - val_accuracy: 0.0000e+00\n",
            "Epoch 8790/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0296 - accuracy: 6.3492e-04 - val_loss: 0.1706 - val_accuracy: 0.0000e+00\n",
            "Epoch 8791/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0296 - accuracy: 6.3492e-04 - val_loss: 0.1706 - val_accuracy: 0.0000e+00\n",
            "Epoch 8792/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0296 - accuracy: 6.3492e-04 - val_loss: 0.1705 - val_accuracy: 0.0000e+00\n",
            "Epoch 8793/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0295 - accuracy: 6.3492e-04 - val_loss: 0.1705 - val_accuracy: 0.0000e+00\n",
            "Epoch 8794/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0295 - accuracy: 6.3492e-04 - val_loss: 0.1704 - val_accuracy: 0.0000e+00\n",
            "Epoch 8795/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0295 - accuracy: 6.3492e-04 - val_loss: 0.1704 - val_accuracy: 0.0000e+00\n",
            "Epoch 8796/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0295 - accuracy: 6.3492e-04 - val_loss: 0.1703 - val_accuracy: 0.0000e+00\n",
            "Epoch 8797/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0295 - accuracy: 6.3492e-04 - val_loss: 0.1703 - val_accuracy: 0.0000e+00\n",
            "Epoch 8798/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0295 - accuracy: 6.3492e-04 - val_loss: 0.1702 - val_accuracy: 0.0000e+00\n",
            "Epoch 8799/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0295 - accuracy: 6.3492e-04 - val_loss: 0.1701 - val_accuracy: 0.0000e+00\n",
            "Epoch 8800/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0294 - accuracy: 6.3492e-04 - val_loss: 0.1701 - val_accuracy: 0.0000e+00\n",
            "Epoch 8801/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0294 - accuracy: 6.3492e-04 - val_loss: 0.1700 - val_accuracy: 0.0000e+00\n",
            "Epoch 8802/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0294 - accuracy: 6.3492e-04 - val_loss: 0.1700 - val_accuracy: 0.0000e+00\n",
            "Epoch 8803/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0294 - accuracy: 6.3492e-04 - val_loss: 0.1699 - val_accuracy: 0.0000e+00\n",
            "Epoch 8804/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0294 - accuracy: 6.3492e-04 - val_loss: 0.1699 - val_accuracy: 0.0000e+00\n",
            "Epoch 8805/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0294 - accuracy: 6.3492e-04 - val_loss: 0.1698 - val_accuracy: 0.0000e+00\n",
            "Epoch 8806/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0294 - accuracy: 6.3492e-04 - val_loss: 0.1697 - val_accuracy: 0.0000e+00\n",
            "Epoch 8807/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0293 - accuracy: 6.3492e-04 - val_loss: 0.1697 - val_accuracy: 0.0000e+00\n",
            "Epoch 8808/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0293 - accuracy: 6.3492e-04 - val_loss: 0.1696 - val_accuracy: 0.0000e+00\n",
            "Epoch 8809/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0293 - accuracy: 6.3492e-04 - val_loss: 0.1696 - val_accuracy: 0.0000e+00\n",
            "Epoch 8810/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0293 - accuracy: 6.3492e-04 - val_loss: 0.1695 - val_accuracy: 0.0000e+00\n",
            "Epoch 8811/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0293 - accuracy: 6.3492e-04 - val_loss: 0.1694 - val_accuracy: 0.0000e+00\n",
            "Epoch 8812/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0293 - accuracy: 6.3492e-04 - val_loss: 0.1694 - val_accuracy: 0.0000e+00\n",
            "Epoch 8813/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0293 - accuracy: 6.3492e-04 - val_loss: 0.1693 - val_accuracy: 0.0000e+00\n",
            "Epoch 8814/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0293 - accuracy: 6.3492e-04 - val_loss: 0.1693 - val_accuracy: 0.0000e+00\n",
            "Epoch 8815/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0292 - accuracy: 6.3492e-04 - val_loss: 0.1692 - val_accuracy: 0.0000e+00\n",
            "Epoch 8816/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0292 - accuracy: 6.3492e-04 - val_loss: 0.1692 - val_accuracy: 0.0000e+00\n",
            "Epoch 8817/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0292 - accuracy: 6.3492e-04 - val_loss: 0.1691 - val_accuracy: 0.0000e+00\n",
            "Epoch 8818/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0292 - accuracy: 6.3492e-04 - val_loss: 0.1690 - val_accuracy: 0.0000e+00\n",
            "Epoch 8819/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0292 - accuracy: 6.3492e-04 - val_loss: 0.1690 - val_accuracy: 0.0000e+00\n",
            "Epoch 8820/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0292 - accuracy: 6.3492e-04 - val_loss: 0.1689 - val_accuracy: 0.0000e+00\n",
            "Epoch 8821/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0292 - accuracy: 6.3492e-04 - val_loss: 0.1689 - val_accuracy: 0.0000e+00\n",
            "Epoch 8822/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0291 - accuracy: 6.3492e-04 - val_loss: 0.1688 - val_accuracy: 0.0000e+00\n",
            "Epoch 8823/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0291 - accuracy: 6.3492e-04 - val_loss: 0.1687 - val_accuracy: 0.0000e+00\n",
            "Epoch 8824/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0291 - accuracy: 6.3492e-04 - val_loss: 0.1687 - val_accuracy: 0.0000e+00\n",
            "Epoch 8825/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0291 - accuracy: 6.3492e-04 - val_loss: 0.1686 - val_accuracy: 0.0000e+00\n",
            "Epoch 8826/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0291 - accuracy: 6.3492e-04 - val_loss: 0.1686 - val_accuracy: 0.0000e+00\n",
            "Epoch 8827/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0291 - accuracy: 6.3492e-04 - val_loss: 0.1685 - val_accuracy: 0.0000e+00\n",
            "Epoch 8828/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0291 - accuracy: 6.3492e-04 - val_loss: 0.1685 - val_accuracy: 0.0000e+00\n",
            "Epoch 8829/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0290 - accuracy: 6.3492e-04 - val_loss: 0.1684 - val_accuracy: 0.0000e+00\n",
            "Epoch 8830/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0290 - accuracy: 6.3492e-04 - val_loss: 0.1683 - val_accuracy: 0.0000e+00\n",
            "Epoch 8831/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0290 - accuracy: 6.3492e-04 - val_loss: 0.1683 - val_accuracy: 0.0000e+00\n",
            "Epoch 8832/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0290 - accuracy: 6.3492e-04 - val_loss: 0.1682 - val_accuracy: 0.0000e+00\n",
            "Epoch 8833/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0290 - accuracy: 6.3492e-04 - val_loss: 0.1682 - val_accuracy: 0.0000e+00\n",
            "Epoch 8834/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0290 - accuracy: 6.3492e-04 - val_loss: 0.1681 - val_accuracy: 0.0000e+00\n",
            "Epoch 8835/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0290 - accuracy: 6.3492e-04 - val_loss: 0.1680 - val_accuracy: 0.0000e+00\n",
            "Epoch 8836/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0290 - accuracy: 6.3492e-04 - val_loss: 0.1680 - val_accuracy: 0.0000e+00\n",
            "Epoch 8837/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0289 - accuracy: 6.3492e-04 - val_loss: 0.1679 - val_accuracy: 0.0000e+00\n",
            "Epoch 8838/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0289 - accuracy: 6.3492e-04 - val_loss: 0.1679 - val_accuracy: 0.0000e+00\n",
            "Epoch 8839/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0289 - accuracy: 6.3492e-04 - val_loss: 0.1678 - val_accuracy: 0.0000e+00\n",
            "Epoch 8840/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0289 - accuracy: 6.3492e-04 - val_loss: 0.1677 - val_accuracy: 0.0000e+00\n",
            "Epoch 8841/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0289 - accuracy: 6.3492e-04 - val_loss: 0.1677 - val_accuracy: 0.0000e+00\n",
            "Epoch 8842/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0289 - accuracy: 6.3492e-04 - val_loss: 0.1676 - val_accuracy: 0.0000e+00\n",
            "Epoch 8843/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0289 - accuracy: 6.3492e-04 - val_loss: 0.1676 - val_accuracy: 0.0000e+00\n",
            "Epoch 8844/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0288 - accuracy: 6.3492e-04 - val_loss: 0.1675 - val_accuracy: 0.0000e+00\n",
            "Epoch 8845/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0288 - accuracy: 6.3492e-04 - val_loss: 0.1675 - val_accuracy: 0.0000e+00\n",
            "Epoch 8846/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0288 - accuracy: 6.3492e-04 - val_loss: 0.1674 - val_accuracy: 0.0000e+00\n",
            "Epoch 8847/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0288 - accuracy: 6.3492e-04 - val_loss: 0.1673 - val_accuracy: 0.0000e+00\n",
            "Epoch 8848/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0288 - accuracy: 6.3492e-04 - val_loss: 0.1673 - val_accuracy: 0.0000e+00\n",
            "Epoch 8849/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0288 - accuracy: 6.3492e-04 - val_loss: 0.1672 - val_accuracy: 0.0000e+00\n",
            "Epoch 8850/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0288 - accuracy: 6.3492e-04 - val_loss: 0.1672 - val_accuracy: 0.0000e+00\n",
            "Epoch 8851/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0287 - accuracy: 6.3492e-04 - val_loss: 0.1671 - val_accuracy: 0.0000e+00\n",
            "Epoch 8852/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0287 - accuracy: 6.3492e-04 - val_loss: 0.1670 - val_accuracy: 0.0000e+00\n",
            "Epoch 8853/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0287 - accuracy: 6.3492e-04 - val_loss: 0.1670 - val_accuracy: 0.0000e+00\n",
            "Epoch 8854/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0287 - accuracy: 6.3492e-04 - val_loss: 0.1669 - val_accuracy: 0.0000e+00\n",
            "Epoch 8855/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0287 - accuracy: 6.3492e-04 - val_loss: 0.1669 - val_accuracy: 0.0000e+00\n",
            "Epoch 8856/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0287 - accuracy: 6.3492e-04 - val_loss: 0.1668 - val_accuracy: 0.0000e+00\n",
            "Epoch 8857/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0287 - accuracy: 6.3492e-04 - val_loss: 0.1667 - val_accuracy: 0.0000e+00\n",
            "Epoch 8858/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0287 - accuracy: 6.3492e-04 - val_loss: 0.1667 - val_accuracy: 0.0000e+00\n",
            "Epoch 8859/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0286 - accuracy: 6.3492e-04 - val_loss: 0.1666 - val_accuracy: 0.0000e+00\n",
            "Epoch 8860/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0286 - accuracy: 6.3492e-04 - val_loss: 0.1666 - val_accuracy: 0.0000e+00\n",
            "Epoch 8861/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0286 - accuracy: 6.3492e-04 - val_loss: 0.1665 - val_accuracy: 0.0000e+00\n",
            "Epoch 8862/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0286 - accuracy: 6.3492e-04 - val_loss: 0.1664 - val_accuracy: 0.0000e+00\n",
            "Epoch 8863/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0286 - accuracy: 6.3492e-04 - val_loss: 0.1664 - val_accuracy: 0.0000e+00\n",
            "Epoch 8864/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0286 - accuracy: 6.3492e-04 - val_loss: 0.1663 - val_accuracy: 0.0000e+00\n",
            "Epoch 8865/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0286 - accuracy: 6.3492e-04 - val_loss: 0.1663 - val_accuracy: 0.0000e+00\n",
            "Epoch 8866/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0285 - accuracy: 6.3492e-04 - val_loss: 0.1662 - val_accuracy: 0.0000e+00\n",
            "Epoch 8867/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0285 - accuracy: 6.3492e-04 - val_loss: 0.1662 - val_accuracy: 0.0000e+00\n",
            "Epoch 8868/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0285 - accuracy: 6.3492e-04 - val_loss: 0.1661 - val_accuracy: 0.0000e+00\n",
            "Epoch 8869/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0285 - accuracy: 6.3492e-04 - val_loss: 0.1661 - val_accuracy: 0.0000e+00\n",
            "Epoch 8870/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0285 - accuracy: 6.3492e-04 - val_loss: 0.1660 - val_accuracy: 0.0000e+00\n",
            "Epoch 8871/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0285 - accuracy: 6.3492e-04 - val_loss: 0.1660 - val_accuracy: 0.0000e+00\n",
            "Epoch 8872/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0285 - accuracy: 6.3492e-04 - val_loss: 0.1659 - val_accuracy: 0.0000e+00\n",
            "Epoch 8873/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0284 - accuracy: 6.3492e-04 - val_loss: 0.1659 - val_accuracy: 0.0000e+00\n",
            "Epoch 8874/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0284 - accuracy: 6.3492e-04 - val_loss: 0.1658 - val_accuracy: 0.0000e+00\n",
            "Epoch 8875/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0284 - accuracy: 6.3492e-04 - val_loss: 0.1658 - val_accuracy: 0.0000e+00\n",
            "Epoch 8876/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0284 - accuracy: 6.3492e-04 - val_loss: 0.1657 - val_accuracy: 0.0000e+00\n",
            "Epoch 8877/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0284 - accuracy: 6.3492e-04 - val_loss: 0.1657 - val_accuracy: 0.0000e+00\n",
            "Epoch 8878/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0284 - accuracy: 6.3492e-04 - val_loss: 0.1656 - val_accuracy: 0.0000e+00\n",
            "Epoch 8879/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0284 - accuracy: 6.3492e-04 - val_loss: 0.1656 - val_accuracy: 0.0000e+00\n",
            "Epoch 8880/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0284 - accuracy: 6.3492e-04 - val_loss: 0.1655 - val_accuracy: 0.0000e+00\n",
            "Epoch 8881/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0283 - accuracy: 6.3492e-04 - val_loss: 0.1655 - val_accuracy: 0.0000e+00\n",
            "Epoch 8882/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0283 - accuracy: 6.3492e-04 - val_loss: 0.1654 - val_accuracy: 0.0000e+00\n",
            "Epoch 8883/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0283 - accuracy: 6.3492e-04 - val_loss: 0.1653 - val_accuracy: 0.0000e+00\n",
            "Epoch 8884/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0283 - accuracy: 6.3492e-04 - val_loss: 0.1653 - val_accuracy: 0.0000e+00\n",
            "Epoch 8885/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0283 - accuracy: 6.3492e-04 - val_loss: 0.1652 - val_accuracy: 0.0000e+00\n",
            "Epoch 8886/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0283 - accuracy: 6.3492e-04 - val_loss: 0.1652 - val_accuracy: 0.0000e+00\n",
            "Epoch 8887/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0283 - accuracy: 6.3492e-04 - val_loss: 0.1651 - val_accuracy: 0.0000e+00\n",
            "Epoch 8888/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0282 - accuracy: 6.3492e-04 - val_loss: 0.1651 - val_accuracy: 0.0000e+00\n",
            "Epoch 8889/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0282 - accuracy: 6.3492e-04 - val_loss: 0.1650 - val_accuracy: 0.0000e+00\n",
            "Epoch 8890/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0282 - accuracy: 6.3492e-04 - val_loss: 0.1650 - val_accuracy: 0.0000e+00\n",
            "Epoch 8891/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0282 - accuracy: 6.3492e-04 - val_loss: 0.1649 - val_accuracy: 0.0000e+00\n",
            "Epoch 8892/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0282 - accuracy: 6.3492e-04 - val_loss: 0.1649 - val_accuracy: 0.0000e+00\n",
            "Epoch 8893/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0282 - accuracy: 6.3492e-04 - val_loss: 0.1648 - val_accuracy: 0.0000e+00\n",
            "Epoch 8894/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0282 - accuracy: 6.3492e-04 - val_loss: 0.1648 - val_accuracy: 0.0000e+00\n",
            "Epoch 8895/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0281 - accuracy: 6.3492e-04 - val_loss: 0.1647 - val_accuracy: 0.0000e+00\n",
            "Epoch 8896/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0281 - accuracy: 6.3492e-04 - val_loss: 0.1647 - val_accuracy: 0.0000e+00\n",
            "Epoch 8897/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0281 - accuracy: 6.3492e-04 - val_loss: 0.1646 - val_accuracy: 0.0000e+00\n",
            "Epoch 8898/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0281 - accuracy: 6.3492e-04 - val_loss: 0.1646 - val_accuracy: 0.0000e+00\n",
            "Epoch 8899/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0281 - accuracy: 6.3492e-04 - val_loss: 0.1645 - val_accuracy: 0.0000e+00\n",
            "Epoch 8900/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0281 - accuracy: 6.3492e-04 - val_loss: 0.1644 - val_accuracy: 0.0000e+00\n",
            "Epoch 8901/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0281 - accuracy: 6.3492e-04 - val_loss: 0.1644 - val_accuracy: 0.0000e+00\n",
            "Epoch 8902/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0281 - accuracy: 6.3492e-04 - val_loss: 0.1643 - val_accuracy: 0.0000e+00\n",
            "Epoch 8903/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0280 - accuracy: 6.3492e-04 - val_loss: 0.1643 - val_accuracy: 0.0000e+00\n",
            "Epoch 8904/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0280 - accuracy: 6.3492e-04 - val_loss: 0.1642 - val_accuracy: 0.0000e+00\n",
            "Epoch 8905/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0280 - accuracy: 6.3492e-04 - val_loss: 0.1642 - val_accuracy: 0.0000e+00\n",
            "Epoch 8906/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0280 - accuracy: 6.3492e-04 - val_loss: 0.1641 - val_accuracy: 0.0000e+00\n",
            "Epoch 8907/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0280 - accuracy: 6.3492e-04 - val_loss: 0.1640 - val_accuracy: 0.0000e+00\n",
            "Epoch 8908/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0280 - accuracy: 6.3492e-04 - val_loss: 0.1640 - val_accuracy: 0.0000e+00\n",
            "Epoch 8909/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0280 - accuracy: 6.3492e-04 - val_loss: 0.1639 - val_accuracy: 0.0000e+00\n",
            "Epoch 8910/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0279 - accuracy: 6.3492e-04 - val_loss: 0.1639 - val_accuracy: 0.0000e+00\n",
            "Epoch 8911/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0279 - accuracy: 6.3492e-04 - val_loss: 0.1638 - val_accuracy: 0.0000e+00\n",
            "Epoch 8912/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0279 - accuracy: 6.3492e-04 - val_loss: 0.1638 - val_accuracy: 0.0000e+00\n",
            "Epoch 8913/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0279 - accuracy: 6.3492e-04 - val_loss: 0.1637 - val_accuracy: 0.0000e+00\n",
            "Epoch 8914/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0279 - accuracy: 6.3492e-04 - val_loss: 0.1636 - val_accuracy: 0.0000e+00\n",
            "Epoch 8915/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0279 - accuracy: 6.3492e-04 - val_loss: 0.1636 - val_accuracy: 0.0000e+00\n",
            "Epoch 8916/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0279 - accuracy: 6.3492e-04 - val_loss: 0.1635 - val_accuracy: 0.0000e+00\n",
            "Epoch 8917/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0278 - accuracy: 6.3492e-04 - val_loss: 0.1635 - val_accuracy: 0.0000e+00\n",
            "Epoch 8918/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0278 - accuracy: 6.3492e-04 - val_loss: 0.1634 - val_accuracy: 0.0000e+00\n",
            "Epoch 8919/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0278 - accuracy: 6.3492e-04 - val_loss: 0.1633 - val_accuracy: 0.0000e+00\n",
            "Epoch 8920/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0278 - accuracy: 6.3492e-04 - val_loss: 0.1633 - val_accuracy: 0.0000e+00\n",
            "Epoch 8921/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0278 - accuracy: 6.3492e-04 - val_loss: 0.1632 - val_accuracy: 0.0000e+00\n",
            "Epoch 8922/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0278 - accuracy: 6.3492e-04 - val_loss: 0.1632 - val_accuracy: 0.0000e+00\n",
            "Epoch 8923/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0278 - accuracy: 6.3492e-04 - val_loss: 0.1631 - val_accuracy: 0.0000e+00\n",
            "Epoch 8924/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0278 - accuracy: 6.3492e-04 - val_loss: 0.1630 - val_accuracy: 0.0000e+00\n",
            "Epoch 8925/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0277 - accuracy: 6.3492e-04 - val_loss: 0.1630 - val_accuracy: 0.0000e+00\n",
            "Epoch 8926/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0277 - accuracy: 6.3492e-04 - val_loss: 0.1629 - val_accuracy: 0.0000e+00\n",
            "Epoch 8927/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0277 - accuracy: 6.3492e-04 - val_loss: 0.1629 - val_accuracy: 0.0000e+00\n",
            "Epoch 8928/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0277 - accuracy: 6.3492e-04 - val_loss: 0.1628 - val_accuracy: 0.0000e+00\n",
            "Epoch 8929/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0277 - accuracy: 6.3492e-04 - val_loss: 0.1628 - val_accuracy: 0.0000e+00\n",
            "Epoch 8930/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0277 - accuracy: 6.3492e-04 - val_loss: 0.1627 - val_accuracy: 0.0000e+00\n",
            "Epoch 8931/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0277 - accuracy: 6.3492e-04 - val_loss: 0.1626 - val_accuracy: 0.0000e+00\n",
            "Epoch 8932/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0276 - accuracy: 6.3492e-04 - val_loss: 0.1626 - val_accuracy: 0.0000e+00\n",
            "Epoch 8933/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0276 - accuracy: 6.3492e-04 - val_loss: 0.1625 - val_accuracy: 0.0000e+00\n",
            "Epoch 8934/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0276 - accuracy: 6.3492e-04 - val_loss: 0.1625 - val_accuracy: 0.0000e+00\n",
            "Epoch 8935/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0276 - accuracy: 6.3492e-04 - val_loss: 0.1624 - val_accuracy: 0.0000e+00\n",
            "Epoch 8936/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0276 - accuracy: 6.3492e-04 - val_loss: 0.1624 - val_accuracy: 0.0000e+00\n",
            "Epoch 8937/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0276 - accuracy: 6.3492e-04 - val_loss: 0.1623 - val_accuracy: 0.0000e+00\n",
            "Epoch 8938/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0276 - accuracy: 6.3492e-04 - val_loss: 0.1623 - val_accuracy: 0.0000e+00\n",
            "Epoch 8939/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0275 - accuracy: 6.3492e-04 - val_loss: 0.1622 - val_accuracy: 0.0000e+00\n",
            "Epoch 8940/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0275 - accuracy: 6.3492e-04 - val_loss: 0.1622 - val_accuracy: 0.0000e+00\n",
            "Epoch 8941/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0275 - accuracy: 6.3492e-04 - val_loss: 0.1621 - val_accuracy: 0.0000e+00\n",
            "Epoch 8942/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0275 - accuracy: 6.3492e-04 - val_loss: 0.1621 - val_accuracy: 0.0000e+00\n",
            "Epoch 8943/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0275 - accuracy: 6.3492e-04 - val_loss: 0.1620 - val_accuracy: 0.0000e+00\n",
            "Epoch 8944/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0275 - accuracy: 6.3492e-04 - val_loss: 0.1620 - val_accuracy: 0.0000e+00\n",
            "Epoch 8945/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0275 - accuracy: 6.3492e-04 - val_loss: 0.1619 - val_accuracy: 0.0000e+00\n",
            "Epoch 8946/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0275 - accuracy: 6.3492e-04 - val_loss: 0.1619 - val_accuracy: 0.0000e+00\n",
            "Epoch 8947/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0274 - accuracy: 6.3492e-04 - val_loss: 0.1618 - val_accuracy: 0.0000e+00\n",
            "Epoch 8948/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0274 - accuracy: 6.3492e-04 - val_loss: 0.1618 - val_accuracy: 0.0000e+00\n",
            "Epoch 8949/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0274 - accuracy: 6.3492e-04 - val_loss: 0.1617 - val_accuracy: 0.0000e+00\n",
            "Epoch 8950/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0274 - accuracy: 6.3492e-04 - val_loss: 0.1617 - val_accuracy: 0.0000e+00\n",
            "Epoch 8951/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0274 - accuracy: 6.3492e-04 - val_loss: 0.1616 - val_accuracy: 0.0000e+00\n",
            "Epoch 8952/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0274 - accuracy: 6.3492e-04 - val_loss: 0.1616 - val_accuracy: 0.0000e+00\n",
            "Epoch 8953/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0274 - accuracy: 6.3492e-04 - val_loss: 0.1615 - val_accuracy: 0.0000e+00\n",
            "Epoch 8954/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0273 - accuracy: 6.3492e-04 - val_loss: 0.1614 - val_accuracy: 0.0000e+00\n",
            "Epoch 8955/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0273 - accuracy: 6.3492e-04 - val_loss: 0.1614 - val_accuracy: 0.0000e+00\n",
            "Epoch 8956/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0273 - accuracy: 6.3492e-04 - val_loss: 0.1613 - val_accuracy: 0.0000e+00\n",
            "Epoch 8957/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0273 - accuracy: 6.3492e-04 - val_loss: 0.1613 - val_accuracy: 0.0000e+00\n",
            "Epoch 8958/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0273 - accuracy: 6.3492e-04 - val_loss: 0.1612 - val_accuracy: 0.0000e+00\n",
            "Epoch 8959/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0273 - accuracy: 6.3492e-04 - val_loss: 0.1612 - val_accuracy: 0.0000e+00\n",
            "Epoch 8960/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0273 - accuracy: 6.3492e-04 - val_loss: 0.1611 - val_accuracy: 0.0000e+00\n",
            "Epoch 8961/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0272 - accuracy: 6.3492e-04 - val_loss: 0.1611 - val_accuracy: 0.0000e+00\n",
            "Epoch 8962/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0272 - accuracy: 6.3492e-04 - val_loss: 0.1610 - val_accuracy: 0.0000e+00\n",
            "Epoch 8963/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0272 - accuracy: 6.3492e-04 - val_loss: 0.1610 - val_accuracy: 0.0000e+00\n",
            "Epoch 8964/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0272 - accuracy: 6.3492e-04 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
            "Epoch 8965/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0272 - accuracy: 6.3492e-04 - val_loss: 0.1609 - val_accuracy: 0.0000e+00\n",
            "Epoch 8966/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0272 - accuracy: 6.3492e-04 - val_loss: 0.1608 - val_accuracy: 0.0000e+00\n",
            "Epoch 8967/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0272 - accuracy: 6.3492e-04 - val_loss: 0.1607 - val_accuracy: 0.0000e+00\n",
            "Epoch 8968/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0272 - accuracy: 6.3492e-04 - val_loss: 0.1607 - val_accuracy: 0.0000e+00\n",
            "Epoch 8969/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0271 - accuracy: 6.3492e-04 - val_loss: 0.1606 - val_accuracy: 0.0000e+00\n",
            "Epoch 8970/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0271 - accuracy: 6.3492e-04 - val_loss: 0.1606 - val_accuracy: 0.0000e+00\n",
            "Epoch 8971/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0271 - accuracy: 6.3492e-04 - val_loss: 0.1605 - val_accuracy: 0.0000e+00\n",
            "Epoch 8972/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0271 - accuracy: 6.3492e-04 - val_loss: 0.1605 - val_accuracy: 0.0000e+00\n",
            "Epoch 8973/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0271 - accuracy: 6.3492e-04 - val_loss: 0.1604 - val_accuracy: 0.0000e+00\n",
            "Epoch 8974/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0271 - accuracy: 6.3492e-04 - val_loss: 0.1604 - val_accuracy: 0.0000e+00\n",
            "Epoch 8975/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0271 - accuracy: 6.3492e-04 - val_loss: 0.1603 - val_accuracy: 0.0000e+00\n",
            "Epoch 8976/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0270 - accuracy: 6.3492e-04 - val_loss: 0.1602 - val_accuracy: 0.0000e+00\n",
            "Epoch 8977/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0270 - accuracy: 6.3492e-04 - val_loss: 0.1602 - val_accuracy: 0.0000e+00\n",
            "Epoch 8978/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0270 - accuracy: 6.3492e-04 - val_loss: 0.1601 - val_accuracy: 0.0000e+00\n",
            "Epoch 8979/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0270 - accuracy: 6.3492e-04 - val_loss: 0.1601 - val_accuracy: 0.0000e+00\n",
            "Epoch 8980/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0270 - accuracy: 6.3492e-04 - val_loss: 0.1600 - val_accuracy: 0.0000e+00\n",
            "Epoch 8981/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0270 - accuracy: 6.3492e-04 - val_loss: 0.1599 - val_accuracy: 0.0000e+00\n",
            "Epoch 8982/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0270 - accuracy: 6.3492e-04 - val_loss: 0.1599 - val_accuracy: 0.0000e+00\n",
            "Epoch 8983/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0270 - accuracy: 6.3492e-04 - val_loss: 0.1598 - val_accuracy: 0.0000e+00\n",
            "Epoch 8984/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0269 - accuracy: 6.3492e-04 - val_loss: 0.1598 - val_accuracy: 0.0000e+00\n",
            "Epoch 8985/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0269 - accuracy: 6.3492e-04 - val_loss: 0.1597 - val_accuracy: 0.0000e+00\n",
            "Epoch 8986/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0269 - accuracy: 6.3492e-04 - val_loss: 0.1597 - val_accuracy: 0.0000e+00\n",
            "Epoch 8987/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0269 - accuracy: 6.3492e-04 - val_loss: 0.1596 - val_accuracy: 0.0000e+00\n",
            "Epoch 8988/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0269 - accuracy: 6.3492e-04 - val_loss: 0.1595 - val_accuracy: 0.0000e+00\n",
            "Epoch 8989/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0269 - accuracy: 6.3492e-04 - val_loss: 0.1595 - val_accuracy: 0.0000e+00\n",
            "Epoch 8990/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0269 - accuracy: 6.3492e-04 - val_loss: 0.1594 - val_accuracy: 0.0000e+00\n",
            "Epoch 8991/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0268 - accuracy: 6.3492e-04 - val_loss: 0.1594 - val_accuracy: 0.0000e+00\n",
            "Epoch 8992/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0268 - accuracy: 6.3492e-04 - val_loss: 0.1593 - val_accuracy: 0.0000e+00\n",
            "Epoch 8993/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0268 - accuracy: 6.3492e-04 - val_loss: 0.1593 - val_accuracy: 0.0000e+00\n",
            "Epoch 8994/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0268 - accuracy: 6.3492e-04 - val_loss: 0.1592 - val_accuracy: 0.0000e+00\n",
            "Epoch 8995/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0268 - accuracy: 6.3492e-04 - val_loss: 0.1592 - val_accuracy: 0.0000e+00\n",
            "Epoch 8996/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0268 - accuracy: 6.3492e-04 - val_loss: 0.1591 - val_accuracy: 0.0000e+00\n",
            "Epoch 8997/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0268 - accuracy: 6.3492e-04 - val_loss: 0.1590 - val_accuracy: 0.0000e+00\n",
            "Epoch 8998/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0267 - accuracy: 6.3492e-04 - val_loss: 0.1590 - val_accuracy: 0.0000e+00\n",
            "Epoch 8999/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0267 - accuracy: 6.3492e-04 - val_loss: 0.1589 - val_accuracy: 0.0000e+00\n",
            "Epoch 9000/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0267 - accuracy: 6.3492e-04 - val_loss: 0.1589 - val_accuracy: 0.0000e+00\n",
            "Epoch 9001/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0267 - accuracy: 6.3492e-04 - val_loss: 0.1588 - val_accuracy: 0.0000e+00\n",
            "Epoch 9002/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0267 - accuracy: 6.3492e-04 - val_loss: 0.1588 - val_accuracy: 0.0000e+00\n",
            "Epoch 9003/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0267 - accuracy: 6.3492e-04 - val_loss: 0.1587 - val_accuracy: 0.0000e+00\n",
            "Epoch 9004/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0267 - accuracy: 6.3492e-04 - val_loss: 0.1587 - val_accuracy: 0.0000e+00\n",
            "Epoch 9005/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0267 - accuracy: 6.3492e-04 - val_loss: 0.1586 - val_accuracy: 0.0000e+00\n",
            "Epoch 9006/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0266 - accuracy: 6.3492e-04 - val_loss: 0.1586 - val_accuracy: 0.0000e+00\n",
            "Epoch 9007/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0266 - accuracy: 6.3492e-04 - val_loss: 0.1585 - val_accuracy: 0.0000e+00\n",
            "Epoch 9008/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0266 - accuracy: 6.3492e-04 - val_loss: 0.1585 - val_accuracy: 0.0000e+00\n",
            "Epoch 9009/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0266 - accuracy: 6.3492e-04 - val_loss: 0.1584 - val_accuracy: 0.0000e+00\n",
            "Epoch 9010/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0266 - accuracy: 6.3492e-04 - val_loss: 0.1584 - val_accuracy: 0.0000e+00\n",
            "Epoch 9011/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0266 - accuracy: 6.3492e-04 - val_loss: 0.1583 - val_accuracy: 0.0000e+00\n",
            "Epoch 9012/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0266 - accuracy: 6.3492e-04 - val_loss: 0.1583 - val_accuracy: 0.0000e+00\n",
            "Epoch 9013/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0265 - accuracy: 6.3492e-04 - val_loss: 0.1582 - val_accuracy: 0.0000e+00\n",
            "Epoch 9014/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0265 - accuracy: 6.3492e-04 - val_loss: 0.1582 - val_accuracy: 0.0000e+00\n",
            "Epoch 9015/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0265 - accuracy: 6.3492e-04 - val_loss: 0.1581 - val_accuracy: 0.0000e+00\n",
            "Epoch 9016/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0265 - accuracy: 6.3492e-04 - val_loss: 0.1580 - val_accuracy: 0.0000e+00\n",
            "Epoch 9017/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0265 - accuracy: 6.3492e-04 - val_loss: 0.1580 - val_accuracy: 0.0000e+00\n",
            "Epoch 9018/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0265 - accuracy: 6.3492e-04 - val_loss: 0.1579 - val_accuracy: 0.0000e+00\n",
            "Epoch 9019/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0265 - accuracy: 6.3492e-04 - val_loss: 0.1579 - val_accuracy: 0.0000e+00\n",
            "Epoch 9020/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0265 - accuracy: 6.3492e-04 - val_loss: 0.1578 - val_accuracy: 0.0000e+00\n",
            "Epoch 9021/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0264 - accuracy: 6.3492e-04 - val_loss: 0.1578 - val_accuracy: 0.0000e+00\n",
            "Epoch 9022/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0264 - accuracy: 6.3492e-04 - val_loss: 0.1577 - val_accuracy: 0.0000e+00\n",
            "Epoch 9023/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0264 - accuracy: 6.3492e-04 - val_loss: 0.1577 - val_accuracy: 0.0000e+00\n",
            "Epoch 9024/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0264 - accuracy: 6.3492e-04 - val_loss: 0.1576 - val_accuracy: 0.0000e+00\n",
            "Epoch 9025/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0264 - accuracy: 6.3492e-04 - val_loss: 0.1576 - val_accuracy: 0.0000e+00\n",
            "Epoch 9026/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0264 - accuracy: 6.3492e-04 - val_loss: 0.1575 - val_accuracy: 0.0000e+00\n",
            "Epoch 9027/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0264 - accuracy: 6.3492e-04 - val_loss: 0.1575 - val_accuracy: 0.0000e+00\n",
            "Epoch 9028/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0263 - accuracy: 6.3492e-04 - val_loss: 0.1574 - val_accuracy: 0.0000e+00\n",
            "Epoch 9029/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0263 - accuracy: 6.3492e-04 - val_loss: 0.1574 - val_accuracy: 0.0000e+00\n",
            "Epoch 9030/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0263 - accuracy: 6.3492e-04 - val_loss: 0.1573 - val_accuracy: 0.0000e+00\n",
            "Epoch 9031/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0263 - accuracy: 6.3492e-04 - val_loss: 0.1573 - val_accuracy: 0.0000e+00\n",
            "Epoch 9032/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0263 - accuracy: 6.3492e-04 - val_loss: 0.1572 - val_accuracy: 0.0000e+00\n",
            "Epoch 9033/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0263 - accuracy: 6.3492e-04 - val_loss: 0.1572 - val_accuracy: 0.0000e+00\n",
            "Epoch 9034/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0263 - accuracy: 6.3492e-04 - val_loss: 0.1571 - val_accuracy: 0.0000e+00\n",
            "Epoch 9035/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0262 - accuracy: 6.3492e-04 - val_loss: 0.1570 - val_accuracy: 0.0000e+00\n",
            "Epoch 9036/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0262 - accuracy: 6.3492e-04 - val_loss: 0.1570 - val_accuracy: 0.0000e+00\n",
            "Epoch 9037/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0262 - accuracy: 6.3492e-04 - val_loss: 0.1569 - val_accuracy: 0.0000e+00\n",
            "Epoch 9038/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0262 - accuracy: 6.3492e-04 - val_loss: 0.1569 - val_accuracy: 0.0000e+00\n",
            "Epoch 9039/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0262 - accuracy: 6.3492e-04 - val_loss: 0.1568 - val_accuracy: 0.0000e+00\n",
            "Epoch 9040/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0262 - accuracy: 6.3492e-04 - val_loss: 0.1568 - val_accuracy: 0.0000e+00\n",
            "Epoch 9041/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0262 - accuracy: 6.3492e-04 - val_loss: 0.1567 - val_accuracy: 0.0000e+00\n",
            "Epoch 9042/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0262 - accuracy: 6.3492e-04 - val_loss: 0.1567 - val_accuracy: 0.0000e+00\n",
            "Epoch 9043/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0261 - accuracy: 6.3492e-04 - val_loss: 0.1566 - val_accuracy: 0.0000e+00\n",
            "Epoch 9044/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0261 - accuracy: 6.3492e-04 - val_loss: 0.1565 - val_accuracy: 0.0000e+00\n",
            "Epoch 9045/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0261 - accuracy: 6.3492e-04 - val_loss: 0.1565 - val_accuracy: 0.0000e+00\n",
            "Epoch 9046/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0261 - accuracy: 6.3492e-04 - val_loss: 0.1564 - val_accuracy: 0.0000e+00\n",
            "Epoch 9047/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0261 - accuracy: 6.3492e-04 - val_loss: 0.1564 - val_accuracy: 0.0000e+00\n",
            "Epoch 9048/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0261 - accuracy: 6.3492e-04 - val_loss: 0.1563 - val_accuracy: 0.0000e+00\n",
            "Epoch 9049/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0261 - accuracy: 6.3492e-04 - val_loss: 0.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 9050/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0260 - accuracy: 6.3492e-04 - val_loss: 0.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 9051/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0260 - accuracy: 6.3492e-04 - val_loss: 0.1561 - val_accuracy: 0.0000e+00\n",
            "Epoch 9052/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0260 - accuracy: 6.3492e-04 - val_loss: 0.1561 - val_accuracy: 0.0000e+00\n",
            "Epoch 9053/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0260 - accuracy: 6.3492e-04 - val_loss: 0.1560 - val_accuracy: 0.0000e+00\n",
            "Epoch 9054/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0260 - accuracy: 6.3492e-04 - val_loss: 0.1560 - val_accuracy: 0.0000e+00\n",
            "Epoch 9055/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0260 - accuracy: 6.3492e-04 - val_loss: 0.1559 - val_accuracy: 0.0000e+00\n",
            "Epoch 9056/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0260 - accuracy: 6.3492e-04 - val_loss: 0.1558 - val_accuracy: 0.0000e+00\n",
            "Epoch 9057/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0260 - accuracy: 6.3492e-04 - val_loss: 0.1558 - val_accuracy: 0.0000e+00\n",
            "Epoch 9058/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0259 - accuracy: 6.3492e-04 - val_loss: 0.1557 - val_accuracy: 0.0000e+00\n",
            "Epoch 9059/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0259 - accuracy: 6.3492e-04 - val_loss: 0.1557 - val_accuracy: 0.0000e+00\n",
            "Epoch 9060/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0259 - accuracy: 6.3492e-04 - val_loss: 0.1556 - val_accuracy: 0.0000e+00\n",
            "Epoch 9061/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0259 - accuracy: 6.3492e-04 - val_loss: 0.1555 - val_accuracy: 0.0000e+00\n",
            "Epoch 9062/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0259 - accuracy: 6.3492e-04 - val_loss: 0.1555 - val_accuracy: 0.0000e+00\n",
            "Epoch 9063/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0259 - accuracy: 6.3492e-04 - val_loss: 0.1554 - val_accuracy: 0.0000e+00\n",
            "Epoch 9064/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0259 - accuracy: 6.3492e-04 - val_loss: 0.1554 - val_accuracy: 0.0000e+00\n",
            "Epoch 9065/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0258 - accuracy: 6.3492e-04 - val_loss: 0.1553 - val_accuracy: 0.0000e+00\n",
            "Epoch 9066/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0258 - accuracy: 6.3492e-04 - val_loss: 0.1553 - val_accuracy: 0.0000e+00\n",
            "Epoch 9067/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0258 - accuracy: 6.3492e-04 - val_loss: 0.1552 - val_accuracy: 0.0000e+00\n",
            "Epoch 9068/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0258 - accuracy: 6.3492e-04 - val_loss: 0.1551 - val_accuracy: 0.0000e+00\n",
            "Epoch 9069/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0258 - accuracy: 6.3492e-04 - val_loss: 0.1551 - val_accuracy: 0.0000e+00\n",
            "Epoch 9070/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0258 - accuracy: 6.3492e-04 - val_loss: 0.1550 - val_accuracy: 0.0000e+00\n",
            "Epoch 9071/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0258 - accuracy: 6.3492e-04 - val_loss: 0.1550 - val_accuracy: 0.0000e+00\n",
            "Epoch 9072/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0258 - accuracy: 6.3492e-04 - val_loss: 0.1549 - val_accuracy: 0.0000e+00\n",
            "Epoch 9073/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0257 - accuracy: 6.3492e-04 - val_loss: 0.1548 - val_accuracy: 0.0000e+00\n",
            "Epoch 9074/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0257 - accuracy: 6.3492e-04 - val_loss: 0.1548 - val_accuracy: 0.0000e+00\n",
            "Epoch 9075/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0257 - accuracy: 6.3492e-04 - val_loss: 0.1547 - val_accuracy: 0.0000e+00\n",
            "Epoch 9076/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0257 - accuracy: 6.3492e-04 - val_loss: 0.1547 - val_accuracy: 0.0000e+00\n",
            "Epoch 9077/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0257 - accuracy: 6.3492e-04 - val_loss: 0.1546 - val_accuracy: 0.0000e+00\n",
            "Epoch 9078/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0257 - accuracy: 6.3492e-04 - val_loss: 0.1546 - val_accuracy: 0.0000e+00\n",
            "Epoch 9079/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0257 - accuracy: 6.3492e-04 - val_loss: 0.1545 - val_accuracy: 0.0000e+00\n",
            "Epoch 9080/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0256 - accuracy: 6.3492e-04 - val_loss: 0.1545 - val_accuracy: 0.0000e+00\n",
            "Epoch 9081/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0256 - accuracy: 6.3492e-04 - val_loss: 0.1544 - val_accuracy: 0.0000e+00\n",
            "Epoch 9082/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0256 - accuracy: 6.3492e-04 - val_loss: 0.1544 - val_accuracy: 0.0000e+00\n",
            "Epoch 9083/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0256 - accuracy: 6.3492e-04 - val_loss: 0.1543 - val_accuracy: 0.0000e+00\n",
            "Epoch 9084/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0256 - accuracy: 6.3492e-04 - val_loss: 0.1543 - val_accuracy: 0.0000e+00\n",
            "Epoch 9085/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0256 - accuracy: 6.3492e-04 - val_loss: 0.1542 - val_accuracy: 0.0000e+00\n",
            "Epoch 9086/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0256 - accuracy: 6.3492e-04 - val_loss: 0.1542 - val_accuracy: 0.0000e+00\n",
            "Epoch 9087/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0256 - accuracy: 6.3492e-04 - val_loss: 0.1541 - val_accuracy: 0.0000e+00\n",
            "Epoch 9088/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0255 - accuracy: 6.3492e-04 - val_loss: 0.1541 - val_accuracy: 0.0000e+00\n",
            "Epoch 9089/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0255 - accuracy: 6.3492e-04 - val_loss: 0.1540 - val_accuracy: 0.0000e+00\n",
            "Epoch 9090/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0255 - accuracy: 6.3492e-04 - val_loss: 0.1540 - val_accuracy: 0.0000e+00\n",
            "Epoch 9091/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0255 - accuracy: 6.3492e-04 - val_loss: 0.1539 - val_accuracy: 0.0000e+00\n",
            "Epoch 9092/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0255 - accuracy: 6.3492e-04 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n",
            "Epoch 9093/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0255 - accuracy: 6.3492e-04 - val_loss: 0.1538 - val_accuracy: 0.0000e+00\n",
            "Epoch 9094/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0255 - accuracy: 6.3492e-04 - val_loss: 0.1537 - val_accuracy: 0.0000e+00\n",
            "Epoch 9095/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0255 - accuracy: 6.3492e-04 - val_loss: 0.1537 - val_accuracy: 0.0000e+00\n",
            "Epoch 9096/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0254 - accuracy: 6.3492e-04 - val_loss: 0.1536 - val_accuracy: 0.0000e+00\n",
            "Epoch 9097/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0254 - accuracy: 6.3492e-04 - val_loss: 0.1536 - val_accuracy: 0.0000e+00\n",
            "Epoch 9098/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0254 - accuracy: 6.3492e-04 - val_loss: 0.1535 - val_accuracy: 0.0000e+00\n",
            "Epoch 9099/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0254 - accuracy: 6.3492e-04 - val_loss: 0.1535 - val_accuracy: 0.0000e+00\n",
            "Epoch 9100/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0254 - accuracy: 6.3492e-04 - val_loss: 0.1534 - val_accuracy: 0.0000e+00\n",
            "Epoch 9101/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0254 - accuracy: 6.3492e-04 - val_loss: 0.1534 - val_accuracy: 0.0000e+00\n",
            "Epoch 9102/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0254 - accuracy: 6.3492e-04 - val_loss: 0.1533 - val_accuracy: 0.0000e+00\n",
            "Epoch 9103/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0253 - accuracy: 6.3492e-04 - val_loss: 0.1533 - val_accuracy: 0.0000e+00\n",
            "Epoch 9104/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0253 - accuracy: 6.3492e-04 - val_loss: 0.1532 - val_accuracy: 0.0000e+00\n",
            "Epoch 9105/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0253 - accuracy: 6.3492e-04 - val_loss: 0.1532 - val_accuracy: 0.0000e+00\n",
            "Epoch 9106/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0253 - accuracy: 6.3492e-04 - val_loss: 0.1531 - val_accuracy: 0.0000e+00\n",
            "Epoch 9107/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0253 - accuracy: 6.3492e-04 - val_loss: 0.1531 - val_accuracy: 0.0000e+00\n",
            "Epoch 9108/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0253 - accuracy: 6.3492e-04 - val_loss: 0.1530 - val_accuracy: 0.0000e+00\n",
            "Epoch 9109/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0253 - accuracy: 6.3492e-04 - val_loss: 0.1530 - val_accuracy: 0.0000e+00\n",
            "Epoch 9110/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0253 - accuracy: 6.3492e-04 - val_loss: 0.1529 - val_accuracy: 0.0000e+00\n",
            "Epoch 9111/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0252 - accuracy: 6.3492e-04 - val_loss: 0.1529 - val_accuracy: 0.0000e+00\n",
            "Epoch 9112/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0252 - accuracy: 6.3492e-04 - val_loss: 0.1528 - val_accuracy: 0.0000e+00\n",
            "Epoch 9113/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0252 - accuracy: 6.3492e-04 - val_loss: 0.1528 - val_accuracy: 0.0000e+00\n",
            "Epoch 9114/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0252 - accuracy: 6.3492e-04 - val_loss: 0.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 9115/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0252 - accuracy: 6.3492e-04 - val_loss: 0.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 9116/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0252 - accuracy: 6.3492e-04 - val_loss: 0.1526 - val_accuracy: 0.0000e+00\n",
            "Epoch 9117/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0252 - accuracy: 6.3492e-04 - val_loss: 0.1526 - val_accuracy: 0.0000e+00\n",
            "Epoch 9118/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0251 - accuracy: 6.3492e-04 - val_loss: 0.1525 - val_accuracy: 0.0000e+00\n",
            "Epoch 9119/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0251 - accuracy: 6.3492e-04 - val_loss: 0.1525 - val_accuracy: 0.0000e+00\n",
            "Epoch 9120/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0251 - accuracy: 6.3492e-04 - val_loss: 0.1524 - val_accuracy: 0.0000e+00\n",
            "Epoch 9121/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0251 - accuracy: 6.3492e-04 - val_loss: 0.1523 - val_accuracy: 0.0000e+00\n",
            "Epoch 9122/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0251 - accuracy: 6.3492e-04 - val_loss: 0.1523 - val_accuracy: 0.0000e+00\n",
            "Epoch 9123/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0251 - accuracy: 6.3492e-04 - val_loss: 0.1522 - val_accuracy: 0.0000e+00\n",
            "Epoch 9124/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0251 - accuracy: 6.3492e-04 - val_loss: 0.1522 - val_accuracy: 0.0000e+00\n",
            "Epoch 9125/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0251 - accuracy: 6.3492e-04 - val_loss: 0.1521 - val_accuracy: 0.0000e+00\n",
            "Epoch 9126/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0250 - accuracy: 6.3492e-04 - val_loss: 0.1521 - val_accuracy: 0.0000e+00\n",
            "Epoch 9127/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0250 - accuracy: 6.3492e-04 - val_loss: 0.1520 - val_accuracy: 0.0000e+00\n",
            "Epoch 9128/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0250 - accuracy: 6.3492e-04 - val_loss: 0.1519 - val_accuracy: 0.0000e+00\n",
            "Epoch 9129/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0250 - accuracy: 6.3492e-04 - val_loss: 0.1519 - val_accuracy: 0.0000e+00\n",
            "Epoch 9130/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0250 - accuracy: 6.3492e-04 - val_loss: 0.1518 - val_accuracy: 0.0000e+00\n",
            "Epoch 9131/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0250 - accuracy: 6.3492e-04 - val_loss: 0.1518 - val_accuracy: 0.0000e+00\n",
            "Epoch 9132/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0250 - accuracy: 6.3492e-04 - val_loss: 0.1517 - val_accuracy: 0.0000e+00\n",
            "Epoch 9133/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0249 - accuracy: 6.3492e-04 - val_loss: 0.1517 - val_accuracy: 0.0000e+00\n",
            "Epoch 9134/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0249 - accuracy: 6.3492e-04 - val_loss: 0.1516 - val_accuracy: 0.0000e+00\n",
            "Epoch 9135/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0249 - accuracy: 6.3492e-04 - val_loss: 0.1515 - val_accuracy: 0.0000e+00\n",
            "Epoch 9136/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0249 - accuracy: 6.3492e-04 - val_loss: 0.1515 - val_accuracy: 0.0000e+00\n",
            "Epoch 9137/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0249 - accuracy: 6.3492e-04 - val_loss: 0.1514 - val_accuracy: 0.0000e+00\n",
            "Epoch 9138/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0249 - accuracy: 6.3492e-04 - val_loss: 0.1514 - val_accuracy: 0.0000e+00\n",
            "Epoch 9139/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0249 - accuracy: 6.3492e-04 - val_loss: 0.1513 - val_accuracy: 0.0000e+00\n",
            "Epoch 9140/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0249 - accuracy: 6.3492e-04 - val_loss: 0.1512 - val_accuracy: 0.0000e+00\n",
            "Epoch 9141/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0248 - accuracy: 6.3492e-04 - val_loss: 0.1512 - val_accuracy: 0.0000e+00\n",
            "Epoch 9142/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0248 - accuracy: 6.3492e-04 - val_loss: 0.1511 - val_accuracy: 0.0000e+00\n",
            "Epoch 9143/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0248 - accuracy: 6.3492e-04 - val_loss: 0.1511 - val_accuracy: 0.0000e+00\n",
            "Epoch 9144/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0248 - accuracy: 6.3492e-04 - val_loss: 0.1510 - val_accuracy: 0.0000e+00\n",
            "Epoch 9145/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0248 - accuracy: 6.3492e-04 - val_loss: 0.1509 - val_accuracy: 0.0000e+00\n",
            "Epoch 9146/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0248 - accuracy: 6.3492e-04 - val_loss: 0.1509 - val_accuracy: 0.0000e+00\n",
            "Epoch 9147/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0248 - accuracy: 6.3492e-04 - val_loss: 0.1508 - val_accuracy: 0.0000e+00\n",
            "Epoch 9148/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0248 - accuracy: 6.3492e-04 - val_loss: 0.1508 - val_accuracy: 0.0000e+00\n",
            "Epoch 9149/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0247 - accuracy: 6.3492e-04 - val_loss: 0.1507 - val_accuracy: 0.0000e+00\n",
            "Epoch 9150/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0247 - accuracy: 6.3492e-04 - val_loss: 0.1507 - val_accuracy: 0.0000e+00\n",
            "Epoch 9151/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0247 - accuracy: 6.3492e-04 - val_loss: 0.1506 - val_accuracy: 0.0000e+00\n",
            "Epoch 9152/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0247 - accuracy: 6.3492e-04 - val_loss: 0.1506 - val_accuracy: 0.0000e+00\n",
            "Epoch 9153/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0247 - accuracy: 6.3492e-04 - val_loss: 0.1505 - val_accuracy: 0.0000e+00\n",
            "Epoch 9154/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0247 - accuracy: 6.3492e-04 - val_loss: 0.1505 - val_accuracy: 0.0000e+00\n",
            "Epoch 9155/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0247 - accuracy: 6.3492e-04 - val_loss: 0.1504 - val_accuracy: 0.0000e+00\n",
            "Epoch 9156/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0246 - accuracy: 6.3492e-04 - val_loss: 0.1503 - val_accuracy: 0.0000e+00\n",
            "Epoch 9157/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0246 - accuracy: 6.3492e-04 - val_loss: 0.1503 - val_accuracy: 0.0000e+00\n",
            "Epoch 9158/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0246 - accuracy: 6.3492e-04 - val_loss: 0.1502 - val_accuracy: 0.0000e+00\n",
            "Epoch 9159/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0246 - accuracy: 6.3492e-04 - val_loss: 0.1502 - val_accuracy: 0.0000e+00\n",
            "Epoch 9160/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0246 - accuracy: 6.3492e-04 - val_loss: 0.1501 - val_accuracy: 0.0000e+00\n",
            "Epoch 9161/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0246 - accuracy: 6.3492e-04 - val_loss: 0.1501 - val_accuracy: 0.0000e+00\n",
            "Epoch 9162/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0246 - accuracy: 6.3492e-04 - val_loss: 0.1500 - val_accuracy: 0.0000e+00\n",
            "Epoch 9163/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 6.3492e-04 - val_loss: 0.1500 - val_accuracy: 0.0000e+00\n",
            "Epoch 9164/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0245 - accuracy: 6.3492e-04 - val_loss: 0.1499 - val_accuracy: 0.0000e+00\n",
            "Epoch 9165/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0245 - accuracy: 6.3492e-04 - val_loss: 0.1498 - val_accuracy: 0.0000e+00\n",
            "Epoch 9166/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0245 - accuracy: 6.3492e-04 - val_loss: 0.1498 - val_accuracy: 0.0000e+00\n",
            "Epoch 9167/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0245 - accuracy: 6.3492e-04 - val_loss: 0.1497 - val_accuracy: 0.0000e+00\n",
            "Epoch 9168/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0245 - accuracy: 6.3492e-04 - val_loss: 0.1497 - val_accuracy: 0.0000e+00\n",
            "Epoch 9169/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0245 - accuracy: 6.3492e-04 - val_loss: 0.1496 - val_accuracy: 0.0000e+00\n",
            "Epoch 9170/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0245 - accuracy: 6.3492e-04 - val_loss: 0.1496 - val_accuracy: 0.0000e+00\n",
            "Epoch 9171/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0245 - accuracy: 6.3492e-04 - val_loss: 0.1495 - val_accuracy: 0.0000e+00\n",
            "Epoch 9172/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0244 - accuracy: 6.3492e-04 - val_loss: 0.1495 - val_accuracy: 0.0000e+00\n",
            "Epoch 9173/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0244 - accuracy: 6.3492e-04 - val_loss: 0.1494 - val_accuracy: 0.0000e+00\n",
            "Epoch 9174/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0244 - accuracy: 6.3492e-04 - val_loss: 0.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 9175/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0244 - accuracy: 6.3492e-04 - val_loss: 0.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 9176/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0244 - accuracy: 6.3492e-04 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 9177/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0244 - accuracy: 6.3492e-04 - val_loss: 0.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 9178/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0244 - accuracy: 6.3492e-04 - val_loss: 0.1491 - val_accuracy: 0.0000e+00\n",
            "Epoch 9179/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0243 - accuracy: 6.3492e-04 - val_loss: 0.1491 - val_accuracy: 0.0000e+00\n",
            "Epoch 9180/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0243 - accuracy: 6.3492e-04 - val_loss: 0.1490 - val_accuracy: 0.0000e+00\n",
            "Epoch 9181/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0243 - accuracy: 6.3492e-04 - val_loss: 0.1490 - val_accuracy: 0.0000e+00\n",
            "Epoch 9182/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0243 - accuracy: 6.3492e-04 - val_loss: 0.1489 - val_accuracy: 0.0000e+00\n",
            "Epoch 9183/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0243 - accuracy: 6.3492e-04 - val_loss: 0.1488 - val_accuracy: 0.0000e+00\n",
            "Epoch 9184/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0243 - accuracy: 6.3492e-04 - val_loss: 0.1488 - val_accuracy: 0.0000e+00\n",
            "Epoch 9185/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0243 - accuracy: 6.3492e-04 - val_loss: 0.1487 - val_accuracy: 0.0000e+00\n",
            "Epoch 9186/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0243 - accuracy: 6.3492e-04 - val_loss: 0.1487 - val_accuracy: 0.0000e+00\n",
            "Epoch 9187/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0242 - accuracy: 6.3492e-04 - val_loss: 0.1486 - val_accuracy: 0.0000e+00\n",
            "Epoch 9188/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0242 - accuracy: 6.3492e-04 - val_loss: 0.1486 - val_accuracy: 0.0000e+00\n",
            "Epoch 9189/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0242 - accuracy: 6.3492e-04 - val_loss: 0.1485 - val_accuracy: 0.0000e+00\n",
            "Epoch 9190/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0242 - accuracy: 6.3492e-04 - val_loss: 0.1484 - val_accuracy: 0.0000e+00\n",
            "Epoch 9191/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0242 - accuracy: 6.3492e-04 - val_loss: 0.1484 - val_accuracy: 0.0000e+00\n",
            "Epoch 9192/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0242 - accuracy: 6.3492e-04 - val_loss: 0.1483 - val_accuracy: 0.0000e+00\n",
            "Epoch 9193/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0242 - accuracy: 6.3492e-04 - val_loss: 0.1483 - val_accuracy: 0.0000e+00\n",
            "Epoch 9194/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0242 - accuracy: 6.3492e-04 - val_loss: 0.1482 - val_accuracy: 0.0000e+00\n",
            "Epoch 9195/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 6.3492e-04 - val_loss: 0.1482 - val_accuracy: 0.0000e+00\n",
            "Epoch 9196/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0241 - accuracy: 6.3492e-04 - val_loss: 0.1481 - val_accuracy: 0.0000e+00\n",
            "Epoch 9197/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0241 - accuracy: 6.3492e-04 - val_loss: 0.1480 - val_accuracy: 0.0000e+00\n",
            "Epoch 9198/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0241 - accuracy: 6.3492e-04 - val_loss: 0.1480 - val_accuracy: 0.0000e+00\n",
            "Epoch 9199/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0241 - accuracy: 6.3492e-04 - val_loss: 0.1479 - val_accuracy: 0.0000e+00\n",
            "Epoch 9200/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0241 - accuracy: 6.3492e-04 - val_loss: 0.1479 - val_accuracy: 0.0000e+00\n",
            "Epoch 9201/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0241 - accuracy: 6.3492e-04 - val_loss: 0.1478 - val_accuracy: 0.0000e+00\n",
            "Epoch 9202/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0241 - accuracy: 6.3492e-04 - val_loss: 0.1478 - val_accuracy: 0.0000e+00\n",
            "Epoch 9203/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0240 - accuracy: 6.3492e-04 - val_loss: 0.1477 - val_accuracy: 0.0000e+00\n",
            "Epoch 9204/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0240 - accuracy: 6.3492e-04 - val_loss: 0.1477 - val_accuracy: 0.0000e+00\n",
            "Epoch 9205/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0240 - accuracy: 6.3492e-04 - val_loss: 0.1476 - val_accuracy: 0.0000e+00\n",
            "Epoch 9206/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 6.3492e-04 - val_loss: 0.1475 - val_accuracy: 0.0000e+00\n",
            "Epoch 9207/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0240 - accuracy: 6.3492e-04 - val_loss: 0.1475 - val_accuracy: 0.0000e+00\n",
            "Epoch 9208/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 6.3492e-04 - val_loss: 0.1474 - val_accuracy: 0.0000e+00\n",
            "Epoch 9209/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0240 - accuracy: 6.3492e-04 - val_loss: 0.1474 - val_accuracy: 0.0000e+00\n",
            "Epoch 9210/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0239 - accuracy: 6.3492e-04 - val_loss: 0.1473 - val_accuracy: 0.0000e+00\n",
            "Epoch 9211/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0239 - accuracy: 6.3492e-04 - val_loss: 0.1473 - val_accuracy: 0.0000e+00\n",
            "Epoch 9212/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0239 - accuracy: 6.3492e-04 - val_loss: 0.1472 - val_accuracy: 0.0000e+00\n",
            "Epoch 9213/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0239 - accuracy: 6.3492e-04 - val_loss: 0.1472 - val_accuracy: 0.0000e+00\n",
            "Epoch 9214/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0239 - accuracy: 6.3492e-04 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 9215/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0239 - accuracy: 6.3492e-04 - val_loss: 0.1471 - val_accuracy: 0.0000e+00\n",
            "Epoch 9216/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0239 - accuracy: 6.3492e-04 - val_loss: 0.1470 - val_accuracy: 0.0000e+00\n",
            "Epoch 9217/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0239 - accuracy: 6.3492e-04 - val_loss: 0.1469 - val_accuracy: 0.0000e+00\n",
            "Epoch 9218/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0238 - accuracy: 6.3492e-04 - val_loss: 0.1469 - val_accuracy: 0.0000e+00\n",
            "Epoch 9219/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0238 - accuracy: 6.3492e-04 - val_loss: 0.1468 - val_accuracy: 0.0000e+00\n",
            "Epoch 9220/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0238 - accuracy: 6.3492e-04 - val_loss: 0.1468 - val_accuracy: 0.0000e+00\n",
            "Epoch 9221/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0238 - accuracy: 6.3492e-04 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
            "Epoch 9222/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0238 - accuracy: 6.3492e-04 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
            "Epoch 9223/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0238 - accuracy: 6.3492e-04 - val_loss: 0.1466 - val_accuracy: 0.0000e+00\n",
            "Epoch 9224/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0238 - accuracy: 6.3492e-04 - val_loss: 0.1465 - val_accuracy: 0.0000e+00\n",
            "Epoch 9225/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0238 - accuracy: 6.3492e-04 - val_loss: 0.1465 - val_accuracy: 0.0000e+00\n",
            "Epoch 9226/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0237 - accuracy: 6.3492e-04 - val_loss: 0.1464 - val_accuracy: 0.0000e+00\n",
            "Epoch 9227/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0237 - accuracy: 6.3492e-04 - val_loss: 0.1464 - val_accuracy: 0.0000e+00\n",
            "Epoch 9228/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0237 - accuracy: 6.3492e-04 - val_loss: 0.1463 - val_accuracy: 0.0000e+00\n",
            "Epoch 9229/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0237 - accuracy: 6.3492e-04 - val_loss: 0.1463 - val_accuracy: 0.0000e+00\n",
            "Epoch 9230/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0237 - accuracy: 6.3492e-04 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 9231/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0237 - accuracy: 6.3492e-04 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
            "Epoch 9232/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0237 - accuracy: 6.3492e-04 - val_loss: 0.1461 - val_accuracy: 0.0000e+00\n",
            "Epoch 9233/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0237 - accuracy: 6.3492e-04 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 9234/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0236 - accuracy: 6.3492e-04 - val_loss: 0.1460 - val_accuracy: 0.0000e+00\n",
            "Epoch 9235/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0236 - accuracy: 6.3492e-04 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 9236/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0236 - accuracy: 6.3492e-04 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 9237/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0236 - accuracy: 6.3492e-04 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 9238/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0236 - accuracy: 6.3492e-04 - val_loss: 0.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 9239/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0236 - accuracy: 6.3492e-04 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
            "Epoch 9240/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0236 - accuracy: 6.3492e-04 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 9241/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0235 - accuracy: 6.3492e-04 - val_loss: 0.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 9242/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0235 - accuracy: 6.3492e-04 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 9243/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0235 - accuracy: 6.3492e-04 - val_loss: 0.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 9244/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0235 - accuracy: 6.3492e-04 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 9245/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0235 - accuracy: 6.3492e-04 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 9246/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0235 - accuracy: 6.3492e-04 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 9247/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0235 - accuracy: 6.3492e-04 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 9248/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0235 - accuracy: 6.3492e-04 - val_loss: 0.1452 - val_accuracy: 0.0000e+00\n",
            "Epoch 9249/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0234 - accuracy: 6.3492e-04 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 9250/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0234 - accuracy: 6.3492e-04 - val_loss: 0.1451 - val_accuracy: 0.0000e+00\n",
            "Epoch 9251/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0234 - accuracy: 6.3492e-04 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 9252/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0234 - accuracy: 6.3492e-04 - val_loss: 0.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 9253/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0234 - accuracy: 6.3492e-04 - val_loss: 0.1449 - val_accuracy: 0.0057\n",
            "Epoch 9254/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0234 - accuracy: 6.3492e-04 - val_loss: 0.1448 - val_accuracy: 0.0057\n",
            "Epoch 9255/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0234 - accuracy: 6.3492e-04 - val_loss: 0.1448 - val_accuracy: 0.0057\n",
            "Epoch 9256/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0234 - accuracy: 6.3492e-04 - val_loss: 0.1447 - val_accuracy: 0.0057\n",
            "Epoch 9257/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0233 - accuracy: 6.3492e-04 - val_loss: 0.1446 - val_accuracy: 0.0057\n",
            "Epoch 9258/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0233 - accuracy: 6.3492e-04 - val_loss: 0.1446 - val_accuracy: 0.0057\n",
            "Epoch 9259/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0233 - accuracy: 6.3492e-04 - val_loss: 0.1445 - val_accuracy: 0.0057\n",
            "Epoch 9260/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0233 - accuracy: 6.3492e-04 - val_loss: 0.1445 - val_accuracy: 0.0057\n",
            "Epoch 9261/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0233 - accuracy: 6.3492e-04 - val_loss: 0.1444 - val_accuracy: 0.0057\n",
            "Epoch 9262/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0233 - accuracy: 6.3492e-04 - val_loss: 0.1443 - val_accuracy: 0.0057\n",
            "Epoch 9263/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0233 - accuracy: 6.3492e-04 - val_loss: 0.1443 - val_accuracy: 0.0057\n",
            "Epoch 9264/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0233 - accuracy: 6.3492e-04 - val_loss: 0.1442 - val_accuracy: 0.0057\n",
            "Epoch 9265/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0232 - accuracy: 6.3492e-04 - val_loss: 0.1442 - val_accuracy: 0.0057\n",
            "Epoch 9266/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0232 - accuracy: 6.3492e-04 - val_loss: 0.1441 - val_accuracy: 0.0057\n",
            "Epoch 9267/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0232 - accuracy: 6.3492e-04 - val_loss: 0.1440 - val_accuracy: 0.0057\n",
            "Epoch 9268/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0232 - accuracy: 6.3492e-04 - val_loss: 0.1440 - val_accuracy: 0.0057\n",
            "Epoch 9269/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0232 - accuracy: 6.3492e-04 - val_loss: 0.1439 - val_accuracy: 0.0057\n",
            "Epoch 9270/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0232 - accuracy: 6.3492e-04 - val_loss: 0.1439 - val_accuracy: 0.0057\n",
            "Epoch 9271/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0232 - accuracy: 6.3492e-04 - val_loss: 0.1438 - val_accuracy: 0.0057\n",
            "Epoch 9272/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0232 - accuracy: 6.3492e-04 - val_loss: 0.1437 - val_accuracy: 0.0057\n",
            "Epoch 9273/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0231 - accuracy: 6.3492e-04 - val_loss: 0.1437 - val_accuracy: 0.0057\n",
            "Epoch 9274/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0231 - accuracy: 6.3492e-04 - val_loss: 0.1436 - val_accuracy: 0.0057\n",
            "Epoch 9275/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0231 - accuracy: 6.3492e-04 - val_loss: 0.1436 - val_accuracy: 0.0057\n",
            "Epoch 9276/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0231 - accuracy: 6.3492e-04 - val_loss: 0.1435 - val_accuracy: 0.0057\n",
            "Epoch 9277/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0231 - accuracy: 6.3492e-04 - val_loss: 0.1434 - val_accuracy: 0.0057\n",
            "Epoch 9278/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0231 - accuracy: 6.3492e-04 - val_loss: 0.1434 - val_accuracy: 0.0057\n",
            "Epoch 9279/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0231 - accuracy: 6.3492e-04 - val_loss: 0.1433 - val_accuracy: 0.0057\n",
            "Epoch 9280/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0231 - accuracy: 6.3492e-04 - val_loss: 0.1433 - val_accuracy: 0.0057\n",
            "Epoch 9281/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0230 - accuracy: 6.3492e-04 - val_loss: 0.1432 - val_accuracy: 0.0057\n",
            "Epoch 9282/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0230 - accuracy: 6.3492e-04 - val_loss: 0.1431 - val_accuracy: 0.0057\n",
            "Epoch 9283/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0230 - accuracy: 6.3492e-04 - val_loss: 0.1431 - val_accuracy: 0.0057\n",
            "Epoch 9284/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0230 - accuracy: 6.3492e-04 - val_loss: 0.1430 - val_accuracy: 0.0057\n",
            "Epoch 9285/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0230 - accuracy: 6.3492e-04 - val_loss: 0.1430 - val_accuracy: 0.0057\n",
            "Epoch 9286/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0230 - accuracy: 6.3492e-04 - val_loss: 0.1429 - val_accuracy: 0.0057\n",
            "Epoch 9287/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0230 - accuracy: 6.3492e-04 - val_loss: 0.1429 - val_accuracy: 0.0057\n",
            "Epoch 9288/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0229 - accuracy: 6.3492e-04 - val_loss: 0.1428 - val_accuracy: 0.0057\n",
            "Epoch 9289/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0229 - accuracy: 6.3492e-04 - val_loss: 0.1428 - val_accuracy: 0.0057\n",
            "Epoch 9290/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0229 - accuracy: 6.3492e-04 - val_loss: 0.1427 - val_accuracy: 0.0057\n",
            "Epoch 9291/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0229 - accuracy: 6.3492e-04 - val_loss: 0.1426 - val_accuracy: 0.0057\n",
            "Epoch 9292/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0229 - accuracy: 6.3492e-04 - val_loss: 0.1426 - val_accuracy: 0.0057\n",
            "Epoch 9293/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0229 - accuracy: 6.3492e-04 - val_loss: 0.1425 - val_accuracy: 0.0057\n",
            "Epoch 9294/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0229 - accuracy: 6.3492e-04 - val_loss: 0.1425 - val_accuracy: 0.0057\n",
            "Epoch 9295/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0229 - accuracy: 6.3492e-04 - val_loss: 0.1424 - val_accuracy: 0.0057\n",
            "Epoch 9296/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0228 - accuracy: 6.3492e-04 - val_loss: 0.1424 - val_accuracy: 0.0057\n",
            "Epoch 9297/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0228 - accuracy: 6.3492e-04 - val_loss: 0.1423 - val_accuracy: 0.0057\n",
            "Epoch 9298/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0228 - accuracy: 6.3492e-04 - val_loss: 0.1423 - val_accuracy: 0.0057\n",
            "Epoch 9299/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0228 - accuracy: 6.3492e-04 - val_loss: 0.1422 - val_accuracy: 0.0057\n",
            "Epoch 9300/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0228 - accuracy: 6.3492e-04 - val_loss: 0.1421 - val_accuracy: 0.0057\n",
            "Epoch 9301/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0228 - accuracy: 6.3492e-04 - val_loss: 0.1421 - val_accuracy: 0.0057\n",
            "Epoch 9302/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0228 - accuracy: 6.3492e-04 - val_loss: 0.1420 - val_accuracy: 0.0057\n",
            "Epoch 9303/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0228 - accuracy: 6.3492e-04 - val_loss: 0.1420 - val_accuracy: 0.0057\n",
            "Epoch 9304/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0227 - accuracy: 6.3492e-04 - val_loss: 0.1419 - val_accuracy: 0.0057\n",
            "Epoch 9305/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0227 - accuracy: 6.3492e-04 - val_loss: 0.1419 - val_accuracy: 0.0057\n",
            "Epoch 9306/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0227 - accuracy: 6.3492e-04 - val_loss: 0.1418 - val_accuracy: 0.0057\n",
            "Epoch 9307/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0227 - accuracy: 6.3492e-04 - val_loss: 0.1418 - val_accuracy: 0.0057\n",
            "Epoch 9308/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0227 - accuracy: 6.3492e-04 - val_loss: 0.1417 - val_accuracy: 0.0057\n",
            "Epoch 9309/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0227 - accuracy: 6.3492e-04 - val_loss: 0.1416 - val_accuracy: 0.0057\n",
            "Epoch 9310/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0227 - accuracy: 6.3492e-04 - val_loss: 0.1416 - val_accuracy: 0.0057\n",
            "Epoch 9311/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0227 - accuracy: 6.3492e-04 - val_loss: 0.1415 - val_accuracy: 0.0057\n",
            "Epoch 9312/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0226 - accuracy: 6.3492e-04 - val_loss: 0.1415 - val_accuracy: 0.0057\n",
            "Epoch 9313/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0226 - accuracy: 6.3492e-04 - val_loss: 0.1414 - val_accuracy: 0.0057\n",
            "Epoch 9314/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0226 - accuracy: 6.3492e-04 - val_loss: 0.1414 - val_accuracy: 0.0057\n",
            "Epoch 9315/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0226 - accuracy: 6.3492e-04 - val_loss: 0.1413 - val_accuracy: 0.0057\n",
            "Epoch 9316/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0226 - accuracy: 6.3492e-04 - val_loss: 0.1413 - val_accuracy: 0.0057\n",
            "Epoch 9317/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0226 - accuracy: 6.3492e-04 - val_loss: 0.1412 - val_accuracy: 0.0057\n",
            "Epoch 9318/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0226 - accuracy: 6.3492e-04 - val_loss: 0.1412 - val_accuracy: 0.0057\n",
            "Epoch 9319/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0226 - accuracy: 6.3492e-04 - val_loss: 0.1411 - val_accuracy: 0.0057\n",
            "Epoch 9320/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0225 - accuracy: 6.3492e-04 - val_loss: 0.1410 - val_accuracy: 0.0057\n",
            "Epoch 9321/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0225 - accuracy: 6.3492e-04 - val_loss: 0.1410 - val_accuracy: 0.0057\n",
            "Epoch 9322/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0225 - accuracy: 6.3492e-04 - val_loss: 0.1409 - val_accuracy: 0.0057\n",
            "Epoch 9323/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0225 - accuracy: 6.3492e-04 - val_loss: 0.1409 - val_accuracy: 0.0057\n",
            "Epoch 9324/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0225 - accuracy: 6.3492e-04 - val_loss: 0.1408 - val_accuracy: 0.0057\n",
            "Epoch 9325/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0225 - accuracy: 6.3492e-04 - val_loss: 0.1408 - val_accuracy: 0.0057\n",
            "Epoch 9326/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0225 - accuracy: 6.3492e-04 - val_loss: 0.1407 - val_accuracy: 0.0057\n",
            "Epoch 9327/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0225 - accuracy: 6.3492e-04 - val_loss: 0.1406 - val_accuracy: 0.0057\n",
            "Epoch 9328/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0224 - accuracy: 6.3492e-04 - val_loss: 0.1406 - val_accuracy: 0.0057\n",
            "Epoch 9329/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0224 - accuracy: 6.3492e-04 - val_loss: 0.1405 - val_accuracy: 0.0057\n",
            "Epoch 9330/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0224 - accuracy: 6.3492e-04 - val_loss: 0.1405 - val_accuracy: 0.0057\n",
            "Epoch 9331/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0224 - accuracy: 6.3492e-04 - val_loss: 0.1404 - val_accuracy: 0.0057\n",
            "Epoch 9332/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0224 - accuracy: 6.3492e-04 - val_loss: 0.1404 - val_accuracy: 0.0057\n",
            "Epoch 9333/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0224 - accuracy: 6.3492e-04 - val_loss: 0.1403 - val_accuracy: 0.0057\n",
            "Epoch 9334/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0224 - accuracy: 6.3492e-04 - val_loss: 0.1403 - val_accuracy: 0.0057\n",
            "Epoch 9335/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0224 - accuracy: 6.3492e-04 - val_loss: 0.1402 - val_accuracy: 0.0057\n",
            "Epoch 9336/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0223 - accuracy: 6.3492e-04 - val_loss: 0.1401 - val_accuracy: 0.0057\n",
            "Epoch 9337/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 6.3492e-04 - val_loss: 0.1401 - val_accuracy: 0.0057\n",
            "Epoch 9338/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0223 - accuracy: 6.3492e-04 - val_loss: 0.1400 - val_accuracy: 0.0057\n",
            "Epoch 9339/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 6.3492e-04 - val_loss: 0.1400 - val_accuracy: 0.0057\n",
            "Epoch 9340/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0223 - accuracy: 6.3492e-04 - val_loss: 0.1399 - val_accuracy: 0.0057\n",
            "Epoch 9341/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0223 - accuracy: 6.3492e-04 - val_loss: 0.1399 - val_accuracy: 0.0057\n",
            "Epoch 9342/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 6.3492e-04 - val_loss: 0.1398 - val_accuracy: 0.0057\n",
            "Epoch 9343/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 6.3492e-04 - val_loss: 0.1397 - val_accuracy: 0.0057\n",
            "Epoch 9344/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0222 - accuracy: 6.3492e-04 - val_loss: 0.1397 - val_accuracy: 0.0057\n",
            "Epoch 9345/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0222 - accuracy: 6.3492e-04 - val_loss: 0.1396 - val_accuracy: 0.0057\n",
            "Epoch 9346/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0222 - accuracy: 6.3492e-04 - val_loss: 0.1396 - val_accuracy: 0.0057\n",
            "Epoch 9347/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0222 - accuracy: 6.3492e-04 - val_loss: 0.1395 - val_accuracy: 0.0057\n",
            "Epoch 9348/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0222 - accuracy: 6.3492e-04 - val_loss: 0.1394 - val_accuracy: 0.0057\n",
            "Epoch 9349/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0222 - accuracy: 6.3492e-04 - val_loss: 0.1394 - val_accuracy: 0.0057\n",
            "Epoch 9350/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0222 - accuracy: 6.3492e-04 - val_loss: 0.1393 - val_accuracy: 0.0057\n",
            "Epoch 9351/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0222 - accuracy: 6.3492e-04 - val_loss: 0.1393 - val_accuracy: 0.0057\n",
            "Epoch 9352/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1392 - val_accuracy: 0.0057\n",
            "Epoch 9353/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1391 - val_accuracy: 0.0057\n",
            "Epoch 9354/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1391 - val_accuracy: 0.0057\n",
            "Epoch 9355/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1390 - val_accuracy: 0.0057\n",
            "Epoch 9356/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1390 - val_accuracy: 0.0057\n",
            "Epoch 9357/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1389 - val_accuracy: 0.0057\n",
            "Epoch 9358/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1388 - val_accuracy: 0.0057\n",
            "Epoch 9359/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1388 - val_accuracy: 0.0057\n",
            "Epoch 9360/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0221 - accuracy: 6.3492e-04 - val_loss: 0.1387 - val_accuracy: 0.0057\n",
            "Epoch 9361/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0220 - accuracy: 6.3492e-04 - val_loss: 0.1387 - val_accuracy: 0.0057\n",
            "Epoch 9362/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0220 - accuracy: 6.3492e-04 - val_loss: 0.1386 - val_accuracy: 0.0057\n",
            "Epoch 9363/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0220 - accuracy: 6.3492e-04 - val_loss: 0.1386 - val_accuracy: 0.0057\n",
            "Epoch 9364/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0220 - accuracy: 6.3492e-04 - val_loss: 0.1385 - val_accuracy: 0.0057\n",
            "Epoch 9365/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0220 - accuracy: 6.3492e-04 - val_loss: 0.1385 - val_accuracy: 0.0057\n",
            "Epoch 9366/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0220 - accuracy: 6.3492e-04 - val_loss: 0.1384 - val_accuracy: 0.0057\n",
            "Epoch 9367/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0220 - accuracy: 6.3492e-04 - val_loss: 0.1383 - val_accuracy: 0.0057\n",
            "Epoch 9368/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0220 - accuracy: 6.3492e-04 - val_loss: 0.1383 - val_accuracy: 0.0057\n",
            "Epoch 9369/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0219 - accuracy: 6.3492e-04 - val_loss: 0.1382 - val_accuracy: 0.0057\n",
            "Epoch 9370/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0219 - accuracy: 6.3492e-04 - val_loss: 0.1382 - val_accuracy: 0.0057\n",
            "Epoch 9371/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0219 - accuracy: 6.3492e-04 - val_loss: 0.1381 - val_accuracy: 0.0057\n",
            "Epoch 9372/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0219 - accuracy: 6.3492e-04 - val_loss: 0.1381 - val_accuracy: 0.0057\n",
            "Epoch 9373/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0219 - accuracy: 6.3492e-04 - val_loss: 0.1380 - val_accuracy: 0.0057\n",
            "Epoch 9374/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0219 - accuracy: 6.3492e-04 - val_loss: 0.1379 - val_accuracy: 0.0057\n",
            "Epoch 9375/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0219 - accuracy: 6.3492e-04 - val_loss: 0.1379 - val_accuracy: 0.0057\n",
            "Epoch 9376/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0219 - accuracy: 6.3492e-04 - val_loss: 0.1378 - val_accuracy: 0.0057\n",
            "Epoch 9377/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0218 - accuracy: 6.3492e-04 - val_loss: 0.1378 - val_accuracy: 0.0057\n",
            "Epoch 9378/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0218 - accuracy: 6.3492e-04 - val_loss: 0.1377 - val_accuracy: 0.0057\n",
            "Epoch 9379/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0218 - accuracy: 6.3492e-04 - val_loss: 0.1377 - val_accuracy: 0.0057\n",
            "Epoch 9380/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0218 - accuracy: 6.3492e-04 - val_loss: 0.1376 - val_accuracy: 0.0057\n",
            "Epoch 9381/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0218 - accuracy: 6.3492e-04 - val_loss: 0.1375 - val_accuracy: 0.0057\n",
            "Epoch 9382/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0218 - accuracy: 6.3492e-04 - val_loss: 0.1375 - val_accuracy: 0.0057\n",
            "Epoch 9383/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0218 - accuracy: 6.3492e-04 - val_loss: 0.1374 - val_accuracy: 0.0057\n",
            "Epoch 9384/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0218 - accuracy: 6.3492e-04 - val_loss: 0.1374 - val_accuracy: 0.0057\n",
            "Epoch 9385/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0217 - accuracy: 6.3492e-04 - val_loss: 0.1373 - val_accuracy: 0.0057\n",
            "Epoch 9386/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0217 - accuracy: 6.3492e-04 - val_loss: 0.1373 - val_accuracy: 0.0057\n",
            "Epoch 9387/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0217 - accuracy: 6.3492e-04 - val_loss: 0.1372 - val_accuracy: 0.0057\n",
            "Epoch 9388/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0217 - accuracy: 6.3492e-04 - val_loss: 0.1371 - val_accuracy: 0.0057\n",
            "Epoch 9389/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0217 - accuracy: 6.3492e-04 - val_loss: 0.1371 - val_accuracy: 0.0057\n",
            "Epoch 9390/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0217 - accuracy: 6.3492e-04 - val_loss: 0.1370 - val_accuracy: 0.0057\n",
            "Epoch 9391/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0217 - accuracy: 6.3492e-04 - val_loss: 0.1370 - val_accuracy: 0.0057\n",
            "Epoch 9392/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0217 - accuracy: 6.3492e-04 - val_loss: 0.1369 - val_accuracy: 0.0057\n",
            "Epoch 9393/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0216 - accuracy: 6.3492e-04 - val_loss: 0.1368 - val_accuracy: 0.0057\n",
            "Epoch 9394/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0216 - accuracy: 6.3492e-04 - val_loss: 0.1368 - val_accuracy: 0.0057\n",
            "Epoch 9395/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0216 - accuracy: 6.3492e-04 - val_loss: 0.1367 - val_accuracy: 0.0057\n",
            "Epoch 9396/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0216 - accuracy: 6.3492e-04 - val_loss: 0.1367 - val_accuracy: 0.0057\n",
            "Epoch 9397/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0216 - accuracy: 6.3492e-04 - val_loss: 0.1366 - val_accuracy: 0.0057\n",
            "Epoch 9398/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0216 - accuracy: 6.3492e-04 - val_loss: 0.1366 - val_accuracy: 0.0057\n",
            "Epoch 9399/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0216 - accuracy: 6.3492e-04 - val_loss: 0.1365 - val_accuracy: 0.0057\n",
            "Epoch 9400/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0216 - accuracy: 6.3492e-04 - val_loss: 0.1364 - val_accuracy: 0.0057\n",
            "Epoch 9401/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1364 - val_accuracy: 0.0057\n",
            "Epoch 9402/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1363 - val_accuracy: 0.0057\n",
            "Epoch 9403/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1363 - val_accuracy: 0.0057\n",
            "Epoch 9404/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1362 - val_accuracy: 0.0057\n",
            "Epoch 9405/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1362 - val_accuracy: 0.0057\n",
            "Epoch 9406/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1361 - val_accuracy: 0.0057\n",
            "Epoch 9407/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1360 - val_accuracy: 0.0057\n",
            "Epoch 9408/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1360 - val_accuracy: 0.0057\n",
            "Epoch 9409/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0215 - accuracy: 6.3492e-04 - val_loss: 0.1359 - val_accuracy: 0.0057\n",
            "Epoch 9410/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0214 - accuracy: 6.3492e-04 - val_loss: 0.1359 - val_accuracy: 0.0057\n",
            "Epoch 9411/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0214 - accuracy: 6.3492e-04 - val_loss: 0.1358 - val_accuracy: 0.0057\n",
            "Epoch 9412/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0214 - accuracy: 6.3492e-04 - val_loss: 0.1358 - val_accuracy: 0.0057\n",
            "Epoch 9413/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0214 - accuracy: 6.3492e-04 - val_loss: 0.1357 - val_accuracy: 0.0057\n",
            "Epoch 9414/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0214 - accuracy: 6.3492e-04 - val_loss: 0.1356 - val_accuracy: 0.0057\n",
            "Epoch 9415/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0214 - accuracy: 6.3492e-04 - val_loss: 0.1356 - val_accuracy: 0.0057\n",
            "Epoch 9416/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0214 - accuracy: 6.3492e-04 - val_loss: 0.1355 - val_accuracy: 0.0057\n",
            "Epoch 9417/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0214 - accuracy: 6.3492e-04 - val_loss: 0.1355 - val_accuracy: 0.0057\n",
            "Epoch 9418/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0213 - accuracy: 6.3492e-04 - val_loss: 0.1354 - val_accuracy: 0.0057\n",
            "Epoch 9419/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0213 - accuracy: 6.3492e-04 - val_loss: 0.1353 - val_accuracy: 0.0057\n",
            "Epoch 9420/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0213 - accuracy: 6.3492e-04 - val_loss: 0.1353 - val_accuracy: 0.0057\n",
            "Epoch 9421/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0213 - accuracy: 6.3492e-04 - val_loss: 0.1352 - val_accuracy: 0.0057\n",
            "Epoch 9422/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0213 - accuracy: 6.3492e-04 - val_loss: 0.1352 - val_accuracy: 0.0057\n",
            "Epoch 9423/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0213 - accuracy: 6.3492e-04 - val_loss: 0.1351 - val_accuracy: 0.0057\n",
            "Epoch 9424/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0213 - accuracy: 6.3492e-04 - val_loss: 0.1350 - val_accuracy: 0.0057\n",
            "Epoch 9425/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0213 - accuracy: 6.3492e-04 - val_loss: 0.1350 - val_accuracy: 0.0057\n",
            "Epoch 9426/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0212 - accuracy: 6.3492e-04 - val_loss: 0.1349 - val_accuracy: 0.0057\n",
            "Epoch 9427/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0212 - accuracy: 6.3492e-04 - val_loss: 0.1349 - val_accuracy: 0.0057\n",
            "Epoch 9428/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0212 - accuracy: 6.3492e-04 - val_loss: 0.1348 - val_accuracy: 0.0057\n",
            "Epoch 9429/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0212 - accuracy: 6.3492e-04 - val_loss: 0.1348 - val_accuracy: 0.0057\n",
            "Epoch 9430/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0212 - accuracy: 6.3492e-04 - val_loss: 0.1347 - val_accuracy: 0.0057\n",
            "Epoch 9431/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0212 - accuracy: 6.3492e-04 - val_loss: 0.1346 - val_accuracy: 0.0057\n",
            "Epoch 9432/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0212 - accuracy: 6.3492e-04 - val_loss: 0.1346 - val_accuracy: 0.0057\n",
            "Epoch 9433/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0212 - accuracy: 6.3492e-04 - val_loss: 0.1345 - val_accuracy: 0.0057\n",
            "Epoch 9434/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1345 - val_accuracy: 0.0057\n",
            "Epoch 9435/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1344 - val_accuracy: 0.0057\n",
            "Epoch 9436/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1344 - val_accuracy: 0.0057\n",
            "Epoch 9437/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1343 - val_accuracy: 0.0057\n",
            "Epoch 9438/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1342 - val_accuracy: 0.0057\n",
            "Epoch 9439/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1342 - val_accuracy: 0.0057\n",
            "Epoch 9440/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1341 - val_accuracy: 0.0057\n",
            "Epoch 9441/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1341 - val_accuracy: 0.0057\n",
            "Epoch 9442/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0211 - accuracy: 6.3492e-04 - val_loss: 0.1340 - val_accuracy: 0.0057\n",
            "Epoch 9443/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0210 - accuracy: 6.3492e-04 - val_loss: 0.1340 - val_accuracy: 0.0057\n",
            "Epoch 9444/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0210 - accuracy: 6.3492e-04 - val_loss: 0.1339 - val_accuracy: 0.0057\n",
            "Epoch 9445/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0210 - accuracy: 6.3492e-04 - val_loss: 0.1338 - val_accuracy: 0.0057\n",
            "Epoch 9446/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0210 - accuracy: 6.3492e-04 - val_loss: 0.1338 - val_accuracy: 0.0057\n",
            "Epoch 9447/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0210 - accuracy: 6.3492e-04 - val_loss: 0.1337 - val_accuracy: 0.0057\n",
            "Epoch 9448/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0210 - accuracy: 6.3492e-04 - val_loss: 0.1337 - val_accuracy: 0.0057\n",
            "Epoch 9449/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0210 - accuracy: 6.3492e-04 - val_loss: 0.1336 - val_accuracy: 0.0057\n",
            "Epoch 9450/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0210 - accuracy: 6.3492e-04 - val_loss: 0.1335 - val_accuracy: 0.0057\n",
            "Epoch 9451/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0209 - accuracy: 6.3492e-04 - val_loss: 0.1335 - val_accuracy: 0.0057\n",
            "Epoch 9452/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0209 - accuracy: 6.3492e-04 - val_loss: 0.1334 - val_accuracy: 0.0057\n",
            "Epoch 9453/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0209 - accuracy: 6.3492e-04 - val_loss: 0.1334 - val_accuracy: 0.0057\n",
            "Epoch 9454/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0209 - accuracy: 6.3492e-04 - val_loss: 0.1333 - val_accuracy: 0.0057\n",
            "Epoch 9455/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0209 - accuracy: 6.3492e-04 - val_loss: 0.1332 - val_accuracy: 0.0057\n",
            "Epoch 9456/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0209 - accuracy: 6.3492e-04 - val_loss: 0.1332 - val_accuracy: 0.0057\n",
            "Epoch 9457/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0209 - accuracy: 6.3492e-04 - val_loss: 0.1331 - val_accuracy: 0.0057\n",
            "Epoch 9458/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0209 - accuracy: 6.3492e-04 - val_loss: 0.1331 - val_accuracy: 0.0057\n",
            "Epoch 9459/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1330 - val_accuracy: 0.0057\n",
            "Epoch 9460/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1329 - val_accuracy: 0.0057\n",
            "Epoch 9461/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1329 - val_accuracy: 0.0057\n",
            "Epoch 9462/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1328 - val_accuracy: 0.0057\n",
            "Epoch 9463/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1328 - val_accuracy: 0.0057\n",
            "Epoch 9464/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1327 - val_accuracy: 0.0057\n",
            "Epoch 9465/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1327 - val_accuracy: 0.0057\n",
            "Epoch 9466/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1326 - val_accuracy: 0.0057\n",
            "Epoch 9467/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0208 - accuracy: 6.3492e-04 - val_loss: 0.1326 - val_accuracy: 0.0057\n",
            "Epoch 9468/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0207 - accuracy: 6.3492e-04 - val_loss: 0.1325 - val_accuracy: 0.0057\n",
            "Epoch 9469/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0207 - accuracy: 6.3492e-04 - val_loss: 0.1324 - val_accuracy: 0.0057\n",
            "Epoch 9470/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0207 - accuracy: 6.3492e-04 - val_loss: 0.1324 - val_accuracy: 0.0057\n",
            "Epoch 9471/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0207 - accuracy: 6.3492e-04 - val_loss: 0.1323 - val_accuracy: 0.0057\n",
            "Epoch 9472/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0207 - accuracy: 6.3492e-04 - val_loss: 0.1323 - val_accuracy: 0.0057\n",
            "Epoch 9473/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0207 - accuracy: 6.3492e-04 - val_loss: 0.1322 - val_accuracy: 0.0057\n",
            "Epoch 9474/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0207 - accuracy: 6.3492e-04 - val_loss: 0.1321 - val_accuracy: 0.0057\n",
            "Epoch 9475/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0207 - accuracy: 6.3492e-04 - val_loss: 0.1321 - val_accuracy: 0.0057\n",
            "Epoch 9476/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1320 - val_accuracy: 0.0057\n",
            "Epoch 9477/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1320 - val_accuracy: 0.0057\n",
            "Epoch 9478/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1319 - val_accuracy: 0.0057\n",
            "Epoch 9479/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1318 - val_accuracy: 0.0057\n",
            "Epoch 9480/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1318 - val_accuracy: 0.0057\n",
            "Epoch 9481/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1317 - val_accuracy: 0.0057\n",
            "Epoch 9482/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1317 - val_accuracy: 0.0057\n",
            "Epoch 9483/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1316 - val_accuracy: 0.0057\n",
            "Epoch 9484/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0206 - accuracy: 6.3492e-04 - val_loss: 0.1315 - val_accuracy: 0.0057\n",
            "Epoch 9485/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0205 - accuracy: 6.3492e-04 - val_loss: 0.1315 - val_accuracy: 0.0057\n",
            "Epoch 9486/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0205 - accuracy: 6.3492e-04 - val_loss: 0.1314 - val_accuracy: 0.0057\n",
            "Epoch 9487/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0205 - accuracy: 6.3492e-04 - val_loss: 0.1314 - val_accuracy: 0.0057\n",
            "Epoch 9488/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0205 - accuracy: 6.3492e-04 - val_loss: 0.1313 - val_accuracy: 0.0057\n",
            "Epoch 9489/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0205 - accuracy: 6.3492e-04 - val_loss: 0.1312 - val_accuracy: 0.0057\n",
            "Epoch 9490/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0205 - accuracy: 6.3492e-04 - val_loss: 0.1312 - val_accuracy: 0.0057\n",
            "Epoch 9491/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0205 - accuracy: 6.3492e-04 - val_loss: 0.1311 - val_accuracy: 0.0057\n",
            "Epoch 9492/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0205 - accuracy: 6.3492e-04 - val_loss: 0.1311 - val_accuracy: 0.0057\n",
            "Epoch 9493/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1310 - val_accuracy: 0.0057\n",
            "Epoch 9494/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1310 - val_accuracy: 0.0057\n",
            "Epoch 9495/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1309 - val_accuracy: 0.0057\n",
            "Epoch 9496/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1308 - val_accuracy: 0.0057\n",
            "Epoch 9497/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1308 - val_accuracy: 0.0057\n",
            "Epoch 9498/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1307 - val_accuracy: 0.0057\n",
            "Epoch 9499/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1307 - val_accuracy: 0.0057\n",
            "Epoch 9500/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1306 - val_accuracy: 0.0057\n",
            "Epoch 9501/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0204 - accuracy: 6.3492e-04 - val_loss: 0.1306 - val_accuracy: 0.0057\n",
            "Epoch 9502/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0203 - accuracy: 6.3492e-04 - val_loss: 0.1305 - val_accuracy: 0.0057\n",
            "Epoch 9503/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0203 - accuracy: 6.3492e-04 - val_loss: 0.1304 - val_accuracy: 0.0057\n",
            "Epoch 9504/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0203 - accuracy: 6.3492e-04 - val_loss: 0.1304 - val_accuracy: 0.0057\n",
            "Epoch 9505/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0203 - accuracy: 6.3492e-04 - val_loss: 0.1303 - val_accuracy: 0.0057\n",
            "Epoch 9506/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0203 - accuracy: 6.3492e-04 - val_loss: 0.1303 - val_accuracy: 0.0057\n",
            "Epoch 9507/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0203 - accuracy: 6.3492e-04 - val_loss: 0.1302 - val_accuracy: 0.0057\n",
            "Epoch 9508/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0203 - accuracy: 6.3492e-04 - val_loss: 0.1301 - val_accuracy: 0.0057\n",
            "Epoch 9509/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0203 - accuracy: 6.3492e-04 - val_loss: 0.1301 - val_accuracy: 0.0057\n",
            "Epoch 9510/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1300 - val_accuracy: 0.0057\n",
            "Epoch 9511/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1300 - val_accuracy: 0.0057\n",
            "Epoch 9512/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1299 - val_accuracy: 0.0057\n",
            "Epoch 9513/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1298 - val_accuracy: 0.0057\n",
            "Epoch 9514/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1298 - val_accuracy: 0.0057\n",
            "Epoch 9515/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1297 - val_accuracy: 0.0057\n",
            "Epoch 9516/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1297 - val_accuracy: 0.0057\n",
            "Epoch 9517/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1296 - val_accuracy: 0.0057\n",
            "Epoch 9518/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0202 - accuracy: 6.3492e-04 - val_loss: 0.1296 - val_accuracy: 0.0057\n",
            "Epoch 9519/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0201 - accuracy: 6.3492e-04 - val_loss: 0.1295 - val_accuracy: 0.0057\n",
            "Epoch 9520/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0201 - accuracy: 6.3492e-04 - val_loss: 0.1294 - val_accuracy: 0.0057\n",
            "Epoch 9521/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0201 - accuracy: 6.3492e-04 - val_loss: 0.1294 - val_accuracy: 0.0057\n",
            "Epoch 9522/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0201 - accuracy: 6.3492e-04 - val_loss: 0.1293 - val_accuracy: 0.0057\n",
            "Epoch 9523/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0201 - accuracy: 6.3492e-04 - val_loss: 0.1293 - val_accuracy: 0.0057\n",
            "Epoch 9524/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0201 - accuracy: 6.3492e-04 - val_loss: 0.1292 - val_accuracy: 0.0057\n",
            "Epoch 9525/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0201 - accuracy: 6.3492e-04 - val_loss: 0.1292 - val_accuracy: 0.0057\n",
            "Epoch 9526/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0201 - accuracy: 6.3492e-04 - val_loss: 0.1291 - val_accuracy: 0.0057\n",
            "Epoch 9527/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1290 - val_accuracy: 0.0057\n",
            "Epoch 9528/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1290 - val_accuracy: 0.0057\n",
            "Epoch 9529/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1289 - val_accuracy: 0.0057\n",
            "Epoch 9530/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1289 - val_accuracy: 0.0057\n",
            "Epoch 9531/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1288 - val_accuracy: 0.0057\n",
            "Epoch 9532/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1288 - val_accuracy: 0.0057\n",
            "Epoch 9533/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1287 - val_accuracy: 0.0057\n",
            "Epoch 9534/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1286 - val_accuracy: 0.0057\n",
            "Epoch 9535/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0200 - accuracy: 6.3492e-04 - val_loss: 0.1286 - val_accuracy: 0.0057\n",
            "Epoch 9536/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1285 - val_accuracy: 0.0057\n",
            "Epoch 9537/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1285 - val_accuracy: 0.0057\n",
            "Epoch 9538/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1284 - val_accuracy: 0.0057\n",
            "Epoch 9539/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1284 - val_accuracy: 0.0057\n",
            "Epoch 9540/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1283 - val_accuracy: 0.0057\n",
            "Epoch 9541/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1282 - val_accuracy: 0.0057\n",
            "Epoch 9542/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1282 - val_accuracy: 0.0057\n",
            "Epoch 9543/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1281 - val_accuracy: 0.0057\n",
            "Epoch 9544/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0199 - accuracy: 6.3492e-04 - val_loss: 0.1281 - val_accuracy: 0.0057\n",
            "Epoch 9545/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0198 - accuracy: 6.3492e-04 - val_loss: 0.1280 - val_accuracy: 0.0057\n",
            "Epoch 9546/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0198 - accuracy: 6.3492e-04 - val_loss: 0.1280 - val_accuracy: 0.0057\n",
            "Epoch 9547/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0198 - accuracy: 6.3492e-04 - val_loss: 0.1279 - val_accuracy: 0.0057\n",
            "Epoch 9548/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0198 - accuracy: 6.3492e-04 - val_loss: 0.1278 - val_accuracy: 0.0057\n",
            "Epoch 9549/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0198 - accuracy: 6.3492e-04 - val_loss: 0.1278 - val_accuracy: 0.0057\n",
            "Epoch 9550/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0198 - accuracy: 6.3492e-04 - val_loss: 0.1277 - val_accuracy: 0.0057\n",
            "Epoch 9551/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0198 - accuracy: 6.3492e-04 - val_loss: 0.1277 - val_accuracy: 0.0057\n",
            "Epoch 9552/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0198 - accuracy: 6.3492e-04 - val_loss: 0.1276 - val_accuracy: 0.0057\n",
            "Epoch 9553/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1276 - val_accuracy: 0.0057\n",
            "Epoch 9554/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1275 - val_accuracy: 0.0057\n",
            "Epoch 9555/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1274 - val_accuracy: 0.0057\n",
            "Epoch 9556/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1274 - val_accuracy: 0.0057\n",
            "Epoch 9557/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1273 - val_accuracy: 0.0057\n",
            "Epoch 9558/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1273 - val_accuracy: 0.0057\n",
            "Epoch 9559/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1272 - val_accuracy: 0.0057\n",
            "Epoch 9560/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1272 - val_accuracy: 0.0057\n",
            "Epoch 9561/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0197 - accuracy: 6.3492e-04 - val_loss: 0.1271 - val_accuracy: 0.0057\n",
            "Epoch 9562/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1270 - val_accuracy: 0.0057\n",
            "Epoch 9563/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1270 - val_accuracy: 0.0057\n",
            "Epoch 9564/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1269 - val_accuracy: 0.0057\n",
            "Epoch 9565/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1269 - val_accuracy: 0.0057\n",
            "Epoch 9566/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1268 - val_accuracy: 0.0057\n",
            "Epoch 9567/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1268 - val_accuracy: 0.0057\n",
            "Epoch 9568/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1267 - val_accuracy: 0.0057\n",
            "Epoch 9569/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1266 - val_accuracy: 0.0057\n",
            "Epoch 9570/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0196 - accuracy: 6.3492e-04 - val_loss: 0.1266 - val_accuracy: 0.0057\n",
            "Epoch 9571/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1265 - val_accuracy: 0.0057\n",
            "Epoch 9572/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1265 - val_accuracy: 0.0057\n",
            "Epoch 9573/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1264 - val_accuracy: 0.0057\n",
            "Epoch 9574/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1263 - val_accuracy: 0.0057\n",
            "Epoch 9575/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1263 - val_accuracy: 0.0057\n",
            "Epoch 9576/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1262 - val_accuracy: 0.0057\n",
            "Epoch 9577/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1262 - val_accuracy: 0.0057\n",
            "Epoch 9578/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1261 - val_accuracy: 0.0057\n",
            "Epoch 9579/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0195 - accuracy: 6.3492e-04 - val_loss: 0.1260 - val_accuracy: 0.0057\n",
            "Epoch 9580/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1260 - val_accuracy: 0.0057\n",
            "Epoch 9581/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1259 - val_accuracy: 0.0057\n",
            "Epoch 9582/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1259 - val_accuracy: 0.0057\n",
            "Epoch 9583/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1258 - val_accuracy: 0.0057\n",
            "Epoch 9584/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1258 - val_accuracy: 0.0057\n",
            "Epoch 9585/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1257 - val_accuracy: 0.0057\n",
            "Epoch 9586/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1256 - val_accuracy: 0.0057\n",
            "Epoch 9587/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1256 - val_accuracy: 0.0057\n",
            "Epoch 9588/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0194 - accuracy: 6.3492e-04 - val_loss: 0.1255 - val_accuracy: 0.0057\n",
            "Epoch 9589/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0193 - accuracy: 6.3492e-04 - val_loss: 0.1255 - val_accuracy: 0.0057\n",
            "Epoch 9590/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0193 - accuracy: 6.3492e-04 - val_loss: 0.1254 - val_accuracy: 0.0057\n",
            "Epoch 9591/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0193 - accuracy: 6.3492e-04 - val_loss: 0.1253 - val_accuracy: 0.0057\n",
            "Epoch 9592/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0193 - accuracy: 6.3492e-04 - val_loss: 0.1253 - val_accuracy: 0.0057\n",
            "Epoch 9593/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0193 - accuracy: 6.3492e-04 - val_loss: 0.1252 - val_accuracy: 0.0057\n",
            "Epoch 9594/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0193 - accuracy: 6.3492e-04 - val_loss: 0.1252 - val_accuracy: 0.0057\n",
            "Epoch 9595/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0193 - accuracy: 6.3492e-04 - val_loss: 0.1251 - val_accuracy: 0.0057\n",
            "Epoch 9596/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0193 - accuracy: 6.3492e-04 - val_loss: 0.1250 - val_accuracy: 0.0057\n",
            "Epoch 9597/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1250 - val_accuracy: 0.0057\n",
            "Epoch 9598/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1249 - val_accuracy: 0.0057\n",
            "Epoch 9599/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1249 - val_accuracy: 0.0057\n",
            "Epoch 9600/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1248 - val_accuracy: 0.0057\n",
            "Epoch 9601/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1248 - val_accuracy: 0.0057\n",
            "Epoch 9602/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1247 - val_accuracy: 0.0057\n",
            "Epoch 9603/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1247 - val_accuracy: 0.0057\n",
            "Epoch 9604/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1246 - val_accuracy: 0.0057\n",
            "Epoch 9605/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0192 - accuracy: 6.3492e-04 - val_loss: 0.1245 - val_accuracy: 0.0057\n",
            "Epoch 9606/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1245 - val_accuracy: 0.0057\n",
            "Epoch 9607/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1244 - val_accuracy: 0.0057\n",
            "Epoch 9608/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1244 - val_accuracy: 0.0057\n",
            "Epoch 9609/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1243 - val_accuracy: 0.0057\n",
            "Epoch 9610/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1243 - val_accuracy: 0.0057\n",
            "Epoch 9611/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1242 - val_accuracy: 0.0057\n",
            "Epoch 9612/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1241 - val_accuracy: 0.0057\n",
            "Epoch 9613/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1241 - val_accuracy: 0.0057\n",
            "Epoch 9614/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0191 - accuracy: 6.3492e-04 - val_loss: 0.1240 - val_accuracy: 0.0057\n",
            "Epoch 9615/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1240 - val_accuracy: 0.0057\n",
            "Epoch 9616/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1239 - val_accuracy: 0.0057\n",
            "Epoch 9617/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1239 - val_accuracy: 0.0057\n",
            "Epoch 9618/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1238 - val_accuracy: 0.0057\n",
            "Epoch 9619/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1238 - val_accuracy: 0.0057\n",
            "Epoch 9620/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1237 - val_accuracy: 0.0057\n",
            "Epoch 9621/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1236 - val_accuracy: 0.0057\n",
            "Epoch 9622/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1236 - val_accuracy: 0.0057\n",
            "Epoch 9623/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0190 - accuracy: 6.3492e-04 - val_loss: 0.1235 - val_accuracy: 0.0057\n",
            "Epoch 9624/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1235 - val_accuracy: 0.0057\n",
            "Epoch 9625/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1234 - val_accuracy: 0.0057\n",
            "Epoch 9626/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1234 - val_accuracy: 0.0057\n",
            "Epoch 9627/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1233 - val_accuracy: 0.0057\n",
            "Epoch 9628/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1233 - val_accuracy: 0.0057\n",
            "Epoch 9629/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1232 - val_accuracy: 0.0057\n",
            "Epoch 9630/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1231 - val_accuracy: 0.0057\n",
            "Epoch 9631/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1231 - val_accuracy: 0.0057\n",
            "Epoch 9632/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1230 - val_accuracy: 0.0057\n",
            "Epoch 9633/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0189 - accuracy: 6.3492e-04 - val_loss: 0.1230 - val_accuracy: 0.0057\n",
            "Epoch 9634/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1229 - val_accuracy: 0.0057\n",
            "Epoch 9635/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1229 - val_accuracy: 0.0057\n",
            "Epoch 9636/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1228 - val_accuracy: 0.0057\n",
            "Epoch 9637/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1228 - val_accuracy: 0.0057\n",
            "Epoch 9638/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1227 - val_accuracy: 0.0057\n",
            "Epoch 9639/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1226 - val_accuracy: 0.0057\n",
            "Epoch 9640/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1226 - val_accuracy: 0.0057\n",
            "Epoch 9641/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1225 - val_accuracy: 0.0057\n",
            "Epoch 9642/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0188 - accuracy: 6.3492e-04 - val_loss: 0.1225 - val_accuracy: 0.0057\n",
            "Epoch 9643/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1224 - val_accuracy: 0.0057\n",
            "Epoch 9644/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1224 - val_accuracy: 0.0057\n",
            "Epoch 9645/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1223 - val_accuracy: 0.0057\n",
            "Epoch 9646/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1222 - val_accuracy: 0.0057\n",
            "Epoch 9647/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1222 - val_accuracy: 0.0057\n",
            "Epoch 9648/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1221 - val_accuracy: 0.0057\n",
            "Epoch 9649/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1221 - val_accuracy: 0.0057\n",
            "Epoch 9650/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1220 - val_accuracy: 0.0057\n",
            "Epoch 9651/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0187 - accuracy: 6.3492e-04 - val_loss: 0.1220 - val_accuracy: 0.0057\n",
            "Epoch 9652/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1219 - val_accuracy: 0.0057\n",
            "Epoch 9653/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1218 - val_accuracy: 0.0057\n",
            "Epoch 9654/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1218 - val_accuracy: 0.0057\n",
            "Epoch 9655/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1217 - val_accuracy: 0.0057\n",
            "Epoch 9656/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1217 - val_accuracy: 0.0057\n",
            "Epoch 9657/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1216 - val_accuracy: 0.0057\n",
            "Epoch 9658/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1216 - val_accuracy: 0.0057\n",
            "Epoch 9659/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1215 - val_accuracy: 0.0057\n",
            "Epoch 9660/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0186 - accuracy: 6.3492e-04 - val_loss: 0.1215 - val_accuracy: 0.0057\n",
            "Epoch 9661/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1214 - val_accuracy: 0.0057\n",
            "Epoch 9662/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1214 - val_accuracy: 0.0057\n",
            "Epoch 9663/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1213 - val_accuracy: 0.0057\n",
            "Epoch 9664/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1212 - val_accuracy: 0.0057\n",
            "Epoch 9665/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1212 - val_accuracy: 0.0057\n",
            "Epoch 9666/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1211 - val_accuracy: 0.0057\n",
            "Epoch 9667/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1211 - val_accuracy: 0.0057\n",
            "Epoch 9668/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1210 - val_accuracy: 0.0057\n",
            "Epoch 9669/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0185 - accuracy: 6.3492e-04 - val_loss: 0.1210 - val_accuracy: 0.0057\n",
            "Epoch 9670/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1209 - val_accuracy: 0.0057\n",
            "Epoch 9671/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1209 - val_accuracy: 0.0057\n",
            "Epoch 9672/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1208 - val_accuracy: 0.0057\n",
            "Epoch 9673/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1208 - val_accuracy: 0.0057\n",
            "Epoch 9674/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1207 - val_accuracy: 0.0057\n",
            "Epoch 9675/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1206 - val_accuracy: 0.0057\n",
            "Epoch 9676/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1206 - val_accuracy: 0.0057\n",
            "Epoch 9677/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1205 - val_accuracy: 0.0057\n",
            "Epoch 9678/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1205 - val_accuracy: 0.0057\n",
            "Epoch 9679/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0184 - accuracy: 6.3492e-04 - val_loss: 0.1204 - val_accuracy: 0.0057\n",
            "Epoch 9680/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1204 - val_accuracy: 0.0057\n",
            "Epoch 9681/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1203 - val_accuracy: 0.0057\n",
            "Epoch 9682/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1203 - val_accuracy: 0.0057\n",
            "Epoch 9683/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1202 - val_accuracy: 0.0057\n",
            "Epoch 9684/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1201 - val_accuracy: 0.0057\n",
            "Epoch 9685/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1201 - val_accuracy: 0.0057\n",
            "Epoch 9686/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1200 - val_accuracy: 0.0057\n",
            "Epoch 9687/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1200 - val_accuracy: 0.0057\n",
            "Epoch 9688/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0183 - accuracy: 6.3492e-04 - val_loss: 0.1199 - val_accuracy: 0.0057\n",
            "Epoch 9689/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1199 - val_accuracy: 0.0057\n",
            "Epoch 9690/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1198 - val_accuracy: 0.0057\n",
            "Epoch 9691/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1198 - val_accuracy: 0.0057\n",
            "Epoch 9692/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1197 - val_accuracy: 0.0057\n",
            "Epoch 9693/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1197 - val_accuracy: 0.0057\n",
            "Epoch 9694/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1196 - val_accuracy: 0.0057\n",
            "Epoch 9695/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1196 - val_accuracy: 0.0057\n",
            "Epoch 9696/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1195 - val_accuracy: 0.0057\n",
            "Epoch 9697/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1195 - val_accuracy: 0.0057\n",
            "Epoch 9698/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0182 - accuracy: 6.3492e-04 - val_loss: 0.1194 - val_accuracy: 0.0057\n",
            "Epoch 9699/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1193 - val_accuracy: 0.0057\n",
            "Epoch 9700/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1193 - val_accuracy: 0.0057\n",
            "Epoch 9701/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1192 - val_accuracy: 0.0057\n",
            "Epoch 9702/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1192 - val_accuracy: 0.0057\n",
            "Epoch 9703/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1191 - val_accuracy: 0.0057\n",
            "Epoch 9704/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1191 - val_accuracy: 0.0057\n",
            "Epoch 9705/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1190 - val_accuracy: 0.0057\n",
            "Epoch 9706/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1190 - val_accuracy: 0.0057\n",
            "Epoch 9707/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0181 - accuracy: 6.3492e-04 - val_loss: 0.1189 - val_accuracy: 0.0057\n",
            "Epoch 9708/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1189 - val_accuracy: 0.0057\n",
            "Epoch 9709/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1188 - val_accuracy: 0.0057\n",
            "Epoch 9710/10000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1188 - val_accuracy: 0.0057\n",
            "Epoch 9711/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1187 - val_accuracy: 0.0057\n",
            "Epoch 9712/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1187 - val_accuracy: 0.0057\n",
            "Epoch 9713/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1186 - val_accuracy: 0.0057\n",
            "Epoch 9714/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1186 - val_accuracy: 0.0057\n",
            "Epoch 9715/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1185 - val_accuracy: 0.0057\n",
            "Epoch 9716/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1185 - val_accuracy: 0.0057\n",
            "Epoch 9717/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0180 - accuracy: 6.3492e-04 - val_loss: 0.1184 - val_accuracy: 0.0057\n",
            "Epoch 9718/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1184 - val_accuracy: 0.0057\n",
            "Epoch 9719/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1183 - val_accuracy: 0.0057\n",
            "Epoch 9720/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1183 - val_accuracy: 0.0057\n",
            "Epoch 9721/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1182 - val_accuracy: 0.0057\n",
            "Epoch 9722/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1182 - val_accuracy: 0.0057\n",
            "Epoch 9723/10000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1181 - val_accuracy: 0.0057\n",
            "Epoch 9724/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1181 - val_accuracy: 0.0057\n",
            "Epoch 9725/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1180 - val_accuracy: 0.0057\n",
            "Epoch 9726/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1180 - val_accuracy: 0.0057\n",
            "Epoch 9727/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0179 - accuracy: 6.3492e-04 - val_loss: 0.1179 - val_accuracy: 0.0057\n",
            "Epoch 9728/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1179 - val_accuracy: 0.0057\n",
            "Epoch 9729/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1178 - val_accuracy: 0.0057\n",
            "Epoch 9730/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1178 - val_accuracy: 0.0057\n",
            "Epoch 9731/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1177 - val_accuracy: 0.0057\n",
            "Epoch 9732/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1177 - val_accuracy: 0.0057\n",
            "Epoch 9733/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1176 - val_accuracy: 0.0057\n",
            "Epoch 9734/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1176 - val_accuracy: 0.0057\n",
            "Epoch 9735/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1175 - val_accuracy: 0.0057\n",
            "Epoch 9736/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0178 - accuracy: 6.3492e-04 - val_loss: 0.1175 - val_accuracy: 0.0057\n",
            "Epoch 9737/10000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1174 - val_accuracy: 0.0057\n",
            "Epoch 9738/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1174 - val_accuracy: 0.0057\n",
            "Epoch 9739/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1173 - val_accuracy: 0.0057\n",
            "Epoch 9740/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1173 - val_accuracy: 0.0057\n",
            "Epoch 9741/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1172 - val_accuracy: 0.0057\n",
            "Epoch 9742/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1172 - val_accuracy: 0.0057\n",
            "Epoch 9743/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1171 - val_accuracy: 0.0057\n",
            "Epoch 9744/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1171 - val_accuracy: 0.0057\n",
            "Epoch 9745/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1170 - val_accuracy: 0.0057\n",
            "Epoch 9746/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0177 - accuracy: 6.3492e-04 - val_loss: 0.1169 - val_accuracy: 0.0057\n",
            "Epoch 9747/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1169 - val_accuracy: 0.0057\n",
            "Epoch 9748/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1168 - val_accuracy: 0.0057\n",
            "Epoch 9749/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1168 - val_accuracy: 0.0057\n",
            "Epoch 9750/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1167 - val_accuracy: 0.0057\n",
            "Epoch 9751/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1167 - val_accuracy: 0.0057\n",
            "Epoch 9752/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1166 - val_accuracy: 0.0057\n",
            "Epoch 9753/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1166 - val_accuracy: 0.0057\n",
            "Epoch 9754/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1165 - val_accuracy: 0.0057\n",
            "Epoch 9755/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1165 - val_accuracy: 0.0057\n",
            "Epoch 9756/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0176 - accuracy: 6.3492e-04 - val_loss: 0.1164 - val_accuracy: 0.0057\n",
            "Epoch 9757/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1164 - val_accuracy: 0.0057\n",
            "Epoch 9758/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1163 - val_accuracy: 0.0057\n",
            "Epoch 9759/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1163 - val_accuracy: 0.0057\n",
            "Epoch 9760/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1162 - val_accuracy: 0.0057\n",
            "Epoch 9761/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1162 - val_accuracy: 0.0057\n",
            "Epoch 9762/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1161 - val_accuracy: 0.0057\n",
            "Epoch 9763/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1161 - val_accuracy: 0.0057\n",
            "Epoch 9764/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1160 - val_accuracy: 0.0057\n",
            "Epoch 9765/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1160 - val_accuracy: 0.0057\n",
            "Epoch 9766/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0175 - accuracy: 6.3492e-04 - val_loss: 0.1159 - val_accuracy: 0.0057\n",
            "Epoch 9767/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1159 - val_accuracy: 0.0057\n",
            "Epoch 9768/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1158 - val_accuracy: 0.0057\n",
            "Epoch 9769/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1158 - val_accuracy: 0.0057\n",
            "Epoch 9770/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1157 - val_accuracy: 0.0057\n",
            "Epoch 9771/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1157 - val_accuracy: 0.0057\n",
            "Epoch 9772/10000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1156 - val_accuracy: 0.0057\n",
            "Epoch 9773/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1156 - val_accuracy: 0.0057\n",
            "Epoch 9774/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1155 - val_accuracy: 0.0057\n",
            "Epoch 9775/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1155 - val_accuracy: 0.0057\n",
            "Epoch 9776/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0174 - accuracy: 6.3492e-04 - val_loss: 0.1154 - val_accuracy: 0.0057\n",
            "Epoch 9777/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1154 - val_accuracy: 0.0057\n",
            "Epoch 9778/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1153 - val_accuracy: 0.0057\n",
            "Epoch 9779/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1153 - val_accuracy: 0.0057\n",
            "Epoch 9780/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1152 - val_accuracy: 0.0057\n",
            "Epoch 9781/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1151 - val_accuracy: 0.0057\n",
            "Epoch 9782/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1151 - val_accuracy: 0.0057\n",
            "Epoch 9783/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1150 - val_accuracy: 0.0057\n",
            "Epoch 9784/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1150 - val_accuracy: 0.0057\n",
            "Epoch 9785/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1149 - val_accuracy: 0.0057\n",
            "Epoch 9786/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0173 - accuracy: 6.3492e-04 - val_loss: 0.1149 - val_accuracy: 0.0057\n",
            "Epoch 9787/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1148 - val_accuracy: 0.0057\n",
            "Epoch 9788/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1148 - val_accuracy: 0.0057\n",
            "Epoch 9789/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1147 - val_accuracy: 0.0057\n",
            "Epoch 9790/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1147 - val_accuracy: 0.0057\n",
            "Epoch 9791/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1146 - val_accuracy: 0.0057\n",
            "Epoch 9792/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1146 - val_accuracy: 0.0057\n",
            "Epoch 9793/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1145 - val_accuracy: 0.0057\n",
            "Epoch 9794/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1145 - val_accuracy: 0.0057\n",
            "Epoch 9795/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1144 - val_accuracy: 0.0057\n",
            "Epoch 9796/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1144 - val_accuracy: 0.0057\n",
            "Epoch 9797/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0172 - accuracy: 6.3492e-04 - val_loss: 0.1143 - val_accuracy: 0.0057\n",
            "Epoch 9798/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1143 - val_accuracy: 0.0057\n",
            "Epoch 9799/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1142 - val_accuracy: 0.0057\n",
            "Epoch 9800/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1142 - val_accuracy: 0.0057\n",
            "Epoch 9801/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1141 - val_accuracy: 0.0057\n",
            "Epoch 9802/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1141 - val_accuracy: 0.0057\n",
            "Epoch 9803/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1140 - val_accuracy: 0.0057\n",
            "Epoch 9804/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1140 - val_accuracy: 0.0057\n",
            "Epoch 9805/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1139 - val_accuracy: 0.0057\n",
            "Epoch 9806/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1139 - val_accuracy: 0.0057\n",
            "Epoch 9807/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 6.3492e-04 - val_loss: 0.1138 - val_accuracy: 0.0057\n",
            "Epoch 9808/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1138 - val_accuracy: 0.0057\n",
            "Epoch 9809/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1137 - val_accuracy: 0.0057\n",
            "Epoch 9810/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1137 - val_accuracy: 0.0057\n",
            "Epoch 9811/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1136 - val_accuracy: 0.0057\n",
            "Epoch 9812/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1136 - val_accuracy: 0.0057\n",
            "Epoch 9813/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1135 - val_accuracy: 0.0057\n",
            "Epoch 9814/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1135 - val_accuracy: 0.0057\n",
            "Epoch 9815/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1134 - val_accuracy: 0.0057\n",
            "Epoch 9816/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1134 - val_accuracy: 0.0057\n",
            "Epoch 9817/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0170 - accuracy: 6.3492e-04 - val_loss: 0.1133 - val_accuracy: 0.0057\n",
            "Epoch 9818/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1133 - val_accuracy: 0.0057\n",
            "Epoch 9819/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1132 - val_accuracy: 0.0057\n",
            "Epoch 9820/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1132 - val_accuracy: 0.0057\n",
            "Epoch 9821/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1131 - val_accuracy: 0.0057\n",
            "Epoch 9822/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1131 - val_accuracy: 0.0057\n",
            "Epoch 9823/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1130 - val_accuracy: 0.0057\n",
            "Epoch 9824/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1130 - val_accuracy: 0.0057\n",
            "Epoch 9825/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1129 - val_accuracy: 0.0057\n",
            "Epoch 9826/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1129 - val_accuracy: 0.0057\n",
            "Epoch 9827/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1128 - val_accuracy: 0.0057\n",
            "Epoch 9828/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0169 - accuracy: 6.3492e-04 - val_loss: 0.1128 - val_accuracy: 0.0057\n",
            "Epoch 9829/10000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1127 - val_accuracy: 0.0057\n",
            "Epoch 9830/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1127 - val_accuracy: 0.0057\n",
            "Epoch 9831/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1126 - val_accuracy: 0.0057\n",
            "Epoch 9832/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1126 - val_accuracy: 0.0057\n",
            "Epoch 9833/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1125 - val_accuracy: 0.0057\n",
            "Epoch 9834/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1125 - val_accuracy: 0.0057\n",
            "Epoch 9835/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1124 - val_accuracy: 0.0057\n",
            "Epoch 9836/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1124 - val_accuracy: 0.0057\n",
            "Epoch 9837/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1123 - val_accuracy: 0.0057\n",
            "Epoch 9838/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0168 - accuracy: 6.3492e-04 - val_loss: 0.1123 - val_accuracy: 0.0057\n",
            "Epoch 9839/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1122 - val_accuracy: 0.0057\n",
            "Epoch 9840/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1122 - val_accuracy: 0.0057\n",
            "Epoch 9841/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1122 - val_accuracy: 0.0057\n",
            "Epoch 9842/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1121 - val_accuracy: 0.0057\n",
            "Epoch 9843/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1120 - val_accuracy: 0.0057\n",
            "Epoch 9844/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1120 - val_accuracy: 0.0057\n",
            "Epoch 9845/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1119 - val_accuracy: 0.0057\n",
            "Epoch 9846/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1119 - val_accuracy: 0.0057\n",
            "Epoch 9847/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1119 - val_accuracy: 0.0057\n",
            "Epoch 9848/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1118 - val_accuracy: 0.0057\n",
            "Epoch 9849/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0167 - accuracy: 6.3492e-04 - val_loss: 0.1118 - val_accuracy: 0.0057\n",
            "Epoch 9850/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1117 - val_accuracy: 0.0057\n",
            "Epoch 9851/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1116 - val_accuracy: 0.0057\n",
            "Epoch 9852/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1116 - val_accuracy: 0.0057\n",
            "Epoch 9853/10000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1115 - val_accuracy: 0.0057\n",
            "Epoch 9854/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1115 - val_accuracy: 0.0057\n",
            "Epoch 9855/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1115 - val_accuracy: 0.0057\n",
            "Epoch 9856/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1114 - val_accuracy: 0.0057\n",
            "Epoch 9857/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1114 - val_accuracy: 0.0057\n",
            "Epoch 9858/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1113 - val_accuracy: 0.0057\n",
            "Epoch 9859/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0166 - accuracy: 6.3492e-04 - val_loss: 0.1113 - val_accuracy: 0.0057\n",
            "Epoch 9860/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1112 - val_accuracy: 0.0057\n",
            "Epoch 9861/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1112 - val_accuracy: 0.0057\n",
            "Epoch 9862/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1111 - val_accuracy: 0.0057\n",
            "Epoch 9863/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1111 - val_accuracy: 0.0057\n",
            "Epoch 9864/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1110 - val_accuracy: 0.0057\n",
            "Epoch 9865/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1110 - val_accuracy: 0.0057\n",
            "Epoch 9866/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1109 - val_accuracy: 0.0057\n",
            "Epoch 9867/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1109 - val_accuracy: 0.0057\n",
            "Epoch 9868/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1108 - val_accuracy: 0.0057\n",
            "Epoch 9869/10000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1108 - val_accuracy: 0.0057\n",
            "Epoch 9870/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0165 - accuracy: 6.3492e-04 - val_loss: 0.1107 - val_accuracy: 0.0057\n",
            "Epoch 9871/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1107 - val_accuracy: 0.0057\n",
            "Epoch 9872/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1106 - val_accuracy: 0.0057\n",
            "Epoch 9873/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1106 - val_accuracy: 0.0057\n",
            "Epoch 9874/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1105 - val_accuracy: 0.0057\n",
            "Epoch 9875/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1105 - val_accuracy: 0.0057\n",
            "Epoch 9876/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1104 - val_accuracy: 0.0057\n",
            "Epoch 9877/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1104 - val_accuracy: 0.0057\n",
            "Epoch 9878/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1103 - val_accuracy: 0.0057\n",
            "Epoch 9879/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1103 - val_accuracy: 0.0057\n",
            "Epoch 9880/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1102 - val_accuracy: 0.0057\n",
            "Epoch 9881/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0164 - accuracy: 6.3492e-04 - val_loss: 0.1102 - val_accuracy: 0.0057\n",
            "Epoch 9882/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1101 - val_accuracy: 0.0057\n",
            "Epoch 9883/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1101 - val_accuracy: 0.0057\n",
            "Epoch 9884/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1100 - val_accuracy: 0.0057\n",
            "Epoch 9885/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1100 - val_accuracy: 0.0057\n",
            "Epoch 9886/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1099 - val_accuracy: 0.0057\n",
            "Epoch 9887/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1099 - val_accuracy: 0.0057\n",
            "Epoch 9888/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1099 - val_accuracy: 0.0057\n",
            "Epoch 9889/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1098 - val_accuracy: 0.0057\n",
            "Epoch 9890/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1098 - val_accuracy: 0.0057\n",
            "Epoch 9891/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1097 - val_accuracy: 0.0057\n",
            "Epoch 9892/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0163 - accuracy: 6.3492e-04 - val_loss: 0.1097 - val_accuracy: 0.0057\n",
            "Epoch 9893/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1096 - val_accuracy: 0.0057\n",
            "Epoch 9894/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1096 - val_accuracy: 0.0057\n",
            "Epoch 9895/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1095 - val_accuracy: 0.0057\n",
            "Epoch 9896/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1095 - val_accuracy: 0.0057\n",
            "Epoch 9897/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1094 - val_accuracy: 0.0057\n",
            "Epoch 9898/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1094 - val_accuracy: 0.0057\n",
            "Epoch 9899/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1093 - val_accuracy: 0.0057\n",
            "Epoch 9900/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1093 - val_accuracy: 0.0057\n",
            "Epoch 9901/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1092 - val_accuracy: 0.0057\n",
            "Epoch 9902/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1092 - val_accuracy: 0.0057\n",
            "Epoch 9903/10000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0162 - accuracy: 6.3492e-04 - val_loss: 0.1091 - val_accuracy: 0.0057\n",
            "Epoch 9904/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1091 - val_accuracy: 0.0057\n",
            "Epoch 9905/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1090 - val_accuracy: 0.0057\n",
            "Epoch 9906/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1090 - val_accuracy: 0.0057\n",
            "Epoch 9907/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1089 - val_accuracy: 0.0057\n",
            "Epoch 9908/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1089 - val_accuracy: 0.0057\n",
            "Epoch 9909/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1088 - val_accuracy: 0.0057\n",
            "Epoch 9910/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1088 - val_accuracy: 0.0057\n",
            "Epoch 9911/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1088 - val_accuracy: 0.0057\n",
            "Epoch 9912/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1087 - val_accuracy: 0.0057\n",
            "Epoch 9913/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1087 - val_accuracy: 0.0057\n",
            "Epoch 9914/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0161 - accuracy: 6.3492e-04 - val_loss: 0.1086 - val_accuracy: 0.0057\n",
            "Epoch 9915/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1086 - val_accuracy: 0.0057\n",
            "Epoch 9916/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1085 - val_accuracy: 0.0057\n",
            "Epoch 9917/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1085 - val_accuracy: 0.0057\n",
            "Epoch 9918/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1084 - val_accuracy: 0.0057\n",
            "Epoch 9919/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1084 - val_accuracy: 0.0057\n",
            "Epoch 9920/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1083 - val_accuracy: 0.0057\n",
            "Epoch 9921/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1083 - val_accuracy: 0.0057\n",
            "Epoch 9922/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1082 - val_accuracy: 0.0057\n",
            "Epoch 9923/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1082 - val_accuracy: 0.0057\n",
            "Epoch 9924/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1081 - val_accuracy: 0.0057\n",
            "Epoch 9925/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0160 - accuracy: 6.3492e-04 - val_loss: 0.1081 - val_accuracy: 0.0057\n",
            "Epoch 9926/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1080 - val_accuracy: 0.0057\n",
            "Epoch 9927/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1080 - val_accuracy: 0.0057\n",
            "Epoch 9928/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1079 - val_accuracy: 0.0057\n",
            "Epoch 9929/10000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1079 - val_accuracy: 0.0057\n",
            "Epoch 9930/10000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1078 - val_accuracy: 0.0057\n",
            "Epoch 9931/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1078 - val_accuracy: 0.0057\n",
            "Epoch 9932/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1077 - val_accuracy: 0.0057\n",
            "Epoch 9933/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1077 - val_accuracy: 0.0057\n",
            "Epoch 9934/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1076 - val_accuracy: 0.0057\n",
            "Epoch 9935/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1076 - val_accuracy: 0.0057\n",
            "Epoch 9936/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0159 - accuracy: 6.3492e-04 - val_loss: 0.1075 - val_accuracy: 0.0057\n",
            "Epoch 9937/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1075 - val_accuracy: 0.0057\n",
            "Epoch 9938/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1074 - val_accuracy: 0.0057\n",
            "Epoch 9939/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1074 - val_accuracy: 0.0057\n",
            "Epoch 9940/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1073 - val_accuracy: 0.0057\n",
            "Epoch 9941/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1073 - val_accuracy: 0.0057\n",
            "Epoch 9942/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1072 - val_accuracy: 0.0057\n",
            "Epoch 9943/10000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1072 - val_accuracy: 0.0057\n",
            "Epoch 9944/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1071 - val_accuracy: 0.0057\n",
            "Epoch 9945/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1071 - val_accuracy: 0.0057\n",
            "Epoch 9946/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1071 - val_accuracy: 0.0057\n",
            "Epoch 9947/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1070 - val_accuracy: 0.0057\n",
            "Epoch 9948/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0158 - accuracy: 6.3492e-04 - val_loss: 0.1070 - val_accuracy: 0.0057\n",
            "Epoch 9949/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1069 - val_accuracy: 0.0057\n",
            "Epoch 9950/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1069 - val_accuracy: 0.0057\n",
            "Epoch 9951/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1068 - val_accuracy: 0.0057\n",
            "Epoch 9952/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1068 - val_accuracy: 0.0057\n",
            "Epoch 9953/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1067 - val_accuracy: 0.0057\n",
            "Epoch 9954/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1067 - val_accuracy: 0.0057\n",
            "Epoch 9955/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1066 - val_accuracy: 0.0057\n",
            "Epoch 9956/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1066 - val_accuracy: 0.0057\n",
            "Epoch 9957/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1065 - val_accuracy: 0.0057\n",
            "Epoch 9958/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1065 - val_accuracy: 0.0057\n",
            "Epoch 9959/10000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0157 - accuracy: 6.3492e-04 - val_loss: 0.1064 - val_accuracy: 0.0057\n",
            "Epoch 9960/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1064 - val_accuracy: 0.0057\n",
            "Epoch 9961/10000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1063 - val_accuracy: 0.0057\n",
            "Epoch 9962/10000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1063 - val_accuracy: 0.0057\n",
            "Epoch 9963/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1062 - val_accuracy: 0.0057\n",
            "Epoch 9964/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1062 - val_accuracy: 0.0057\n",
            "Epoch 9965/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1061 - val_accuracy: 0.0057\n",
            "Epoch 9966/10000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1061 - val_accuracy: 0.0057\n",
            "Epoch 9967/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1060 - val_accuracy: 0.0057\n",
            "Epoch 9968/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1060 - val_accuracy: 0.0057\n",
            "Epoch 9969/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1060 - val_accuracy: 0.0057\n",
            "Epoch 9970/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0156 - accuracy: 6.3492e-04 - val_loss: 0.1059 - val_accuracy: 0.0057\n",
            "Epoch 9971/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1058 - val_accuracy: 0.0057\n",
            "Epoch 9972/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1058 - val_accuracy: 0.0057\n",
            "Epoch 9973/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1057 - val_accuracy: 0.0057\n",
            "Epoch 9974/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1057 - val_accuracy: 0.0057\n",
            "Epoch 9975/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1057 - val_accuracy: 0.0057\n",
            "Epoch 9976/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1056 - val_accuracy: 0.0057\n",
            "Epoch 9977/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1056 - val_accuracy: 0.0057\n",
            "Epoch 9978/10000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1055 - val_accuracy: 0.0057\n",
            "Epoch 9979/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1055 - val_accuracy: 0.0057\n",
            "Epoch 9980/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1054 - val_accuracy: 0.0057\n",
            "Epoch 9981/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1054 - val_accuracy: 0.0057\n",
            "Epoch 9982/10000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0155 - accuracy: 6.3492e-04 - val_loss: 0.1053 - val_accuracy: 0.0057\n",
            "Epoch 9983/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1053 - val_accuracy: 0.0057\n",
            "Epoch 9984/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1052 - val_accuracy: 0.0057\n",
            "Epoch 9985/10000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1052 - val_accuracy: 0.0057\n",
            "Epoch 9986/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1051 - val_accuracy: 0.0057\n",
            "Epoch 9987/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1051 - val_accuracy: 0.0057\n",
            "Epoch 9988/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1051 - val_accuracy: 0.0057\n",
            "Epoch 9989/10000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1050 - val_accuracy: 0.0057\n",
            "Epoch 9990/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1049 - val_accuracy: 0.0057\n",
            "Epoch 9991/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1049 - val_accuracy: 0.0057\n",
            "Epoch 9992/10000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1049 - val_accuracy: 0.0057\n",
            "Epoch 9993/10000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1048 - val_accuracy: 0.0057\n",
            "Epoch 9994/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0154 - accuracy: 6.3492e-04 - val_loss: 0.1048 - val_accuracy: 0.0057\n",
            "Epoch 9995/10000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0153 - accuracy: 6.3492e-04 - val_loss: 0.1047 - val_accuracy: 0.0057\n",
            "Epoch 9996/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0153 - accuracy: 6.3492e-04 - val_loss: 0.1047 - val_accuracy: 0.0057\n",
            "Epoch 9997/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0153 - accuracy: 6.3492e-04 - val_loss: 0.1046 - val_accuracy: 0.0057\n",
            "Epoch 9998/10000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0153 - accuracy: 6.3492e-04 - val_loss: 0.1046 - val_accuracy: 0.0057\n",
            "Epoch 9999/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0153 - accuracy: 6.3492e-04 - val_loss: 0.1045 - val_accuracy: 0.0057\n",
            "Epoch 10000/10000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0153 - accuracy: 6.3492e-04 - val_loss: 0.1045 - val_accuracy: 0.0057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6pl3hzYYLDc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2hGrIki1Szc"
      },
      "source": [
        "## Build the Convolution Neural Network\n",
        "\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRO0K9Q82w4m"
      },
      "source": [
        "In this part we will build a Convolution Neural Network(CNN). CNNs are usually used for visual images and categorizations, however it could be used in the regression cases like this. In order to use the CNN, we need to change the shape of our input and output values, and then redo the train-test split. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKwugvwk1-CR"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XYRLTJwI1eD_",
        "outputId": "b63034cb-21d2-4b28-d749-e3741b6cb6c6"
      },
      "source": [
        "stock = df.iloc[:1760,:]\n",
        "window = 10\n",
        "\n",
        "data = stock.to_numpy() \n",
        "result = []\n",
        "    \n",
        "for index in range(len(data) - window): # maxmimum date = lastest date - sequence length\n",
        "    result.append(data[index: index + window]) # index : index + n days\n",
        "    \n",
        "result = np.array(result).reshape(4*window, -1)\n",
        "\n",
        "x = result.T\n",
        "y = data[window:,3]\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1750, 40)\n",
            "(1750,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thzadpTF2YHE"
      },
      "source": [
        "Here we can see that our feature data is at shape (1750, 40), which is a two dimensional. It represents 1750 observations and 40 variables. To make regression predictions in CNN, we need to use the Conv 1d model in Keras. Thus we need to make the input one dimentional. To do that, we can add a dimention and treat the whole data as a single input row. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "snRxioQK4M3E",
        "outputId": "47725e4f-bc44-43b0-fc3c-c1701d5187a5"
      },
      "source": [
        "x = x.reshape(x.shape[0], x.shape[1], 1)\n",
        "print(x.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1750, 40, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw_jlaQk4bpN"
      },
      "source": [
        "Then, we can test-train split the data again, using the 90% cut-off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mFX2Nctu4htL",
        "outputId": "3194b0f1-47b4-456b-cec7-cae0e8526292"
      },
      "source": [
        "x_train_cnn, x_test_cnn, y_train_cnn, y_test_cnn=train_test_split(x, y, test_size=0.1) \n",
        "print(x_train_cnn.shape)\n",
        "print(x_test_cnn.shape)\n",
        "print(y_train_cnn.shape)\n",
        "print(y_test_cnn.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1575, 40, 1)\n",
            "(175, 40, 1)\n",
            "(1575,)\n",
            "(175,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5dMS_6-5aox"
      },
      "source": [
        "Now with the new data shape, we can create the 1-d convolution model and fit the train data. \n",
        "\n",
        "- First we add a Conv1D layer, the input shape is (40, 1) because we have reshaped the data to be a single input row. It uses ReLU as activation function. \n",
        "- Then we use a flatten layer to flatten the data for further calculation\n",
        "- Then we add a dense layer with ReLU.\n",
        "- Finally we compile the model and calculate the loss with ADAM optimizer. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lrJBEs3v5pDo",
        "outputId": "29899088-3a32-4f0a-dce4-fb9c53fef784"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(32, 2, activation=\"relu\", input_shape=(40, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, 39, 32)            96        \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1248)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                79936     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 80,097\n",
            "Trainable params: 80,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foDNq7dH8mRL"
      },
      "source": [
        "After creating the model, we can fit and predict it with our trainning data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0WVwhCp46Ae8",
        "outputId": "675ecfe6-cfd4-4ef3-a23f-d89c35ea2f25"
      },
      "source": [
        "hist = model.fit(x_train_cnn, y_train_cnn, batch_size=12,epochs=200, validation_data=(x_test_cnn, y_test_cnn))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "132/132 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 2/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0031\n",
            "Epoch 3/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 4/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 5/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 6/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 7/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 8/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 9/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 10/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 11/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0030\n",
            "Epoch 12/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0037\n",
            "Epoch 13/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 14/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 15/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 16/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 17/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
            "Epoch 18/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 19/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0035\n",
            "Epoch 20/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 21/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0031\n",
            "Epoch 22/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 23/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0035\n",
            "Epoch 24/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 25/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 26/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 27/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0033\n",
            "Epoch 28/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0031\n",
            "Epoch 29/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 30/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 31/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 32/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 33/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 34/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 35/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 36/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 37/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 38/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 39/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 40/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 41/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 42/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
            "Epoch 43/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 44/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 45/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 46/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 47/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 48/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0034\n",
            "Epoch 49/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 50/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0037\n",
            "Epoch 51/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 52/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 53/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 54/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 55/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 56/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 57/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 58/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0031\n",
            "Epoch 59/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0033\n",
            "Epoch 60/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "Epoch 61/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0029\n",
            "Epoch 62/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 63/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 64/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0032\n",
            "Epoch 65/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 66/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 67/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 68/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 69/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 70/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0033\n",
            "Epoch 71/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 72/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0031\n",
            "Epoch 73/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 74/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 75/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 76/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 77/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 78/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 79/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 80/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0034\n",
            "Epoch 81/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 82/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 83/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0031\n",
            "Epoch 84/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 85/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 86/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 87/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 88/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 89/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0033\n",
            "Epoch 90/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 91/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 92/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 93/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 94/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 95/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "Epoch 96/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 97/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 98/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 99/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 100/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0034\n",
            "Epoch 101/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 102/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 103/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 104/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 105/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 106/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 107/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 108/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 109/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 110/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0034\n",
            "Epoch 111/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 112/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 113/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 114/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 115/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 116/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0031\n",
            "Epoch 117/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 118/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 119/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 120/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 121/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "Epoch 122/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0033\n",
            "Epoch 123/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 124/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0027\n",
            "Epoch 125/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0032\n",
            "Epoch 126/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "Epoch 127/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 128/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 129/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 130/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 131/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 132/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 133/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 134/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 135/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 136/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 137/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 138/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0037\n",
            "Epoch 139/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 140/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 141/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 142/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0027\n",
            "Epoch 143/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 144/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "Epoch 145/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 146/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 147/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 148/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 149/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 150/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0033\n",
            "Epoch 151/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 152/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 153/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 154/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 155/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "Epoch 156/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 157/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 158/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 159/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 160/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0032\n",
            "Epoch 161/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 162/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 163/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 164/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 165/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 166/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 167/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0032\n",
            "Epoch 168/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 169/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 170/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0037\n",
            "Epoch 171/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0027\n",
            "Epoch 172/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 173/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 174/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0031\n",
            "Epoch 175/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 176/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 177/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0033\n",
            "Epoch 178/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0027\n",
            "Epoch 179/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0033\n",
            "Epoch 180/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0028\n",
            "Epoch 181/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 182/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 183/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0036\n",
            "Epoch 184/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 185/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 186/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 187/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0030\n",
            "Epoch 188/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 189/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0038\n",
            "Epoch 190/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 191/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0031\n",
            "Epoch 192/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 193/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 194/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 195/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0027\n",
            "Epoch 196/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0029\n",
            "Epoch 197/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 198/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0035\n",
            "Epoch 199/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0028\n",
            "Epoch 200/200\n",
            "132/132 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4BoDcXA6vxa"
      },
      "source": [
        "y_pred_cnn = model.predict(x_test_cnn)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "tLoSx_pQ7BP8",
        "outputId": "1aac5a32-aee2-4e9f-e60f-51045dea9e8a"
      },
      "source": [
        "print(model.evaluate(x_train_cnn, y_train_cnn))\n",
        " \n",
        "print(\"MSE: %.4f\" % mean_squared_error(y_test_cnn, y_pred_cnn))\n",
        "\n",
        "x_ax = range(len(y_pred_cnn))\n",
        "plt.scatter(x_ax, y_test_cnn, s=5, color=\"blue\", label=\"original\")\n",
        "plt.plot(x_ax, y_pred_cnn, lw=0.8, color=\"red\", label=\"predicted\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 0s 1ms/step - loss: 0.0019\n",
            "0.0019289364572614431\n",
            "MSE: 0.0031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eZgkVZU2/t5Ycquqrq2zoaFpgUaSfW9AFseRQUdGsQGXQYf58GN0XFDHUX8ug/xElGHGHZeBGVBAR9wFRtDBBRcEsRGanWzobtaG7srqrurKJbZ77/fHjYiMiIwtM6Oqu4t8n4eHrszIiJuRN8499z3vOYdwzjHAAAMMMMDig7SzBzDAAAMMMMD8YGDgBxhggAEWKQYGfoABBhhgkWJg4AcYYIABFikGBn6AAQYYYJFC2dkDsJEHsBrA8wDoTh7LAAMMMMDuAhnAcgBrAejBN3cVA78awO939iAGGGCAAXZTnArgjuCLu4qBfx4Atm9vgLHudfmTk8OYnq5nPqj5wmC884fdaazAYLzzjd1pvL2MVZIIxseHANuGBrGrGHgKAIzxngy889ndCYPxzh92p7ECg/HON3an8fYx1lBqexBkHWCAAQZYpBgY+AEGGGCARYpdhaIZ4EWCVquBen0GlFrzcv6tWyUwxubl3POB+RqvLCsYHh5DsTiU+bkH2H2QaOArlcrnAJwDYF8Ah1er1YdCjpEBXAHgrwFwAJdXq9Wrsx3qALs7Wq0G5ua2Y2ysDFXNgRCS+TUURYJl7T4Gfj7GyzmHaRqYmZkCgIGRfxEjDUVzI4CXA3gq5pi3AjgAwEsBvAzAJyuVyr59j26ARYV6fQZjY2Xkcvl5Me4DCBBCkMvlMTZWRr0+s7OHM8BORKKBr1ard1Sr1WcSDnszgP+qVqusWq1OQSwKb8xigAMsHlBqQVVzO3sYLxqoam7eqLABdg9kFWRdCb+H/zSAfTI69wCLCAPPfeEwuNe7JqTnnkXu57cuyLV2qSDr5ORwz58tl0cyHMn848U43q1bJSjK/Au3FuIaSXjXu96Ot771PJxyysvxmc98Cn/zN6/FUUcdE3qsokj485/vgWWZOOGEl4UewzlgWYCqdr735z/fg6985Yu49tr/7nhPkqTM59qLce5migefB/50B3DemzveynqsWRn4pwG8BKIeAtDp0afC9HS9J6F/uTyCqam5rj+3s/BiHS9jbN4DoPMVZLUsC4qS/nHhnINSDsti+MhHLrLP0TkuZ7z33LMWrVYLxx57Qsi5gA0bCBoNgqEhjlWrOLzOOaXMXgA6z88Yy3SuvVjnbpZQazuQ39FEPTCuXsYqSSTWMc7KwP8AwNsrlcqPAUwCWANRG2GAAXZpnHLKcXjb296O3//+t9B1Df/4j+/BK15xmu+9u+76A0444WV4y1vOw1e+8kVs2PA4DMPA0Ucfh/e+9wOQZRmbNm3EZZddglarhVWrVsEwDPcaF174Dpx77nk4+eRTUa/XccUVn8djjz0CQiQcffTReN3rzsZNN/0YjDHcc8+fcNppr8J5552Pu+66A9df/w1omgHLUnH22R/E/vsfAcvi+OY3v45f/eo2jIwswdFHH7uzbt8APYBYJmAayQdmgDQyySsAnA1gTwC/rFQq09Vq9dBKpXIrgIur1eo9AL4F4AQAj9sf+1S1Wt00X4MeYIAsIUkSrr32O3j66SfxzndegCOPPBrj4xMAgHw+j6uvvh4AcPnll+Koo47BRz/6CTDGcMklF+GWW27GmWeehUsvvRhvfOPf4jWveS0eeuhBvPvdF4Re64orPo9isYhrr70BkiShXp/F8PAoXv/6s9FqtXDhhf8EAHjuuWdx7bXX4Atf+ApKpWH87ncb8bnPvQ9f/OItuPvu3+EPf/gdvvnN7yCfz+NjH/vQwtyoAbKBRUFMc0EulWjgq9Xq+wC8L+T1Mzz/pgDele3QBngxYPgDF0J56MHMzkeIzVcfdjjqX/xqqs+89rWvBwCsXLkvDjywgocffhCnnPIXAIDXvOa17nF33PE7PProw/judwXXrWkali3bA41GHZs2bcCrXy0eicMOOxz7739A6LXuvPP3uPrqb0OSRJxgbGw8lFq5++678Nxzz+I973mH+5okWRgfr+FnP7sHr3zl6SiVSu74r7vumlTfdYCdD25a0OdMcA7Mdxx8lwqy7urI/fxWGH99RvKBA6RGWiOcFllz8MViyfMXx2WXfQ57773Cd0yjkX21Qs45TjjhZfjEJz4FACBTW8EnJgFZzvxaAywcGAO+8G8ERz/B8dk1RfzkJy1I86gJ2Plyg90IQ/966c4ewgDzgFtuuRkA8MwzT+Pxx6s49NDDQ487+eSX49vfvg6UisJ9MzMz2Lz5OQwNDWP//Q/AL37xcwDAI488hI0bnwg9x0knnYobbrgenHP7HNsBAENDQ76F4vjjT8Tdd9+FjRs3AADI3BwetXc6xxyzGr/+9S/RarVAKcWtt97c7y0YYIFQqxE8tYFB5QbWrpVRq82vCz/w4LsAaTV39hAGmAdQSvG2t70Fmqbhwx/+uMu/B/H+938QX//6FTj//HNBCIGq5vC+930Qe+21Ny666BJcdtkl+Pa3r8X++x+Agw46JPQc733vP+OKKz6P8857M2RZxjHHHIv3v/9DePnL/xIf//iHcf75b3GDrBdffCkuv/xS6LoOq9nA4Ucdg4OPPAonn3wqHnroAZx//rlukHVqamo+b9EAGaFc5njpfgZyG02sXk1RLs9vKWPieBI7GfsC2LSryyQnjqhg2wPVvs+zK0q34pDVeF944SnsuedLMhhRNLqlaE455TjcdtvvXD57oZF2vPKGJ0D32hsoFrs6f9b3/MU2dxkTXne5zDPjy/PXXwv5ez9A46e3+M7Zp0xyPwBPdrzf10hfZCCt1s4ewgAvVnAu/htgwcAYcNZZRRx11BDWrCkiq6KfhFrIEXPeA6zAwMB3BaK1Bg/ZIsMdd9yz07z3rsF3nyqZiwG1GsHatTIsi2TKlxPLBKyFkUkODHxacA4YBjJbxgeIBOeAaQ7WUj84yOCGLCjKZY7VqykUhWfLl1sUMHYRHfwANigVD5hl7RZStfngDhcCSWn5L1pwALtRb9HFAEKAn/yklf1zZFnCi18ADDz4ABgDtm4lnd6jk3lm7frlV+eLO1wIWBbQaIj732iQ3eF2LxAWJwcf+bztIpAkYNmybJ0MYpmCDVgADAy8B4wBZ6/JhxpGYteOILtBfe354g4XAooCDA2JB2poiKOL+l6LGxyLzsDvzo5IX7AskAXyXAYG3oNajeCyP74q3DAau48HP2/c4QKAEGDVKo5DDmEDesYHvlsFWYtXfS3xmN3ZEekL1Bp48DsD5TLHAflnQg2jw5nVXmC7vCPlcIfr1jVw442t3c5IEiLqnu9K47766ivxq1/dlnjcjTf+EN/7Xmdd9m7wmc98Ej/60ff8L+5mHnzhhuR7sDs7Iv2AmAvHwQ82wB4QAiwf3oF1v6mjvMxvYJgmVtxXn5bD3sfPfw2JfuFwhwP0D0op/uEf3pnq2DVr3jB/A9mNDHyacrjzFsTc1WFZAxXNToNhYNmoBpCC7+WZKQtlAKDU3U4ODOjCYb5UQX/845246qqvgjGGsbFxfPjDH8fWrVvw5S9/DpXKwVi/voq3v/1d+M1vfoWDDjoY55zzZtTrdfzrv16CTZs2olxehqVLyxgfn8CFF/4TrrnmKrfs7623/g9+8YufY2RkCTZu3ICRkWF8+tP/jsnJpdiw4Ql8/vOXQ9M0GIaOM888C29601uiB8r5bqWiSVsO90XpiNCBiqZ3aFpfng4xDRBd63h9Ylh4JHnZ2j22k5yDbNmys0eRCeYrGLd9+zZ8+tMX4+KLP43rrvsuTj/91bjkEtF9adOmjTjzzLNw7bXfwckn+3vXfPOb/4WRkSX4znd+hEsvvRwPPLAu8hqPPvoI3vOe9+Pb3/4+9t13f/zwh4J6Wb58Ob70pa/j+uu/g//8z+tw880/wZNPJrRQ2MU8+JEL/zH8DUdOnAamCdjF23ZFyI89iuJXv5zpOYlptlV584xFZ+CHL/oo5Mce7f0EhgFoesfLzop7y007dgteW3pyE4Y/8ZGdPYxMMF/BuIcffgirVh2I/fbbHwBwxhln4okn1qPZbGLFin1w2GFHhH7uvvvuwRlnvA4AsGTJKE499S8ir3HEEUdijz32BAAceuhh2Lz5WQCilvzll1+Kt771TXjXuy5ArTaFJ55YHz3YXa1UAedQ7r0n/D3GUicEFv/rSuR+dkuGA8sWUm0K8jNddx+Nh9PwYwF+z0Vn4ImuhXrgqUApCGMgRoiBtznFyVFrlzfuAEAMA8Tc9RU/abAzgnH+OvC9I5fLuf+WJNktNXzVVV/DxMQkrrvuO7juuhtw8MGH+tr8hYFkpaLpwgBHwrJAonhkSlN75UTXdu0qrYYB0IzVS9QCz+cXRJG36Ax86ORqNkHmdiR/1n7AiN5p4HcnmSQAe+u7m4w1BNJTT7r/7lkV1GwCMQXiDj30cGzYsB5P2df62c9+ipe+tNJRm4bYNdsdHH30sfj5z4XXOTc3h9///ncpB9RGvT6HZcv2gKIo2LjxCdx/fzTNAyBTD754zVXI3dJnDXldj5ZtUgqSlnahC9e+rheQeXiOiGmCF4sLIpVcdEFWzhi21xiGPe2w8rfcDGm6htY7L4z9rBv40Dp3AM57u0OiE2CPcyG5TU2Dcv86WCecmMnpgl5dL8E4Uq8DkiQephCMj4/joos+hUsu+RdQSjE2No6LL74UW7f6YxfSC8/7/j7//LfjsssuwVvecg4mJ5fioIMOxvBwdGf7MPyf/3MBLr30Ytxyy03YZ5+VOOqoo5M/lJGBJ3NzkIa6G2/HOQw9en4xll6zT+mC8dE9wTTTJyXV60CaeUAt8GIJxDIx33vRRWXgGQP+8FuCT9+Ug+GVMloWSIjR7oDtpYdSPM5qu4t48Imqkm4mZgaQn3oSxWuuxFxGBj6TSCpnYJQAMb0vTzzxJJx44km+11as2AfXXPOt9guU4V/+5ZPun8ViEZ/85GeQz+fRaNTx7nf/A8488ywAwAUXtAOPZ5zxOperD/594IEH4Vvf+n5oPXjvtTxfJjvO1jCEB94HiB5t4AlLT9GA0VSSyp0FYhqpn/nRt70VO77xLfCRJfEHWhS8UFgQqeSiMvC1GsHMNuE9eKWMhNJUE9otRxByrOvdWzs/4u+oStaulbF6NQ3X5Fs0e+4wDqaZrYyvz3NxDsxMA5rJUZ8jvWfFct5hrObmduCDH3wfGGMwDB2nn/7XWL36hL7GmzwOZOfBG4Y713uGrkfTMIylnnuEsl07VmQYqSka0mikMtrENIGBB989ymWOqXEL6gz1B+MoBUnDdznHhHn7xq5D0YSpSoL0BbEWloMn1ErPu6Y5H2Pop+28ZQGmwUHA7aJlHKraw4k47whujo9P4Bvf+HZP4+odGXrwpgHo/Rl4ouvC+w4Dpel3YLs4RUMsCyStU2cY6XYu1FowDn5RBVkJAU483sR/XRkIxlEKhChjOj4f58E7Hs8uoNktlzlOOM6IV5UstL445fVSt4jsM6ioKEBeZSDg/RUtc8bRp3Htu8Y9R9e0VdS9JroeqhTrBoKDjwqyMkHTpAGl/e8m5hNGeoqGGHoqB9AJsi5EstOi8uABwf+NLbFgeh0/RsOVMUHEcfCmKXizXYCDJwT4tXQ6Hl93ayQHn7VHnQiLRnt0NmRZgWkayOXyKU7Yn1ElBBgbZWAAynv3kf3qjIGxnvsAZFPjvvv7YZoGZDnkETfN/nlvXY9ecLqRYXK2a3vwZnqKBjFxCR8sKjz4BaCmFpUHDyBUokUoTbUdilXR2AZ+V6BoAEDaVouvU21a8RMzY+OfRrUzPDyGmZkpGIae7MlnIQvkHBLps7SBQ8/0MZbMatynHAPnHIahY2ZmCsPDYx3vE10HyYCiiXIgugqyUrqgYoCuYaYv7UvS7podFc0C7FwWoQfPOgN0lKVU0Rjgshzu7ZsmeLG0SwRZASQvWJYVuYWWnn0GQ/96Kea+9p+Jlyl94mOYesdHwFeMxRtK00zcMRSLQwCA2dkaaNziwwHJbIJtebprr1mSJDDbeyQ7poVMUu7jN7OsnsfiQIQSCAyDIJ/nqNXai453vHGQjAY4N8BfSDcGWVYwMjLu3nMfTDMVZRmLJA4+baITpeALVDq3FwgVTcr5o+vYtpVidGV86EgEWYsLsnNZdAYelHVOrpRBVmKa4CMjoRQNMQ2xrdpFvI2k5BBiRcskSasF0kzOHmQMuOuHW/GRq7chf/zy2AqawoNPNlTF4lC40fHCNFE+8nBM//khsL1XJp7Ti3J5BFNTcwCAkYsuBh8ZQf2LX0312TDpqfzE45j4mzMwvfYBsL1f0tVYvNhjj3BZq3e8cZh47WtB990fsz+8qecxOMjEg48LKDIm2lumCZJTltiAOn/jj6Cf8TrAkxW8YEiZ6MQY0Nhm4Kwz81iSVG3WDbLOv4FffBRN2PaQpQuywjCEhjWkFg0MEygUd53s0KQFyzT79rBqNYLZbQwK1ZJrwJhWdg0p7LFlEQhMpZ5CTEEzezeXKoYTg35bv3FFyUwvTgy973MRXYueQ87raXh4RqNLHtjIf/t6bFu/beeU4kmZT1KrEShUB6cs+VmxKHhhYYKsi9DAd0bwCU0XZCWmAT48HB5ktZzI9/wb+Nz/3NSRHh9E4uSgNHq3QZMDooBQ6ywdszAka8k1YKwMM2ed82Qh5Utp4KMKmrk8aZ8Gvm/kcqkXq0SYZt8LFtd0EMbAQ/IVXFlpKj6axnrwjAEPrWN47enyTmnrR2J08NILzyP3i58DEM9KDkb6arO53EAm2QtImHeaMsgKwwQfGg6XSRoLR9Hkb/0fSM88E39QgtcTF/BJGwQjBDjxOB0/+raWWAOGWMkcfFo4C3TfQSjDSG0Uy2WOE4/TUZEf9z+guiOd7bGAXUbgai6zuSdkkr3fW8aA//iisLRnrSl0Gl2HqkthjUlCLZpajaC5g0Gmxs5p62eZkRy8vHEDcr/4XwBiziqg+MENc6nqJXFVHXjwPSEsyYLSdNt9S3Dwod6aZcskF8KFYMnjTTR+cQka3SgXGMV4UUumFrL04J2xZeLBp/NUCQFu/PSf8cdX/4vvAXV+B8cg5m77GdQ7ui8ulv/ufyP381u7/pxvgFkmOvWxeNZqBM8/KYzTvWvRaXSdeZDWg48ZS7nMMTqSchc5DyCGEfmsMItCm9HFz2LbjIm01WZVddcpVVCpVA4EcB2ASQDTAP6+Wq0+HjhmGYBvAtgHgArgdgDvq1arC0ta85AgK2MgYbx6AMQwwEaWhAdZbQ5+ISgaYqUICpumWGwiIjnESuDgUy5UhNLYiowuLCsV7ZMKtge4kB48AEhaC0XW8OdQOGOwVVjyY4+BT07CPOXlXQ1F2roFrFcDnTH5THSjL4qmXOY4YB8NeAo44Tij0+g6KibOklPxeXypAkKAgw8w8IMPb8fwaTuhD0NEkJUx4NOfUHDiYxRf2VLEjd+0KdWUTg5Xdi0P/koAX6tWqwcC+BqAq0KO+TiAR6vV6hEAjgBwLICzMxllNwgxXiRlJivMGA9+IVU0KWrnhFJRXpgxHnWY0ihyLCy8dENwPDGyzK7hcvALF2QFAKK1QBp+dRHRDXBJcg0i0Vo97VSIpvVOYTEGyBlutk0DZt3oed0gBHjbuUL58/0b6p1GtysPPllFA8YwMaTvlD4MxDRDn/lajeCJKkeeCwHCthfsY9JKKnPqgsgkE2eN7ZkfA+AG+6UbABxTqVTKgUM5gJFKpSIByAPIAXguw7GmA2WdDxKlqWRhxDDAh6NkkrYOfiFUNEkUDUsRxKLRCRrcojA1mu4BZzSVgYeVXeasy8H3G4SS5K703kRrgTQb/hdNoaxyf49mC3MzrGvjSHS9d+eA0sidWrdgDHj6WRUP3mP1FbR07ofEO39zbhs5nsLYkTQS5pTFAvuFeucdkJ943P+iGS4HLZc5Dj7QRJEI6mjpiHhG0pZo4Kq6IHXw08yafQA8V61WKQDY/99sv+7FpQAOBPA8gBcA/G+1Wv1DhmNNBcLCdfDpPHhD6ODD6BzTBC8WFibrjtJ4fi6Fh0QiZJKMARd9XMWD9/J0DzhNa+DN7OITzvfqk6LhitJdYpqmdeQHEF0XuzpNA2PArT828W+X9aDoiJMVJoExsVhlgFqNYLaVg4r+gpauUQ58J8aA/+9Doqrb/zkvn25+JTxThFp9S2bTQL3zDsiPPuy/thEuHiAEuOhjLZy6WtS9kkx7fGl/YzW32yU6vRHAAwBOAzAC4GeVSuUN1Wr1h2lPMDnZexOCcnlE/INwjAzlMOL8DQB5GTCN9jFRyEnA8jLwsNV5rAxgcgwoKBhOOk834w2DTJAvSEDUMbbBLU+UgCURx+RlgNKO62zZAjz+GCCBYu1aBcAIysG9mBeSuF7ivSsoAOHJx6VBXTToGM3H3IMYuGNQJIB3MSYVgN7yH5+XgLFRLMlLaGEE9S2aXY46xb3zQuJASfXPy+B4o9CQgLwKULPv+7t0KbB+mKBRB046ieCQQ4a7pj7K5RFAYkCxiKUTQ8Bke0xbtgDVR8QJH7iPIPEeKQTgnfPUD47RgtzTXHDHmwYFBRjK+a8jcYBFjG9JHpBNDC8bAbaKRW1sOJc8TkWCOjEC1Osd8yGT58d7qRTHPANg70qlIlerVVqpVGQAe9mve/FeAP+3Wq0yALOVSuUmAH8JILWBn56ug/VQB9ybDThumGjNNqB5sgOH6y0UWhpqCRmDxe1z4OMTyM81MBs4dmSuAcok8NkGWikyD9OONwyjLR1abRZ61DGNBsoAaltmwPXwp3NotoGCRTEdOAchwCEVA8qjFKtXWyCkhamp6LGO6QZUTUvMtixur6NgmNje570BAGnrLCYB7JjeEX0PIuC9t2N2I42ZlOcobN2Oobm6754VpnegUByCVpsBIXNYMdHAI9utVPfOi5GZOVghcydNJiuZ24ElDCAWS/1d4rD//gyWBfzgB3Oo1br7rDPe4Zk68sUitm2ZBWftDFNCgEMONoCHgGOO1EHIXOw9WtLSIbW02O81bphoTs10PRe8402D0lwTdHvdd53RehMyCLaFnCO3rY5So4WZqTkoW7ZjHMDstjkYCdcbsxhaGoW0ve6bD92M1YEkkVjHOJGiqVarWwGsA3Cu/dK5AO6rVqvBn20TgL8GgEqlkgPwVwAe6mq0WYCFcfAsZblgu1RBaLExy84+WwgOnsWqHFyeLy6oaZqhhdEIAT75iSYOrpjp+pumpGiybBFIHBVGFrxrF2Q50Vqij6sXug6tMAroBggBTl1dxwc/kJwX0AFd6z0I7a1kmZGiRlF6LrUPQOQF8GKpM6mQAJd/WqiuvnF1M/EahNLEqorEshYkKYiEiQ9ME1G1pgmj7Xid3i1Foy5IJ6u0kZt3AnhvpVJZD+GpvxMAKpXKrZVK5Tj7mH8CcGqlUnkQYkFYD+C/Mh5vMmhIJyMnsSeJEDQN8KGh8MnkqGgWogSvlcA5plEpxBhciVOopK3XlauPxWS9plPRcNMCM7sPPoZfM4NSBb0MRNNEkNX+LGPAt67muPWOcdzwDSqo8FYTw0XatXEkWspSsmGgFCASoCr9q7iyat5t6JHPgxN4TRVwZCxZDstSFgvsF5bVqcAzTfCoGjiUuuNqxyTSLeJcWZggayoOvlqtPgagoydZtVo9w/PvDQBOz25ovSF0FaYUKJbEKhvRgBkQARUeUavczWRdABWNaDEYM+kdnTijkTrj2NKlgXtU+sK/oflPHwY9+JDO81hWooFnDPjBd4BXPsdw7pqEQktpQKl4qPpJBDFNYRC7qLlNWi1RJEvTgGIRtRrBlmdNKHwJpp41UKsRTLRa6ZtZeM+taz19DoCojipLIpvVMNBbayoblmUvFP05KkQ3bFVZyHnSqLy8xyYZuiSHJyuElBqHaYiAaMTxrufu/D9pAWZMbHNyu5YHv/uAdzYbIJSCl0rJk8Q0oivWmRZQLKZv39UPkjJv03jwlj1Zw7y1gIaeWFTQE2FIIZOs1Qi2bqaQQbNJJ6d2MaY+Hmpi6JGLdeRnNE2Ui7ZpmnKZY7/lGupkBPvu2RIJPVqPapg+ZZJckgA1l0kv1W7vS/h5NKAUYeCdHVia4nNpdtZJDk9WCCvhYVHwqDLRtE3RuP0ikhZxywIU2fbg599ZXITlgmnnTbYNfNIkIYYBrqrhRtE0wAsLlOiUUP2yzcHHGXh7axnWiYgFPBXLit4Cp+Dgy2WOffY0ID3PMkknJ4z237NStxfrRiN1b1eitcAnJkGaDfDJSRACvPH1TTTIMIZbU2gQgLSavSU6pe32E/ZZLn5DnkPf6e3E9UiTy0XHnsfZ0YYZ5zQxIuc8lCbW2ScpSndkgcTkweDx3lhZDGXlg2UBiirm5i6ig9+9EPYj2QYjsWCUaUZuf50+iguS6ERZfGJWSh08z4e3GOyYyIwCrYgHPoWBJwR4/Ws1LJuwug8+Rl2zWOwr0YkYOng+b9M0KR8kTQObnPRp4Ympo7TncLtfr6b1VpIhrkFGEpxEJzWXQQllAzyfAyTSVzyJ6LodZO004u5raRIFUhh4LFCQFZRF/0ZRO2FNE43Z7fuRqOm3THBFsT34AUXTNcITnZgw8IkFvEzBc4ZZKNtgLkgtmoQCTO4WOM5gUAvI56M50qAH3wo34iRlkFWyTEjoPvgYCup48H0YM10HcnlBR6Q0DkRrgdkevPuabmeyOsG0VlPcky5BdK2nzwGwDbwsFqx+DZ1hALm8+K8flZKugxcLERRNNxy8HUCOA41XlWWG4M7WgSyFL1aUCntjWfE7Gi8sS6hycuqgJ2tPYLRjFSaUitU1icfzcvBhK3YGwalUYAmlFVwPPnoyEdMCz+fDe8gGOXgazcFzVUmZyRqiXuoV7oLcjwdvCIqqC6+XtDSbovHsZkxRgM4xrKTZay2aPlQ0Ds2WQXq7iE2oYm7040FyLqiGfoOslImM4xiQhJgUY8DWrQTyQw+i9G+fSW/flpEAACAASURBVL5m5Fgi5rAcoV7y1kwyRNA5sVyHRV0PfhBk7QWUhvRkdbb8CR68YYKrKriiYOvmkFotirIwFI1lZcDBCwMfFQTzef8euVcH8oV0Bj5THby9IPfFwQuKhufTN8oI9+D1dhtHzoEei431U6qAMBFk5Vk0iTBM4b2rat+BSy7L/QdZHVVJHKgVudvwduK67N1TkJ5+OvmaEYji4EXJi5DnnrfzNYhhK/RSUDTCg8/tMrVodi8w3rmKMgpeGkrlwTMlh4eeKOGU4zrrjXBZWRgdPE3oQJVmC2w5LQYjOFLvRLQsYbhCEDm5g+c0zd5lgEHYFE1fHryuCYpK7cIoahrY5ISfgzfs+kS2lyaauvfgwRt9cPC2TDILFY3w4HPguXyiw+N4xpGyeVkON+JpHJAuEfU8eDtx1dbPwtxW7/0itHP3DwBQlPCkQWch0zUgTjbqhRNk7SY21AcWn4EPW4Vdg5HkwRuYnsthaq4Iheqdkj9FWTAOPta4peDghWwrH7219Bh+QmkkBw8gXWJMljsbJ2+hX4qmBw+ej0/4s1ntapLQdfF+1K4o6dy63vvcsROdeC6DJhG2uojn4w18ZI9aL6RwD550Q9EQIhavmGPj4ijlMsfq1RSKwnHkymkUzD4MfCQHL0c8R/b31DTR7rNUTF7ELcsTZB0Y+K4R2o6OUjRRSqYaTBOTy1UUx/IYllt+yR/ngCIvDEXDEkorpMpkpSIoHDbhggkd1IrWwacEMS3BK2YBRoWmOIMga1fBRMZFQDWUotFBWi3woaHuyyI7yVP9lirIQkVjGkJIkJBIFtWj1ocow+y8lraulBJTG50xIJ+P9OAJAX7ykxbWrWvg7W+cAmn048GH90mIrEpqJ+Q5ncPS9GwmliV+y1xuwMH3hMA2izHg/nuB63+4BJdfEh/kJnaW4PEvV3Dbzds6JH9cXqAgK+LrsKTi4E1TUBRRHnxaDj4tnAzJDOAExbMIsvJcd7QGL5VEINWBaYIPDwsPstkEHx7p3lBblrBEfcokeT6bRCfk8+K+xCwWXs84MrdBksLvRRqVlwexvxEV9GrcWCUJWLaMQ5qd6cvAd8qH7fiAooR/F2YnUOqaJ7M3hYpGVXetUgW7FRjzaXNrNYLGDoYGL+GZJ0zUagTLlkV4FpYpVtZCAZNDGqjXaXF+6AWgaBKDaWlUNJYFVgiXsRFGAxw8jeTgU8MyhQefMqkoFpQJCV4/AUVDGDLkcl0FE3lpqNODtzM/iaaBDw13baiJbn+uj0Qnbnvw/Sc6CSEByeVidzaOZ1yrEZTL3P+T2r8xl+UIw2ePN23BfCWGj7YsQX2kmAvSzAxIPUMO3smLiVDREHvxgWZ78FGZvb7PCIoGOXVBkiYXpwfvucnlMsfYsAVNKuKg/VrxWZaWSLrg+UJ4UpS8MBQNV3OwmjEt1dJ4SJaoq5NOJmmBpOm7GgNi2br7LJp+ZOHB24aZ57qTAwoP3svBt5PfSKspitF1a6g18fD33PHK0cFnsa03HA8+n+hBOp5xx3ptGMIox3HwuVzq+xTb3ciJn6Wg2cjsTH96eUb9uQpmW1UXtRN2PXinZ3PS4m+agGxz8AuQvLW4PHjORbEobwCRAIcebGLPv1QxtLSOiPLp8H6AFwKcn21peZQeNkMwBmx8JodGg+LCqMJdaVQ0jAvDFOblM/s+Od42pfEGnpDYBt8AhKflPNRJmYlJYBQoFPpKdHIzNnO5rs7TYeA5d783abXAh4e7NtQkbRp7FHyZrP2qaAQHn+TBx59DBy8UxO8cWqqAid1cmu/LeWx3I0cySxqN0Pe9kGZmwJYsSb5mFCy/1Nct66DIkY6SSx8ZOnhxWbJ9sKigMnO55F60GWBxefDu1rAz0Wm4XAQxU07ooPbbLhAERZ53iqZWI2g0JHAgMrjlTrakBygy+h/g8ONq0QDC2CYZA8sSAc0MpHGEUhEI7Cdxys1kzaXqx+su4gGKpj0oIlQ0wyM9ePAaUBrqQyYpmm7zLBo12wuf4OB7XCw0XRioOB28qqTezXE15ns5ssI0Sq5mE8bwOHhYy80U6ODgDVMk+kXF3hgTtIymix1jKXl351I0srwg8bzFZeApFQkEYTr4YjG812oI3Mi4A9O0V/L0k7ZXlMscpSEOAkQHt9KoaGBH/0MzDduGHYCokBnGwTsPVSGCsvKAWJbwmLPQPkfsAhJ12d7xOHrvfD4draEJ3XyHB++FraLpnoO3+dleH2jKRKKTkkN92uyrnDtxShXk8z3vkJw6P1yWIlVaXFHTBVmd2FYkRcOEc5UAxoCNGwn+8MAY/v5s2ttjGqhFQyz7uY9wlAilgEvROKUK0lE02dT0SMaiM/BcUTuNMGVdlZ/lhYLIPLRBTFuRsQAUDSHAqlXAwYew6MJdaVUKEUEwElwgCMI9eMZEUao0HKhlRssyuwWlQoIXGEqiLtsL3XATnVLxt60meKEY7cGjTdF0u7MgutYXB084A5dkfPnKYXz20ymbpUedy5fo1KMHr+uikB2JkElyFk0PhiGmsiJhMeV6PajVCJoNgjk+jCfua/ZWsjqog3eUWBGJTmBM0Ee6LvIlSqXkcuK2imahsLgMPGMiOh026QpdeCxB3a1hpxcvkIoGJKGlWtpyrAkUjWOMebEYzsE7nnQhRbkCyoS3k8UOx6HaPEily/bAqQefloogmgZeLER78LIEMjcHPtQ9By+CrNHb98SdCaVo6RKqmwqQmdlfzX0n0Smn9qxSIrqXognJlKZUGLEuKBoSxUdblvB4E1Ae1ZEbVtAgIzjx0JneSlYHxQdOu76YWjSCotHEPUkRZyGW2Z7bGbVfjMOiMvCEOR58SLJCvpCOi3WPbRt44tRWX6haNAno8MCjEPEABikeHhXkstUbgqJJWBy5nU6fQcEx4lzXs8Kl0mV7z6HrIpM3Zf0WorVEvf9iMXQx4/kCpNkZ24PvQSZZKoXOy1Q7E8ZQHJax8gAFBUnvq+Z+O9EpOnko8RzeIGsoBcgEr572Pqkxi43jZCQYQ2l2BgesXoK/eXMeV1w23RMDQgIZ3jBt2bQSwZc7AWC32FiaevA0ssfrfGBxqWhsDj7MyIh05/QUjW+bbhgi0CNJ8x8YSdMzk6Z4gBydcsTWEkDyd6Gi8l0aDh6IKT7VLUI4+Fhddhg8QVYpgnLxoaWJnYokhd//XB5kZgZ05cruOXhDePBkZnvHe1NT6NiZdORpUAoiy/jwRYB5VwPv+2QfNfd1HbCDrNLcjh7PYe8CZNktuOUfLxPPS9pEJ1WN3hnTdBSNNDsDPjaGQnkYRqOOnmZhoBKtsxhGUTRupzhda9eDT3IAqSWe3QXCovLghTxLCd9C53PxQVbvQ53P+44VHry6MIERh/eOM/SUCm457gHiXGwtw3TKzkOTtJ1kXVA0QCTn3zUigqyRuuwQuC378vlUiU6uB++Fp9IhL+QhzWzvLWEpRge/bBkSdyZONUmSUzGcM/qahm7Pgy4TwHzn0DVxbyU5/FlzUvhTJzpFe/CE0naQNcbxITPbwUfHhIw1haQyFMESHobd1zeJotE1oZkvFBLpO+IEWRcIi8yDtxMsQiZWYvU8z0TqSHQyzOjGu1nDMW6SFB2QYVQsOP3IJPP5dtPuKIthWekpGiAy8aVrMAouF8S/e82MNQzhqaaswEg0TdAOwXM4/QFsD74nHbyugQ+Fp7Gn2pk4OQiZlAv2JDr1o6Ip5KMpGs5sOjOlB5+L4eAdus6RiEb0TJZmZ8DGxkWtoPpc2q8SuBaD1mDulCOWvRhGJjox8NIQpO3bxN+KkrJUgW12F8BhXFQePGG2fjrMi0yShRme7umFfKeKZqG2VZSKTLeYIlmEUvF+GplkVCq5mkLSSIX+OhVFQ4hdmyQbHbxI7Om9pKpbYiCfLtGJaC3BoXpfc9r+AaL64uyMncnarYrGCbKGb98TdyZUGHieVcs+VU19X0Kh21LLiLZ/Io8hfZBVFBuLoDbs4lxJCxKZmbE9+JGe6tEwBjy5geFnPyXtWIi9wPOoRCdGxcLtPBtpMt0d2nOBsKgMPBgTRiFk0gUTXoLKBa8R5/mCn87x9mqd71XXoU/iJrQba0gwppIU7m0yW+UQfC+wBXYlaoWC4KiTkBUH75SM6MPLdD34XF6kkSfB4eABsZMzTXvnZs+JQgHSzAx4qftaNND6k0m61STz/deiEfclby8WvS6eNkUTlclKI+ZXFNTo7kZCOKEkUkrE5uBZjxRNrUagNxkIp24sRHjw0YlOTi0aZ3fL5Qh62PuZIEUzz0qaxWXgKQUUNYKDb3vwocoFs02H8Hze57E6BZoWAg7vHVvH3PaQIjlOh8ePKHNKHI7U8TY4h0lU8OAD5JFJpguySum6+CTBuW4flITrwacsVeDl4B0tvNeDRy4njEhPKhpdZLL2WaogLd0UOxbDaMcmevbgdaCQB4/i4BmzKzAmzAU7xiG+VzxFk1S/XpqZARsdA4aGeio4Vi5zDBcpFELbsRDDk+AYRXWWSu0ckjQOjpd2Vec/r2bRGXgepaLJ510PPkxT7SQzAehMzTcXmIOX5Pg65knFnExTbHvjUsnt+8Qshic2yrj7gWH83TkBh6wbmSRgc/BZ6ODFzqGfdHqfDj5VkLXNwbtaeF13f3eetz34HurBE6fSYK8BaKeaZCYcvAHk1PQlHELgLp6RtWjs5zDJwDsJbXFUnGWJYxLq+pMZ24MfGumJgycEWLHcxKteqbsJhs6uXnjmEUHWYrE9rjTCBWq1VUExweWssLgMvO05hEm3eK7tlYdqqj0cvKBoPB6r1/jPd3KCzXvHefDtWi0Rk8npGhMlk6TMLQxW28Kwo6GiyYt49F7Dn0DTTaITkBlFQ9IscknwUDTpShW0OXhh4Bti5+b87vk8SLMhatGk4JZ9FKCmpasVHgHnfsRWXUx7LtuDT31fQs9h72wifm/CYhpye+F+L78HT2o1qL/7jX2MUMbxmKYfAEB2zIKNjokFuEcVDaEUeZW2WVgzwYPnzKZoxLORSiZsWq4OPjbBKyMsKgNPHM8hgaLxdoFpr9a2FBI2X+8xaMTJZF2I7+Cs8HHGjdLojF04NTTUSJmk4ODFfSqPmyiOSNBIESccUffJ9LwcfLpEp2x18DzXu0HzUjTpShW0OXhB0TTdxt0A2v9PUYsmSAFC0zsCuF3Bq6LJoFywI5PsubSuUwYiKqhOqeCu0xh4WbY5+PbvrN51B/I33wjAS1kmUzR8TMgkpV5rwgcyWeHYBCVqJyyKjXkpmsTdnY+iyaAFYwIWn0wyioOXZV8LMUe54MKrosnl/NHwGHlW5nCMW5xiIkkHbwcpIUvRjQpyqqgDzygOOlTCyqUqXvHhGTCy3HOdlCoat5xyljr45G15LJxgYupSBV4OvgQ0miCq0t7V5fJisSuGNzL3IkgBavvpkPKF3nd/9v3gKevqxIG4O5s+6C8nyKrrkCKKjUHNhSdBec/jUHGK4ktGU6qPtUvpOqUKkhqUzM6Aj44CutG7TJIxn+0gdoIjR4xayHEGZKkLisbvwc8nJ7CoPPiuU6Q98HLwwaJixDSy6zeaBDeoFPMAxu1U4Oh37UYFkSqHnJ3YIXS5+fEiJL3VeZyUgqJhdsW/jGSSjmqk22YdHefowuv16eCdIKtpigqZgAgqFoqpVFRBCrAkaUJ62yuc75KPLsqVFk49+L6CrIYIskb+3vZzmOjNOuqgXM4nk5Qfr7Z3btTrwceoaOp18OGRviiaju/jlCiRI8qE2xw8qc8JZySNTNL0sAFqBjGVBCwuA+/Is3rxIr03PlBUjBsm5vTcQtQGspVAipgwcdl9cdX6HCmWFDMxnQXCshUaxUJnwTFnLEkUjed6WXHw3Elu6TEQ6Gagpq25orWEd45AkDXnUDQF9/00l/ZRgLomPh8B9Q+/h3L/fdHnY6KaJE/R8COxcJmT6JS2eUiIg0B0ox1kDW0oQ+1SBSmCrEQSTpmHi1bWr28bSkaTKUug3ZglopZQKkj+oDFxZLJRHDyzEwYbzXa12URaqp3oxFVlwMF3A5Iieh81+X0BNQ/nxhjw9S8Bl33W5lMxvzp4sW11gqxRFA2L9eBdni8qm9BbztVJvCgUgYCBd+MBgfLJYdfjqiq2qRm17OtbB+8gn7bYmEdFMzQE0qjbu7q2dJaXSqkv60teMoy23DIE6m9vh/zIw9EncxK/EnYjqQqXOfRdyvsydsZpHa+5C1aEikY4ICmyOh0K0Nu+jlJIm58FMZ1eBU6iU7xs2JVk9pGnwuWAB28adoPsiCKDjiNil2BOw8ETs03RiE5WA5lkergqmvC3Nmwg0ZPfq6LxUDS1GsHmJy20WN7mVTG/ShrKPAqSmAp7MRw8sSw7QSMmOJQX/VoJtR+gQqGzJnxKmSSxxO6HR3l03cKrg+8zqJjWUyWtNgfPlu0BaevWdsYmAJbLw1QKPf30RBfNRKIgv/B8/BgdKiPh/qYqqUyI0J6n3Nkojzzc6RE7PH5I9zRnvGla9rlB/Fzbg5eefgr0Jfu2qSjK3PkZRSmVrvgC9Fe/JvG7JCJgoN26PREUDbHnKbFMm6JJQVFaARWNaXTVyKZbpDLwlUrlwEqlclelUllv//+lEce9qVKpPFipVB6y/79HtsNNgL3l890p+99OQ4Coye/11rwUTbnMsWqlDiqpglfNZ+Slxn2HJO+V0fhYgx2YipJJEg8H7x5bKIIEuzo5wc4w4++7HnWbMGcSZHWUE31otV3ENJPwwuvB0733gfzs00IOqObAGHD5F0bw8MZhexfXHYgWT9FILzwfv5A5C14CuiqpnPK+wDAgP7nJ9xLR7CAriciUdmpCJSW9OXNdUV2PXXm8CuuQwwJBVjuzO2QOKn+6G+pvfo3mhz7afrFXSxl0iEyRMxCVMOhKmtWciNWkqb9DLTeexxUV0y9Y7q7rFa/I3rSk9eCvBPC1arV6IICvAbgqeEClUjkOwCcBnF6tVg8DcAqA2YzGmQ6OQfLCzup0WuFFTn5vQTHPlowQ4ILzmvjU5aLDUmQBr6zgTOh8tGqAJJUqcDJvYxKd3AXC5tl5McyDZ20dfIIH7/aZzJCDT91uLw5R5X+D8HDwbJ99ID33rOup1moEDz1RQhPF9i6uGzhyywj6QNryQnzZAC5a9ol/x1RUDJH/RiLNfWEMhDHIGzf4X3cop5hiY1xNTttvJ/W1d2ry+vWghxzqOljCy1ciKZrSlz6L+me/5JcxR6jHEiH5dyTEMMEVP0Uz9KmL21Qms6kzu3NYZGavB6KJiAzGgFtuK+KC82TcdZfYdd15J3pv5BL1lZIOqFQqywAcA+AG+6UbABxTqVTKgUM/AOBz1Wr1BQCoVquz1Wq1x2hHj2C8s3a0s40iwKqXEqy7ZzZ08ruNEICOhrgSNbFkUgUhdgGveTTwrnQsrqWak+gUSdHYQc+oxr7MXiAYtXl2KZyD9+ng4zl4t15+Jjp4W5XTqywwxHAlbYG9HjxbtgekLVvcpKBymWO/g1S0SMn2kLsbDtE9dW5CkOTBu8XXgESOuZuSyomwf0t5wxMAgOJXvgQcdxyUhx8URi2KkqA0faKTLZN0VDPy41VYhx7efsac3Us+PMhKWi2wPff0vdZrwTEerAbpyKPl9o5e/dMf2x2/HEekUIhf8ADIDz8k5qUtkKjVCJ7dkoPExHllmeOkk9BzI5copJmq+wB4rlqtUgCoVqu0Uqlstl+f8hx3CIBNlUrldwCGAfwYwGeq1WrqEU9ODqceeBDl8giwJA8MFQBFEn8Dwmjlc+Lv4RIOPUAFhoY6T1CQgYkRDDuf855DJcDSJUB5BCjmUR4vAqMjPY/VHW8YlhTEd5hcAjQaGAk7rqAAo0NAXsFQ2PsjeWBJCcWJEWC70v5ODmQCLBlCYSgHjBaBoSIKy8aBzZv91xvJA8NFoFBAnlnRY56zxzxSRGkkL+5TP8hJKC5dIu5BXur6fOXxIlAQvzljwOMbJRx11DBOOgm4/fa2rfTBMrB0n2VtrlwC1BwBSkswsmwEX75qCMZlJfzhFgXkOCn6XoSBAOXl44BMOj+naZC2b8ewSjp/JwdFFRgbEvdB6fLaQXg/HzYeL1otoFDA8PNPi7Hdcxfw9a9Duf12TB68P/D8k0AhZA6qEjA+ArRa4fPTwWwJKOWRXzYGyECxPAI8uQHFk1cDn2dibCUVGC0BS0eBWi3keWBYunwC8AbAJ8awNA933qS+XzkF4Lx9vAKUyqOATIG8LL6LZWDpWEGcWyYo7zkGDJWgjA6juHwcILzzepwDbzkH+POfAYWgWB7F2CHDuG9FHsXnDJx6MsH3vw/ssQdASJ/PTgBZJjrJAI4AcDqAHICfA3gawPVpTzA9XQdj3a9g5fIIpqbmoE7PIadTqJRjZspOdqjXMcqA2ak5jEoqdjw7BT7RSXTlt82B6BSa/bkxi7nnKM02YLYsmFNzGGXAjhe2gxu9x6ed8YZBqe1AwWQwdQZpegdaIceV5pogFoC5Fhoh76tTs8hZHGbdgDLbQDNwzGhLB6WAsa0OOjKLksmgG4BSm/Ed69zPUqEAY66B2Ygxy1tmUGIA1S1Y2+ZgRByXFsMNDa1ZDarOgMYO9zcJQ+6X/wuuqDBf8UoA9r19toZRScHs1By2biXQ64AF4M47OR59tNHZMQnAWFPDzKwOEOFJj5aGYT75LOiqA6BPzUHRLBSLCmq1Od/ciP0eH/0g6pd/3j0+7HPleg28VEJzpt7xOzko7miBDRnQI86RBtLTT4GtfAnGTOp+PulcpD6HsVUvBXv4UcxumcX4U89AOf54TO13MLDDgDqnI1fXOubgSFOHpTOQuWbkdwIAeWoHSiZFs26iNNfE3NQcxnfUsd2QMNbSMDM1h/xMA0SzwHUGaVvn8zDW0jAzowGNtuc8ouTRfHoLaGEs9lkLYsxiAG/bjuEdTWgNE6RhQN0hvst4o4nZF7aDyUMY0wzMbGtiTFZhUoLGdANjhtVxT5UH78f4889j2/qnUJprorlDB63NYc0bGE5dNYviG+fs2Hf6sTqQJBLrGKexUs8A2LtSqcgAYP9/L/t1L54G8MNqtapXq9U5ADcBOL6r0fYLZzvn2Yu7XYmA+Pou3kzWmPd4VMAlK1BRWCouNZs4QayEIGtk0Ie268ETatetCeXg29vjRIrG1cFn1JPVlcbFUzTyxg2Qn37K/3mjrV9PjL34PtjmNdjeKyBv2uDKG+mqA6C95e87P1KrRZ4u/8PvCy84ghtiDNj20GbQfVbGq2i8FE2PGHvdqzvHkcTjWBbYxCTI3BzkjRtAVx3gfz+yJ6uQSZIkZ83h4J1SBS27HpCqus+YW4cnH6Hk8tR2ccCHeyg4xliHAtqlbT0UDdG0Nn3kllEoiOeRkNDfOveL/wVdvhekbdN+Hfzy5ZioPzuvFcgTZ021Wt0KYB2Ac+2XzgVwX7VanQoc+h0Ar6pUKqRSqagATgNwf5aDTYQjJ/PCmURAfLKEt6BYyHtu/QhFyUYpEgF3QYpJdHKDpFHjcOrXR3GknLkcvDDiClAsAa1mx1i4LEWrCDzXc4OsGergRbZlgtLDoh1qEGIYbgYqIcCq/Vm6wKN3CCv2gbxhQ3thHx6B+fJXdBw3+pZzIs9BdK0zQGnD0ay/e81m/GnLfvGadKeapPOFUsQ5CtdcBfXXv3QvJj+/GfITj7e7CQHJQVaLilhIqQT1t7+GeVzAX4usRZNOJunl4GGakLZNgy1d6l94bFlhrA4+8KPy4eHuSwaHKZUMozPRSdfbyjQmkqu4XfohCrnbfwV9zTkg27eBWNTVwVtHHwN13b3djbNLpHUL3gngvZVKZT2A99p/o1Kp3GqrZwDguwC2AngEYkF4GMA12Q43Hk7vSh+cZAokefCeph7B97z14KP6M2YFu01ecEL7tLIJKhpimWIXENWAwM5kJZbllmPlhYIouOU7jiFN/0hCrfjyxN3C8YzSdDCyrE4pqKYBAVliYuAxYOzYin0gb9wQ++ACAJmL8RQtC8rj1dC3HM36Hmwz7p/dF9qO6IWMeJ2UiGBjEMXrr4X83LPiD3tnpv7pj12VvXZ2d3T/VSj84Lswj13tPyBCB0+Yk0iXbOCdMsjENCFN18AmJsV7zu/hXezDpLohPyrvpSa89x47sBP4RIaq7cHrGqa30PZ0IQTIFyIT2cj0tDj9qgMgTU/7Muatgw+NT3DLAKk4+Gq1+hiAE0JeP8Pzbwbgn+3/dg7CtrLOJAL8Hny9jsIPvgvtbf8g/o714D3Gf75lkj7v1d+gZO1aGatXU/ziMKGikSIpGruUQVQ5V+8C4ZRjjdTBJ+uvYUu/eFY6eGrLAlO0lSPUArf801ioXzy/pSS167lEnshvKOiKfSDN7UgsMheZH8A5CKWQ13sMvOcajmZ9xR83g+7zEhTlhxFpkjxjd6i7uKxa+fH1op6LvSMjWgs8n4fypz8K/bqDpPtiU290/1XI//gHsI440v8V45pup2jZ5+5WnVIFtWnUi0t9ay2hFphcAlNz0GaNzha9IbsQni9EOgbKA+vAxifA9lnZ8V25LPtYGuL05FVEohNjgD6r401n51A8vojfcud6eZcSDCJ3+y9hvPKvwCYmoax/zKZobFuSEzWBSH1OlKGeByyyTFa7ZK1nBvg4eFV1vT1puobhiz8GYjfMjeXgTdOTnBBRYz2z7+BN8hGTtKM6YYPZ5YIjHiCvLj2qFo232JisRGSyWm0DH+P+uj04s+zJ6nrwCRSNaXZ+x2BpgIRKhGFgK/YBAL9BDBtrgNZyYVlgo2OQq1VYVqdE09GsX3jOZpz3ieXxNUk8+R08H5PhbCN/809g/NWrXNkrabVgHn0s1LV3t4unAcn3xaZHrFUHwDr8iE6pZxQF6HjwSYu9w6+rovHFly/agX//5l7+ZDJboh+hBQAAIABJREFUivjPH1uCG79Ho0sweKGqkU5Y7rafI/ebX3e87rUTLpwig7bcuDYF5JgGUOrLh+CFQqRzKG/cAOuQw8AnJ0G2TYssc8+u2DzyKCj3r0v4Qr1jcRl4x4P3Pk3erZcsu3wtoRZAKQrft+X9lunnJ72wvB78/AZZCbV5b0/3nmCGYjFnJejgbcoksuk2BXJ2yz8nsapYFMk+wbEEt61hcIKsGdeDT1XxkHZSNMT0L9Y8132rO7r3CvGPfIwHz5i/d68Xpglr1QF47pfrcd8jRWG0OHxerSQBxW2bwVaujE/o4h4vO5cQ8AaQu+1ngvP1ePBsr73EvPDel4Qa64KikWGtPgGtC/6x84BACW4XdqZ1qkQnWQJUFVbTwo6N27CVlV1nRhzDsKOp4L5HSlC5EV2CwQslZpdtmZA2Pxc+lsBcJ6bVzmRlFOUxAzIYCrLpPo8AxDyNMPAOvcsmJiFt22Yvmu3rWEcfC+W++ePhF5eBD1uFqd+Dd42zRWH85WlC6cC5yFqL4ictTyf0FIlOfdWWsHlvb62QjgzFJBWNKRYrHllN0g6CWVY7kzWqFk1aiiYuqNstvLuYBA+ehARZYbSbtwBIbNgcmgFdLIItLUfPCcC+f+FzgVALplxEqwW0UMDatTJMHrIAzsyATS6N/Z6EMnehjS0jDUB6chPY0jLYsj1AmvaC3RR1dswjj/Z78EkNJywRgGd7Lof+hjd3vh9Vi8YphZHYk5Xb9eBVqDBwxPKt2CYtFcbT+fmohSVjEg48XEGB6J1KqDAOXoluFENMC9Lzm0PGzDrngFNszFbRSIZ4Pv77ujmR1e5cLx/twTvPhjDw03a3tfbctI45Fup9fw7/bAZYVAbeKavqg5eD9/ZWNE3wiUnQgw+Beucddt2J6FXYLRCkRPRntJGqol8cfBLB9oPsy1BM8JDcbaASI1u0JZROJisvFMPLBQcnfdj1bE9PNPzIRkXjlMdN9OBDjCzXDTTNdnlnnk+oKx9Bz9EVK6I9eM7FtaPquZgm1JKCqYkDYZA8Vq+mUPMRC2BSSQZvbCkfX5tfmq6B7bUCtFCEtl0TnHVLlGGwjjza9z3Z6Cikme3R1/UUxgLE3N6ypb1B5iT8+4gga3I1SeKk+udyIJaJN522BV/+7yFhPO2LENsB+fo3gFe/IkQJFcbBKyrmtlvhDpZptoPPXnjthDM+p3a+49TZu7WJJZZvDLxQiC4m5ywS4+O2isZ/T+l+qyKVVllgURn4sCArYZ6V2eN9OwqB5vv+GcMXfRTyk5vaSpkgOiiaaAOfqqJfHJzyADH0BLGsZB28G2SNGKvjfTlKmXyILNMrO+UcW7eEPk+2FlntqKfdK4iHovFqn0tf+HdXleDCMoUX7xnypZ8guPr69gLLcxEKDOd6gQC7swMzXnk62PhE5wckYnf/scT8CvvO9q5v9d+vwsmvVNp1jLy/Wb0ODA2JxTpNNUkgsYSyQwm8/6Pj+On3TUEN2ZUyrWOPEy0HndPutSKcrnDOZT8jzhDOOquIFSvQdlyiyuM6O8SUHLxTJVOermH0gEm/AXdKjRTyKHAtUebKGHDF14v47GVSuINlmaEefCgH75bdFs+RS40Fnn+2x55gk0tDx+Mq8BypsRVo/ylJ0E9/dTY73xAsPgMfCLJ6uTVfXWdHIXDASzH32S8id8fvo2WS3sBIVH9GG16+fM1hVZQnugvIElcmKRQ/oVRPQi0auOV7o6vbcefhdDyKkCQNh4MX6f4qjj2qEPHQ2OfIjIO3q/QF6DDl/nVim+sdoyP1tDE1BWyqWtB4vr3AJnQDgkci692BnX7XZ0DHJjuPd76n472HePFOX1x2YAW50bxbx8irMpK3vgAsX55c2dFLMxYSvotpommqWPvwCAq8ibVrZezYIhKI9ONPwqb3Xu7+zGyvvcLpCgdObAVexwXt+xqb6JSy4YfHqJJt0+CTgftty3jT1q+v1QjWb8pDYhbWrpUxFcjWIaYF6bnnOj2VMJmk3UREUDS008Dbdka74B0wT/2L8AF5e7ASAkvvZBmaH784HRXaAxaXgXe89WCQ1aVoZLcsqZAS2nrU447H9l/+TpQpdWB7aeIAT/aZEl8ljxDgpis3ofaXZ+F7TxwPpfpod9/BHi9Tc3joXhpO9dhB0qgtMLEsV0UTOVanEJnT1CNmLFNTwEwjB0Kt8FLLltlWG2TIwUMNcKmW2WkI7e/gYNky4JADNFh2eedymQuKxnk4TVMk/HjH7/HgU+3AnM5Vzs4hzDjbxtE64iiwFSv9n3OuOzcHjI0l16wPBFljOxaZBoqjORx4VB5DpInVqynGci2wQglnnV3CkSdMuvOJ7rUinK7wfgc7INh2XNDmwWXZLQmcv+nHguoE3Hrw6YKsHgNfr4MP2Wn3jpPGbBlvVP36gEtfLnOsXCUjLxlYvZpi2bLgdzIBSQKZ2xE7Fh8CFE03KjqH5rEs4NENeWx4xMSas0rzWnHci0Vn4DsTnTzcmkc+5d1+AgA94KWBkqMe79EbGJGSdfCFX98G5ZjDoJ31BmzfYnYXbLV579pcAcYOI9zQ2KUGIh8g00PRhI2VtL0v4mSyRo5FxrJlQGGJgqJshKf724aAS1Jv7RJDrsudFHaPfJCYZieXTi1fIJkQ4CMfqOPCD6DN1+bz7sMpVx9D6fP/5j+Hh4NPU1Odu/fO6ToU7sFzVQE9sILGRZ8UL8qSf1F2dNZOqn4EvGqmROWLrfy45gaCv1gtgoFEa6FOix0LF9trL0iboz14QgXNxBgwNUXw4x+38Oyz7fvKpfb3kTduECWW4eRZpNPB82CMhxAwJn52zng7yStsl8NYh4EnBPjQxzje/55WRNVYE/Ql+wov3gtKffbAB3vn33YSutiVWyaYrOJ1ryviqUYZS1HrjbrtEYvKwPsy/pwgjVcH76VonD6iUfDy9YF+rYmJToYBWt4Dt95WwPlvVboLtjKRlr50LxXjQ1qooUmqB+/WZ1ciVA5AuxuPI5MMHYvNfxLg0KNk3PnbmfB0f2fHIEU0gOgSrg4+qIYIC2oaJlpz/oAaMQ0MT6juOL2JL0RrdXjLgicVv2+qmuqySOhiuhgLN0O+s9W5cPLADsdNpEmqzW73NACQnMlqp9eToRLytCmKWDWbGCoXOxYua/kKWE8+B84BecPjKF75Vf+5KAWXFJeyOvvsIsplj0317hC9+QgsLQfP2s+rnXDlUGQPPJLDG16vgJuWS7sSQ/eXtLYT7IIgqoLhnBH+21km2Ev2hfS838D7YnUBOCoaV2UW5ODjVHOGhQ1P57BunYxpTKKEJo46KqEmUoZYVAa+3drM03XJp4P3NNMORLOD8KllPEHWNIlOxDIxp6l4dmseEjW7WrGdRYrIkq+GilSbAtm61f1OsbVobB28kEmGHMO5rSiitkwy3MAT3+5HwdJRM/ShcXX3cjbFxtztsupfTIlh+Aw+Y8Dvbwdu+iF8i6jbas35uoU2RUN0vSN4zXUDGm2rbhJrqksymEnx7neI+XPB38udC7g3+9lBsMOWEa3c8sFpvILkJuJugSxVdT1NomlAseBbuDgHzvrHlXj89zWsWVOEdPefYN77iN9IWRaapuLz/H2ctiexjZsW6tvs3arDwSfNBU/wWNqxA3xszKXIDKhYdw8XSX32c6r97d+h8J9Xto2pM+8CEM2sI+SrpgX6kn0hB3cuYRy8A8WmMzUNnBDfbxhUzQW/3to/ULzp70ZRKnFsI5PgsoKf/jR9TaR+sbgMvKOi8XKdXqmfJwHCkfZFrr5eisbJkHVfT/BMDBPDEyqWLldQkCJojbjv4Fl4HEMz/ImPonDTj+zxxHvwIsgqx7cQs+kbYcSjErw8vKSqRmdbZh1ktXcOVM7BbBjt3ybAwddqBLPbKCRO/Yto0HDmCy5FA13zGUjGgA+9j+BH/1NKv9OSJWybYnj0QTGwh9exzrhEgAIE0MnBe6W5sR58Wx3G8wm9VM3OhD3SaoIXS76Fq1YjuPueHAgY/vQnGTf/6xO49Sb/QglqoTQi+zx/H6dt7wIZA276PsPllwrlCixbxttlkJVNTroUmUVUnHCMhqJquvRU423vwPNf/BFOO7KFNWuK4IYZrnxT1OhdtmmCrnyJSydFjcV/Poei0UVJATeFlXfEbLyXrdUI6jMWNJZDs0mw5h9GMTKu9FsYtCssLgPv0DFeQ0Pblfi44vXgKbisRmvWnVU7iDQUjWUCORVr3gT859fmuqpiGDbRpKefQv6nN7W5P1tFE62Dp56gZ5RMUkqmaLxjUaNVDA4lxD1Bt75AGRgkvOHcJXj4Ptb+bUzLx8mXyxzlcRM5YvkWUeHFth987sn+JJru+x61GsETj1C/6iYBXJYxOc5w1KHinMccrnUu4F5az0FwATTM2GbcLrz5HQkUTXD3AsDXrcqBY0ibGMLLDp9FeesjkLl/t+lotiMpK/v71GoE0y9YIMxO4Td5uv6knuKAPKeKhC+bIlv9MgnfuW5OUKz2DrM2V8Dl2gfwLvpVrF0rY9uWiF24ovjmiQ+WCbrvvp3qIWe3SkhH7MClaHQNfHjY9/wHYzZKrv35cplj6RIdXFZw/PEUSw+aiOb55wmLysATO8jKPVtHn77Vu7JbFhq6EqmY8FE0Hu/Kx+NHjcMU/V1JLoexUgQXGPVZj6qFmAZIrYbSf3wF+uvWuMkwbQ4+wpja9ECyTJL5dwzBTFTWpmjitr2+ptsZ6Xlr0xL+eE8eMtrKHWKZvoxPQoCXHavhjFdpfuNjmD4PXlA0Ngcf8ODLZY7DD9JhETX9TkuWIXGKL3++AQC48iv1kLhEZ9COB4weiUmu84J4FtqkIGsYNcSbTWzXS/44hW1ID3vNcvzkKxtwtPowcsT03wP7d42irERxOYZymWPvZYarXFEURGe5Br+X1N4hcruSpCQBakmGRE0fPVUuc+DQg7A32YzVqymWjprgstKxA4/NZDVMsJX7dqiHXDvhfQackzrPvKaJSpXe3zAQs/Eu4oQARx6s47d3mYIWm5yMpYXnA4vKwLsep+ypauidRN7AqWViaFSJVkxEJTTJMYbOgWmIUgEBFUjq72B7NY0Pfwyjbz4Lyt1/hP7a17cnLWUJHLzpUibRMklvJqtnAfQ8GL4HUIlRerilCjKiaGB7RsczEHhkeWanTJJQCwXFn1no668LCIrGMeqa5vPgCQE+8//P4a1vIx0eaiR9Z1MtTj/NsJgMscxOfliW/LRFWg4+UE0y3oP3714YA355k4G//b+THbtUSQLU/faCuv5RLN1Lxl/9RUB5Eiehtb8PKAUhwGv+qoUPvrfRzkKVUyS9eRcuRfUnC7mlNNo7TEKAz36Z45wzm8JgmhbuvrfQuQNXY2hU08QWsgfItm3+1+38E5dG85attCXFRNeFjDPw/PsWwIDKjlgmli5XhOpoYmJg4PsCZW0O3htkdSaRN8iVtP30UjHeN1LUWyGmLauM8SRiv4M9XuN1azDzv7dj9vs3AgVPOnsCB9/WwceM1ZFQenh2HuTZacx73utROxEsq6bbaHtGBx/C3N+GGCEySSc70AtD95UY8OngWxpoU/cZbckyUBxTO4x7JH3nJjpFyyRDKZogB586yOrZhSYEWWFa7XPKEmovUNSndMzRUigFxfbeG7nbfwl62BEoSP4gOvEkOvk+4yx8nudMskwM59uf51KKxd4bH8upYN4kJ1s6GowRkXwORVnsirdvtbB1Jte5A4+gaBgDHnuI4vhTxrFxI/H/pk4tGue39Y7NLqtMtJbIBI5x8IJKKe+Oik1MDiiavuBV0Tj0hY+iUQI8dsz2M0ItE9xmh8LZeqtKquw7H4IcvKKAL11qbzvTcfBu0DMpyOp0dHIloAEv3RegTuPBZ6SDtyFJ7SRbAOGJTtTqeOCCheN4QXjwjAHf/A+KZzeYfqNtmB21aOISnoI6+NBMVmq50ksXHRy8x8DH8Xi8LZNMCrJ6PXheLGHZSBN7jTdgyMVQCoou3xu5X/9SlAMO6rsDlQ8B/8J37luH/MlejlElREhmE4uNMd/ukXs8eJcSDDwPoqyDuM7kEhNLJpSOHXgURVOrEehzFlo0hxcao9j2VLsCP7HpSO6RwJpc9e/edN2maCy/h+9FsOObnQ0LCAM/8OD7gedHcnkw6kmm8FE04d6Jiyi1TAqKxqkfz9VcMp0T/CzrLHoEwE708HLw8TJJ7sokwxOd3G5P3m24qvgfcm8NlOB7XlAn0cnm9ecJItHJ7Hwt+B2D3HY+D6JpqNUItj5jIA/dH0wMUjpISHiSJfEQO9cNuy9m5/zy7SAR4OBDgnsuaCDImsjB220Gi6KA3ElH1fHTX/HQYL+1fG/Im5+DedgRnV5vSPLP1BTaC9+9OZi6PQctyy/JDSZ1hYCwtg6eqTnU4Gn2IYs2fr6eBID/ObBMnPpK0rkDV9XQOFm5zDEyZIHIEtSxEpaWPLX8HTpSFhLYt75Jwdp1/tIcxObgRfa0x/nxIiYRko+Pg5X3iL0nWWNRGXhCKUAk23toq2jatWjUDoomElFqmTQqGlOoaJIyFEMRkVnKFaWdoEPbDTvC4CZmxXrwUkcma5CG8dWDV6NrqvtVO9l58B2I8uAD1xTp4UEVjY5ymWP/vVrII1B21jDE7+U9R1zCE7GNl9NbIIyi8dYgcRCmonEMfMxcIcGOTlE16AG/TLJYAmk1QbQWlq4sdBh3xoDzL1oFADjvCyd0xjdCnKBly+AufEcfB+Qk25EyDP/n02Q1O2U5GHDL4xW87JxV7QJxzlz0qOAA+Mo6ELuBdXAHzhWlvdv1fh8CrFrFse7+Jo49UYJkeeazs1OQhAT2wXsZDKh+R8DLwUfp5uMWNlnG7I9ujr8nGWNRGfg2RRPUwXcGWd2uRxGIKgucVkXDFdWeaH1SNA5yOY8u304kiepa7zQviZJJOkEwSv0LXShF4ynzEEfRZNl0Owqm1WlMLdq54Jp+Fc3/a+9NwyS5qjPh98aSa23dXVkttbaWWlIYoaUt1BISm4SRbcCIFpaNsTHG2CwaIw9ePjzwGT6MARub8eexDWbx2IMNxphN9gDPmBkDBiyEGqRGEkKhBbXQ3pXVXVVZlRmZGRF3fty4ETdu3FgyK2t1vs+jR12ZkRE3Im6cOPc97zkHlQrTvxPg565rYc9EN2a0VdJCICPhSaZoFC981he3gA4+kElmNiURYyGlbA9ePBfWZ7fDdPCVamLbZpPgS0dPxQM4gH85ug9eR0XRSJp64cX3j5/pRbJYtx9fAQwQZG02CV6+8EE0vd2RQQ2CrER+HkrCPOwrAtlAQMWmO1Zzc5TVHuopDLyuY8+Mh0MHnbiyihAgkEnyZkGq51QuKLfZ2FkGni+bxCBrjIOPDB7J0n8DGSqaFNpDBDcwpdJgdSuAYEmavC2xglRi4pUCoUetaekvgTCYFB2P8Z6SgRfr4KcpgniQtYA0bi0g/V6iQQVx3cT9COt4B2C8deD19Rxo/W7caBcNdnKEL8fAey3qwcv1+UWKJmhbp4Q4hyuVnCBrL8q6rtZYn13PV65WGw2KZ1wOXK5/B5ddTqMORRyqZC0ILz6hsqpMn6X2a5XPS9PUdBinBCWKJvYc9F11F7Yi6jWpkJ3IwWvUw998uIVnXR1XVhGHcfDo99Op1PVexQ6IjWX81xs840/m4DlFowtLN96YOg1iopMYaTFSuHkR/SDxZwiZpNi9JwbZgyYkPTDHZZKq74Nz4Rw88XyhFLIZfyF5rkDRmKkvK8I7SHFucr3Q76uvp/xZP0650HIlXqqg348FyUi/B78yVXgYPBAHt89ki6rroghQhr8LQASKhnnwfShfxyJFI/TqVUGkp2hN0cRF3DbwxptNHY1GB/hx6Xs3RyYpOhCcthC/y1ObeR58TRPGQdBo0Ki0stuPiwCAYCUbUWNUVarAMHOdMKUHL9gOzeujXDfRFVVFXQe0NgHSXklfaRcoRriR2FEePDeOVNfiOngVRZPinXCEFI3cdT4rO5SPg6tKjJxGDiqkLf3k0rlZkNqCJfevxSkaQQqZ0MGH3n1GqQL+EGpkZIlOCfg+iO8nridV1L9JtF+slIEwk9VhPKp4LaXEqFwEVAtxXUZ9KKtJKu6BLB3sdQUPPiNTWIyF5AVZeTMYMA8eaU3B+ZCy6u64XmHVh1wnSCwlnApBEpwYR0AXEteNOzy64HilxdGyerJyyDElvsoR7628OuCJTtyRIYqVdhGV3QZiRxn4kIMXypjGot1CdL2YisZN6JlD9UkW+NK7NGSik8ozMM3stm4CiDTmxP55Fx2FTDJO0QgdnYx0CoHHHEZWbCwmxg7UJdx4yNdTZZkkFQ0tRYFJ4jigU1OxbFCViiYTPL/AdRnPrXrxFihVIOrgaclM5+AHCLKSXi96sVSrUV/WYZDjBMUgB8CLUBVpcx2Bs+G5geEVthHuNyvJnOLB5zhDtCT1oxU4eJbjkOT3SdeJdPCqHq5ApLDaIthZBp4vs2IcvCD1E/nzlFKjIbi377rxSVRARRMFWU1lND8TqtZhYNxjYUWOm8JNAuFEppqGqOFHsG1CJikG9zIKOInFxkY9uXnAjCtWVE2i5ZrgsopGoGjQZQY+1oR7KA7eZ+ddrarvi+cmjY8ueZZiMNgspTfAFoxJXss+VgdJlElme/BZyHWCRPSlfARC0uM/HClzHQDTk/fd7G36KR68mTFXw20kDz7k4JmBVr08iOOwYmOem87Ba8IKYwtgZxl4RbGx2PJW4M95M4M08EQnIvdQFAK1qXBdQSY5GEWTWt2xZKqNm2ofWRQNTy4JOlMR3hIN6kzW6NpleEWBXK1Q9uKA4LRR+MDJHryqCmNCRRP1myVOF3RS9uBTqhKmjSng0onrMiOqOGeiMD5U8u5iHryZ4cGLHZ1yKBrSi9RhtFpjXaMKNE5XIk9KLB7XlfIRChRgIn5KvAmIXuwyRSNCVZKZ/zbPwEscfFiWQ9MjCaz8DHW7TEWjSMAKIa5cFA1JNho7zMBzDj5LJsmX+q5aYsXBE52kB5X3Z8wCXyYPxJtzpCRQUGMAukd+KYljk1+CosJCVYumgEyS9CMVTW724qDgL51eH7RWL3Q9kyqaStisgXQd+FNT8Xoug3rwYcs+NwiypqholKUKJBUNryaZwcFDdlKyaDDJg9dOnlBKJAvBSwaKE+AGrNcbHR0JHihlpQpS57JKigrkN1CBIqaVoGiSq2AWZA0SnYQkrfi4BQ4+iyrdIOwoA0+ESLgqyEr14g0/uBeQqOtduFxwKVN5kooMHXzhgG1WcCzBwceDrKm1aLJkklwSuB4SsaC8BHH7oCo6RNEsPOHZiS+nLufghWvZ76WveFTgOni3zwKZaS375H3K1SRjKpqMCogZhjCxrcDB02oV5OQJRiMNAeJm9Arg4J3TXHc4ZyatODqnWbIoGpUUtcBYASQ8eFl8oLx/rsdWgxk6eIjZyv1+2Ot3s7CjDHzIVRJBouVLXqioosmYvCyY6iaXagUSnXhwknHwI0p0KsIrcgj1L5Rj00hYxiBGCYm1eoDktUt7WXFPalQ9WQXQUom9WPp90FotaURUnpp8/rEqYhS0Uo04eXBDO7iBZw98SpBV5UAkMlmLqWgSSq4sBD1ZAQDVKrQTJ9hLaBgMQNEAZHBnxlevVoGgNIZUDE81voTSJQtCli+VOHjevSyUsspOQqAQC51EL4OD5/SwqqLoBmNnGXhFyz7GwQccs8jN93OWn9xTl240LVCLJoSqUXAOYjGD2BcKT3UY8InJk1TEh1imYbyoibn8QMSGFgZZ8+uP5EI+x0C9Q1xG0QxcvE2131IpTtEMqKKhQi0aWqmm6OD7iSU+q5+epYMvkOgkn4sM4VxotQbtxEKi2UdheMUNPC0Sm5JApDIEMegGe3FmOCskLZM1DeL2JVOhg9cRyST78ZeHbkTXw3XTe7iKyWy95BzYaOwwA8+WfDFtdEzqJxjnvMkbaGlZMFbU4WqFo+S0CJ0jY4Dl+DCIcfC+H89kNZK1aAqVKnCjIOuadfBSDCLMru0HipWU4mmZf0tgTTME700OyuYh4NI5baSsB99XrBBlD17OZE3zgAfw4Eksk5VRNLRW0IMniJUXyE10EmEYQ1I0KfvPq+NE6cAct6iMYQ6LioPXIg5eXrnz5DVO0ag4eIEeJu6YohkpQu83hYMXg6yZShMIencVRVOUhjCHSHTK4hxHAZGDlzNZTamGhxjgMjNeVq5QqmAUBl58cILsWtLvMYpGvJ5pJVtVELcrSU0zBlTRiEliyrgAkFJsTItdw7gOPqqSmICfQTnJ6LsQSxVoCyeKe/ByLaIBEp1glpSxiExkBlnVtaDYsVLiY3kQBRPy6joWZPWDFZiwcjcMgNJIZJEWPxAzWXu9TadoCl0dy7LOB/BRAHsALAB4lW3b96dsawG4A8AHbNv+7VENtBDCRCdRqhQPsoot+wpVk5R08DStRo0KQ3V0Sln6DYKsJXyog2ccPBWuAwuyxksVREHWjCCgGGRdKwcvPfRhdm0/oGj6isDYgLpjKgWsCzfe4BDr+JTLqeUTlB68qDIKXwJdpssexBnIerkFn0dB1mIefHitubJnEIqGG8ZBpIFCjkoCGSsayuMVfcVLNANxD96E1lqOvvM9+AIHHybvcegGcwy4fDONgxcC6cR1Wf7IJqKoJfkggPfbtn0+gPcD+JBqI8uy9OC7m0czvAHBjYPYk1XktE2Zosnn4Inbjyd7GMU5+MQysABSdfCjQsjBG5GRErNVJZlkrBZNRiPjMNFpjR58IoHELIUUTSLIyhNx5Bda2guOfy5ryQfm4LkRcJnWXFWaVpFspqSwuDEuZVASssGUV1pp46zWoLWW2SqjCGSKzs0WIkQHEq53Gjetgp8SbwLikmYZPB6UksmaihgHX0pmsvI5svysAAAgAElEQVQkSb5yF++foYNWyqHIgqSttMVnYNAYwTog905YljUH4FIAnwg++gSASy3Laig2/y8APg/gvpGNcBCIxcYULftib1cVRyogbM4g62GLqGg4Mh7E2nvfDe3RR5Jf5FW5XCMIFVqTBaUKIopGMuIxmWQG3eQDx5s6fDICHby8bDcFmWStJlEIwRI9q1lGuB8TaLdZrEBqezewikbUwVcqxXXwcp0S0TAO4MHnZrNyVBk1U1gHL2cyF1XRiHGTlBotKoi1jmRkrRh5mYFhgqxxDl6qRSPo4GUKlxoGaLkSU9GoOXgtpJbk/ribgSKu4hkAHrNt2wMA27Y9y7IeDz6f5xtZlnUJgJ8AcA2Atw0zmD17Job5GQCg0ZgETB2VxhQwWUVtsgw0JoGKAeyeYP+uaQChbFsdKJ+yi32uHMwU0G8DkyVgsoYq3255GtAJKmm/AwBDY8eo6wB89m8J9UceQt1dTR7fICjPTavHxferE/Z//rcISuOfmzoae+oRX9isArUKKnunWVBNA8p7p4HZSWD3JNDsYpL/VieY3TsNANi1dwYwSHQdAvg+cN8PNBw8OIEXHnLwT3WiPN/C0HpApRTtY6qOat0A+hTYPQ08KFxP0wNqFcDro7G7Fi7XTdV1maihYXrARB3mnimgrAnX2MPsvj3ARMH5N10D6iWgpAGzM0CvjZriPlbnZuL3cYaVmg2vr8HuSaMxyebb6mr0XWxf0vlM1jE7YWbPEQCYYQZ+Ym4XJorck3oVs9PlaL+mhopiLsbGYmhozFSAWhXodNh94PdPdR9ElHRU90yqz2N2il3flHtZnioBZR1I+73wu/D3zTIwUWXPbmMaeJCgzr+rGmz+c9tR0YHaZHQ/ahWAepg9dRegAaWpCjBRSTwPmKwBE8E1nCix+TvA87CmZ0eBkXABlmWZAD4M4JeDF8BQ+1lYWIGfV79CgUZjEvPzLUy1u1hZ7KDiuHBPtNCbb6HWasNd6aI33wK6Xcy0HSzOtzDVdrCy5MCvtJT7LLf70BZX4c4vodSnWJ1n22lLDiZWOlgO/lalS8+4PhbnW4DrYqbDjiePt7u8gs4TC+hL3011umid7ICWkuPi+w3/3/eweHw5voTv9zEDDfd9bwWNBsUuECw+uRiOUZ9fRq3nodVcwYzrgzo9LC92QGkL5Y4L7eQKOsGYpp0elk+2MbtrF060eqi12mhJ4z1+nMBZAVwA37xNw+plvfD3w4DML2HKo1gK9lHvU/Tml0D6PRjERKndCa8naZ7ElA8QaFh84iRQraKxu4Y+ReKaT2sGVh56HBOagW6PAu0lOME2M6sdLC51gU6xuVft9OGfXIG5vAqvQaAvt7EiHW+y1UZ7uQtP+Lzc7oO0V6Pjuj5MAPPzLZQdD9qJlvLazfS92PlMER0rjy/ARzJ4Gs69ALOGgZZL0C1wT6Z8gpUnT8IvsdLJU6vBMyL8lj9r4vGWnjiBKWggro/Fp5Yw7QNLwjxNw8SqA2fZgavYxlzto7TchqnYxyTVsPrECVSXVtFb7SeeofA6HF9GY24KzktfhtZffRT6U4uoeUBrvgWz7aK0uBI+17XlNtyVHowusx3ayRZofSK8blMeAM1Aa7GDqU4XqwsrKPe88Pccta4H98QKevMtGMeXUHZpYps0yNe2CDSNZDrGRdZSjwA4LeDXOc++L/ic41QABwB80bKsYwDeBOC1lmV9eKDRrhVCJiuXScbqqwv0Sh6/GCY6ydH0SpU1UQgw8ebfgH7XncIPxd6denoAsNvF4pNOgi7OzVoUf6AlqQna7uCuB+s4eLCOw4er7NxjgVNp/8J1UMkk4/Xgk0vmRoOiVmfNIi65FCjpo+XgYzLJUilWwIqrKGKKi14v0UAbCMoVLC2xZXapFKc40mqapIDykgyul1oumNfniUHTUmWkmSoaedtyJa4Cytq2WiucyZpo+FKUoulFckXCadIiyJrrWTJJXmYg677xPA/Pg3nnUTY2kbNP6+jEJbByiRJDB61UQ4omjYNnweaIotnyHLxt28cBHAXwiuCjVwC4w7bteWGbH9q2PWvb9n7btvcD+FMAH7Ft+3XrMOZ0UD8RZI1NIl0XGhR4BYOscS2wX66g34oMs7a8DP3hY9HvxOBMiprA94G7v+Pit26ksaa+bLwZQSpDZw82/14R1DzxeA/zrSprinxER9+PbxMzoITEOltRw8Tqohu9Q2I6eLV6iBDg3AMUR4+u4u8/2RtIB6/ffVfyQ/mh501IVJpiHmQVlU29nlJ7TCtlaEsnQasVFmTtSsZ0kKJQnIP30ssFp+rg0174g6hocpp+iKDVanEOXtHwpUg8KGY4U2q0KH+XltQHZAZZw2YdbpaBZy8Iv9OF3+myOS3o5n3DRGe5n5zrYrlgcd+6weYNdxLTNPxiIH3Q/Ip1QFEVzRsA3GRZ1n0Abgr+hmVZX7Qs67L1GtzA4BJAXUfYbCDNS8goyAUgTHQSpVi+D/z0K3fjnm/3IsPsdKA/JixmUvp7ipifB/rLXZR8J9bUlx0ky6spsdUDn1iK6o2z9TYqM5Ww/ZlZkXpEihOTUnY8w4DvA+/8gzr++wcRnZsoMc2ssU0TLdyKYOrGX0l+KD04NOjgowyocZmhoUeGqddTP/SBB49ypXiQMg1BEJ/002vRMA9eUS5YvD7iS8U0invwlUrx8VerhVU0iYYvRVU04qppEJlvng4+1YNnAdKsRCxqGKC9Pq77cQdLT3XZarbHJM++D/zmf5nE5/7Bl+Z6Ri2aIMgavqTTxh4TcmT3fd4IFDq6bdv3ArhC8fmLUrZ/x9qGNRyI54ESLf4WTUnzlqPkvo94yzCe6CTU9W42CW79dhkavNAw7+p0oD36aDSGfoqBETA3ByzWHUx02lEPSo4MmSQ1Tea5hbr+pEHVel1c8TwDR9+1yvb7MyqKRngAg1ofzSbB9+4r48eoG57bbjELOKv0MTdUA+rgyfJy8kOFBx8tx6Xqfm6fZRkHFA0F0j34UjmkaFDOqPtSBHqwkvJcplRReeX9pA6eiteH0hjdxnqNFpRJlkqAqumHQh5Ka7XitWjkhi95q1wA0DWQbjfy4LMKiMnI08GnrHbCZh1ZxcYMEyeOe7jzNgdVdHDkiI7lBRcVw0SzSXD0niqupv1wrk96USVaVS0aahhMJskrVaadp5jMNiD1tx7YUZmsUS2ayPClLgOFJA7fB66/vhry1r6PiKLpRzp43hyYAJFh7nTQ/8Gj0bNVIPmCEODAaQ7e+ZalWFNfADHKJAHTBDqdyGvR9WT3mE4HtFqN2p/JjZ49P/nCCxofH/gRHWXSi85NqANSSNMvJ/JkgVJoS0uJjxmFJExL02C1aOTEEyB4ORnMs3dzOPhKGdryEmilnJBJDorQUAccvJKiUTVdEbuByd8PwsGnrUB4Kr24bbUayiVzkchkLsDBazrgOBEHTzPqy8jIKjaWVR6be/CqOcF/bxrYM9XHlZd2UYGDQ5e5mKkz56vRoLAukuZ6jINXtOzTdKAcXcfEPOXH1SOpMKOutgdFsz3Al4cakTh4xWkKVeqaTcZXc9662SRSsbFg8gbNgZ/2NA8339wBpcBD9/Zx7/9+MnwxpLURk0G6DiaNTpL6lVYcvs+UKpQiarjMv1dQNKTrAEJqeqjn599LHHz4OQHe9V4fr/y5TuKlAyC7VIG4k6IqqH6f9QuVvU4vzuGGDZRV3hAPAhoyB7/OFE0QLCX9PtPBKzNZc6pJyjXrByhrQSuVWDXMEP1+4uVGy1U027VCderkTOZCFI2us7EM4cGnNpgHsmvbcA4+M8hqQPP6+MTfONDh4+ZPt4IVnwFCgL/4sI8XvaAdzXXuWIkcfIyi0Vntfw4vJdagG7F7PC42NkooE50kj1Xu94nIM+e8daPBa070E5mlmsaeW0LYi2F1VYOJHm67Tce992qg3YKR814vpsYJIYxXXllQw4xz8IrqjcRxGA3BIU44vlORgxd/WzJQM/rKeGMqB+/7TE8PDBSoJE4HhNLkSyOR6CR0dJIMJgnoM959C0CGiqYMsrzEDPIoKBrPD4Ks6R58wrvUo+A/o/KEcUq1UcQXe8I6l0rJIDGSiTW+D9x27zSuPdxIBvNVSNSiyffgqa6zGvSlEnOs+v244csrm5FaDz4jyMpVNFnZ6MGqTuuzF7nW7cRW11qlhIrWi6ZsWISP99tVUDRiLCONgxfZA9cde/AjBe/opAkZlQWKd3HP/OjR1eiNbgTBlAwvgUsEeyhjV7WDF7yghl97nV7Mg+91wy5DMQi0iLyy6PoloOOEKxIVB0+6DlOKcOg5Mknx0JnL4pTvUgxqLjq8R6rkSStq0cRkkiL6/eChNCK+NlVFU4EWyiTXRtGI2Y6Mg08pF5xo2Sc4Hr1+bKVBBRWN7wOve9EC/vLiv8Xhw8kAKS2nBFklerDZJHjZ8kfxsHdGMpivQKIlYhGKRteBTidYSZnSCjOnxHXGs8kyp/tqpyHw4Ek/vWBgKPnkz5jTTVaTlFr2RRy8nwyQchUNR6aBH3Pw64JQQ57FwadMOE1DxFsDkRxKRbkEqfGEAAcOUJxz9amY7TwK1yWw7/LgeAUMntMFVB68AHllUZowmAHP5OCdGFeYeAlkek0ZSpmU4k+k140vXQuCUwyyoSKepIzgx1XdBzfoq2sI3HFa4bAyC7KiUg48eOG4A9bZDzn4sBaNiqLxkg+3FjV9T3rwkXFtNgla3z2GK/1/D17w8rmUIsMlgPTjL7dGg+Lcy6djK9NM8EbXHHIVSxVIFGSlpsn6lvLfiHJlFfJ08L2u0kOnQi2aVAOqB2UXeKtGpxOnsOTaP5zKFcpQxPbNVTQAQGlq020q5jpsk1IF2wexRCeFDn4AhAkNKilWpcImTlBne+Jpp+MFx4/hgfvOw8ELHJQnTcQeeUXlP9LrgnRSPHi+TbCy4Ooe/GaJef05HHxM92zE68MkOPhYPZSMAk9pDUe6A1Zi5LvjD16vh9heZZlk4FUSsfRqcD2Jx3TwcqKTallMS2WQ5UXBg+9Fxxu0eidXaQU6eKUHr6r2KM7LbvzFKKpoGg2Ky89dQO2+DnvBr8Z345tlrCz0YMiHkHhjef7kMmh5NdhV0DX2sjZM5sH3hDwNLTvonqWDp7rB5ojq+6BZR1aQNeyAFqzUSLcb6wAle/CJWjTSvlmik7AyTtP7Cz1zSd/ddAO/ozz43ESnQRAGWZOqmDCbNTB43hln4F2vfRBHj67iT967IiVIKLyYoKSqkoOXEFtZmCbQFSa9iqJxnLhHrcpk5R6WZLAZzz5gV55eF7Q0vAevpmiEacmLnPEOSaIRCnXw8SCr8oVT4ZmsTEUTevDDUExiQapyioFP+x1vBiEv3wUVDSHAW26cxwuetYKbb+7ErLjvA3/24Un88e8nk+SYBx+fq4mVaQbkTOYioDpT0dBSiTkTvV7m/IwhUybJDLzSS+aKrgwZZ0jthRSNE8+lkGW/cjN6OZ9CpGgIyaZoQplkvmR6vbGzDDzvhSpSF7IUq2ggMOjcwtLhJQNfrTDvotsFymX4p50B4/FH2IPUj3OricAVwLy3qWnlMjtrfNQ0QTqdTB08HCeemi5XMJSDziLy6terxtYdjqLhHHxCOSKPL1hVcL6VmmYUIA0Cr6xzlqhOST5UtBzIJKtVoBx5b0N13REDcaVSYYqHSgoL8biyR6kvn0SZOolL3mwS3PtQFYbfS/LqcheiQVGwDHEMus68Y8Ng191xImmtpiUpRBFZSVEB3aOMARTJZNV1di4iRSMabTGrHTIHzyma6NjuBRfCO+eAMHb1yo9KL/GBmrmvA3aWgefLYk3syZohxcraFe/comgLxj144nRAK1X4p58O7TGW7CQ32g2bRovoduHPzBTy4GMwS3GvRtcS5XllD16WScY8D8l6ZGerqjFwswz+uxQPPlGLhq8quMdrRtczzBnQpVo0qiCrLJPkx+0NHggLg6WDdDwC2P1KVdFIWaRLS8r50WhQnH5uCVXNSfDqMgc/KOggjd05NEEmKQdZ8/Ii8oKsXTVFw73zbB18kCjV7bJnoNtVKrFCeMG9DFb/8r57P3Ud3Et+VBh7it5fzHXoD1iGeh2wszh4Di5jA5JLqSK1wwGho1MygxKVCtDugNSYYsU77XToPJtVXtoZRryxAMCWtNPTag4+C2Yw6UWOM4+DT8gkUzrRAMl64DIUnurQQdbAeCX03HKNj0A+GCaNmML15AZW1sGrKJdKOaBUyrGGH0MZRTFTepAaNuK8zFDRAABZWlTOD0KA33k74H6thTf+vpSvsNYWcUO84KHrgNMVVldikDWHosmpRUOcrtrD5806cmrRcIqGTk8zajMrCTEm0Ei27BMz3YFA0KGqey9QNGMPfr0gUheyl2DoxbwU3rnFTZYOCDn4dptVmNu1m7VGQzLRKeQCRXS7oNODe/DREjiD43QcphThkPuAygZUfNnJFE0R6qHbHa6gUpBqn6Ro4l5xKN0MOtTHVkS8jIRYmKrXU3pNYZygUokvz9fAwQ+M2PJdOq7ECWtLS0xlpXqpViuoG93ku6W/xhZxwwRZtSDIWmL3ISGT9LKDrKkqHcMAuo7S445UNDkqnH6fPWuTUyAdJzsJUa5FIxhnOR8FQAYHr0XlKMYyyfUB1YSLrKpOWMDAh51bFDeJVqsgjsN4+Go17sXJS36zpOTg/cmpwiVfQ5TiKhqlDt6Je/BU9BqBeGDLiLeQG5aiGSrI6nRCWV0MiUSnQLrHiz8ZEQfPy0hQPZIfottVq2gCiZu82lAFJnMxpIGnokyy142vHGROeGmRGUsF18soJrVMcqicBL5fwxgiyKqxOWcIBl4T5ueQFE2kkkpX0YCQ1BVUmPzmOPCnZ9j1yugAReRaNAIHL+ejuC5J7bzGalgF5zwuVbBOEJbQshQrs1u7CJ7oJFeVAw+yRhw8OxCTEcr1J2JBQQ4nXk4Angf9/qDLYYbXzDJZs3XwxOnEjZhuJDl4LXgoNB0QRYqyBy8/PClBVgylg+8ymkrWwSdq0TDPlqtOqNhXl9deEQtTpapo2BgTpXN7yfT+PFAt8sQHQqxUgaKUrHDvtaUgIOz7SSqgUlY7B2v1GDMaXadC0xn9Iejgo/mVF2TNUbillOQtVBeJlz52nGC17KjpVnksWtKDl/NRjEqQvZujoiG9jONtEHamgY+VKpAmkV5QKRBSNIp06EoV6DggnU6kjS0HD12iWa+iSXc3Li3UH3wA9Xe+LX9MJZMt2zN08Oh2JQ5e2kbw4Kmux+knyYssAiKpQQonDTmdYBWjUNHItWj6/ejhFFdEnhepaGI6eJWKJsuDH5SDT2/ckQnxXuQdt91mVSAVRpBRhCoPfsAm1BKGkUlC10GcbkiVxQxfrgefk0jl+eqgqNysQ4EwK7fbBZ2aCmSSkiIu1ixckkkKHLyc6c7iat2UapLCPc6KEWwQdqiBF7Tncpd3g8u6spU1IUWjKEkaU9HUmDGl9TrI6mrwkKXXGAEQSAujbUhrGaTdzj0tylUKsVo0SQ8+tjqQZJKxFY2u55eDTQxCMuBDB1nVHryyFg2XSZqloA4JlzgGskBdeImmqmgEDj42/iG0yooaQIV/xzn4Itx/oLeWPUVarTK5rIyRePDDyCQFD76XXQwvhgyKhe1bU0sRhTmQ/tugWJnjwJ+eZs9N1vUJg6xamKUsbivmE1A51hA7rh67x2OKZj0gXOREbRPDYBRJXpW8WEcnOcga6OA7DvPmAdBaHWR1JVlHWjUZnaCcAK9Nv7zMfgtkT/hSKdDBi7VoZJlkN5ZxJ3Z5T1wP3UhO0qzjK3TSRA6yFlSVEKcDOjmd9MRUtWj6bpQ0IhohLmEVA+epKhruwccNPMtbGCLIOgRFE+Nn5XwJFXj9f8lTpJUqSCfpELBiY2swKFmZzCmgekTRgGefckopr1RBHoKXdwIqp0kGr34a5JwQp5Ns4gFEz6DrRhy850OsCZUAf3mkcvCiBz+maEYOSrTwQUqkQwdecG6nFb7sTwuydtoxDp7W68wLl+tPGApKSOXBr0r56KrzCh74fA5eriYp1oMXDbyW/qJTUS1CgDM83pBBVnQcdCrTah28pvLg+6EUj/OvvG4NTWSypqtoEquN9VDRiHGOlN9levABzUcrFZD2apKHrlVZga+U3w2LWCZzUapN05hTYZjRC0kUAWRRNDnHoKapNqIF2huGZaYTMknh+ojOQlhqvEAAPWidqebgtTAexFedm4kdaeCzatGw5ZWD3AQVTWMcoapxQ1CLRuTgGUWzwh4Q0YMvlZQcPErlUMKotVqFDDzMgIPPaNnHMlkzqkmKbfi4cVRBqd5QJ20NGmT1feB/ftrFZ//Pbvz1B3ypJ618v4KHkN8HkYMPdfBmjKJRq2gkiiboGTCMioZqepKDF40Vp45kxJbv3dSVA1laAp2aDgx8O/GykBu/h78r0C4yE6LBk6nNNISJTgar8yJy04pEvIFgGGojWpLKDKT8FiJF43STJYBFLl/m4DNAzfQkrNjqblyqYJ0geg4qHXyngIEPoKRoqjWQTsDBV0WKZjXp8Su8XgQ122mlyl4UIkWTAWpKxcZUMsluvB48NYwYncBWNELT7jQVg0rBYCQTobIMVRqaTYLlJx2coLvw5A/78XR7+cViGkyNwFUNol5cqkXj+8DqYjpFE1aeBNgLttsdSkWTuO4ydZXWizNPRRPQW9rSSfgzM0ClyuaFfI8MQx0DGDKrmCMWZOUNzfOga2w+m6VgdSwEWcnaKBpqGMoxZLY35BCKjYUUjZx4xPX0QDzRKY9+01mXMRWFI5ajGCc6rRdiHLxU20Q3mGEummKuiITHOPhqnKKRedDURKdyiRXAchyQ5SX2csjzdkwmkwyNlGoyymVqBe01gPj1UHHw4XYK9YbqXHq9OO1RIFO40aA4bbaDZW0aB/Z1Ej1p1UHWQCYplLQlLut7Sg0DtO/i+uur+OiHe3jz2yaTQzAM0PpEdC5l1tVpKN5avu5SvSGiargNSQefdlxKAw9+hs2z1dXohZyDzFT8IhAzmV230L6oFGRlnq3gQKzFgzdN9SqiQHvDUNMfyCTRVXnwZpgVHdai4avirFhSTpA1JuMdlyoYPahIXUjBkigCXtCDV7yF5Vo0AEDrE0KQNS6TTGiLu11WE4XvZ6XFOEXHUU9oftwSy2SlYZC1gFxPJZMUHsDEEpgHnVQlDRSF04jjMG84PJ6WXXMe7Nn5sStXcenTa5hqP4W22GTLj9cOCjXPfGUkBth4xyFdR3uZNUJ/Ne3hu9+votkkmJuTqmVOT0f/5l2RUjj7THCeNTAC1DSjpt8Au99p/GxYqkDhbQcUCVlcZGP1PUbRZGnFRahWBQNAbPhCijT7AAKKpsd+q0sUzUiCrMNx8KGmv9tliU6dTiCTFDl45sFTIKaiyXumqKGz+6d6VqU4y9iDXw9oJP0mGSYLuBT24L2klLAqcPAhRVMrLpMMyqvyqpRkeRn+7t3QWsvZLx65AJOWVNEkfyMZeMFDprqWfh0UmXoqRVBCB19wWU56Dur7JgvLJAEAmhYEAvmyOshRMAxMVFwcOuShQno4/0Jd2dzCPd+K/ihxD35w3ppqOhs3nxe6HnuJ81aCCcRKFSQ165wT1paX4E9zD35FzfWqULAfcCpMoS9sSpJRAqGKxmB0WrcXi/EQOrwHH+Y4yCjxkh0ZlVe5SMJxQKemgnrwORx84CzkPlO6wahJZT14YXW3BXTwO9KDz7xJhh6kVhd/aJQ6+A7Tm4sqGm2hmZRJGgqZZLcL1GfYbzsdaMvL8E/ZB7K8nO2tlfI5eBlM9iVw8KJnrunpLxRVWeHU1YjowRdblpNOh2UY5hl4TYsl24pVF4nrRSnybh+f+1wHUzf28OL/x4evePaX//7T4b9pucSOPZQOnudSsN9x6iry4Ptq7lhuyJzw4JlHGXrwiyeDIGtBimbY9onh8QWZZEat9Rg0LVjFldi9GFQHnwXDSM9k7bSzC6vxBDlRRUOpxMELpTl40lURDj6DomE0HA+yZhQ32yDsTA9e14EUz4EagVa34NIpVQff6cQUK4yiWU2WNlDV2OaNsSus5AGWl9HZsw9YWkqv9AhExcZimYIFAkKyB88fGkPBwQfqEiUHr1iNyEHWWC3+LPAMwxwdPNtpZOFj9XJCHTwLqGkaUNUKBhpLZaDbGy6TVQ9kcty7lKmrtIQa8WWr4OA5J0yWl0BnIg9eOSdU82qNumtRJsn6IBQJsnKHKZBJOgO07MsbT4pMEqYJ0m5nj4+/rFwXdGKCrZQlmSSVM2IJidO7aeMygiBrWqKT+PtBqo2uA3akgc+8SUGQtThFk+LBOx2QTjvy4DlF04vXgKamWiZJyyVWibLj4MHbV/Cpb5yOd/5WyrKPw4zXolHK9WTIOvwYRaMnVzKBsUrj4FVB1oQHX4SiCUoVyM2vmQ4+Y1rGtMuuMtGpiIHnQdahvCzuwfMXv5QBSjxPvUIU+dlukvunu3ZDP/4ktMVF+BkySYArueLJTqQ3ApnkgCoaqmtsFcdLFcQ6jmlr0sHzoHoCQXmErPsW9nOgNCrtID/LoopG3HduXKtYJuugvX7XAzvSwGfeJMMI6lcPwsFL24YcvBNx8PU6S0pJePAKmWSgg6fVClpPOXBWfSYZtFvoe1kefIm9nNLKBff7iWU1rdXiae1ihytdTyyBQ6WMypNW1IsnUl2dQokiAFsS16rx5tdAegGq4GGhpeih5P1yY9mDRdPDeZB1CA+eanpwHDYvYgXQgPSqhTEOPpkg1n/Wc2B+4+tMRTMzw1Z47baapuCrSBG8w9SQiK2O3EGCrE7ElwtBVlWm9UDQ9XR6yu1nj0986fKeAnKfVUFFEztmPyWAymHoTAqb2pN1DYHlEWNnGviMpSE1Ay+jiM0rfWgAACAASURBVIqGN5qWOx+lqmhWEx2OlNJC3nWpUsVMuYNanaJN6rhk/0mY1WzvlYhLQ6kWTaLZRziuSGNPPD/OwcsPCacbFEE2fi7mV78M89++wj6Ug6wD1Gmh5UrU/Jojq6UgEI8DcElogUxW3weOHyehU0V5kHWoTFYtCLJyuapwfCBo7qww8Fq2iqb33Kthfu0rjKKZnmb3sr2qNnLVWiKblak2RiOTZBRNsSBrOOdNMwiyRhRNIbouBWGtfxXSrjH/raAICp9jlQcvP5t8dZBB4VLDiDcXF78TZcmbTM8AOynIGjSyBpDNTfPlVdEgq+ommSZ7UB0nymQNKBpq6Ip0aHVgkgYc/IEDFK+7toT6RBO4JYeDB+IeuLgE7jiJrFI+rhAxDl4H9aQpwB9ylScdJG2Zd3wHtFJF/3nXsIkutwj0PRRZnMaaX4vjk48r3ANaKgk0AtPBk5yOTrxhw5EjOg4d8vC5z3UEiqZATRgZEkUjv8SJqw6yiuehUtH4p58B7amnQDsd+NO7Qh28MpinKjjWX5sHH6dovIKJTgHdZ5hhkDXmQKwpkzWFgwej8rIVZ3qSGpWchwQHD7A+sl0nW42kG0FZZJVMcshCdOuEnePBi6nVWdyfYQBOp7g+NY1Ho5RxoFXBg2+vJnhQKnXqARBw8IEOvtUCDB31vXVoraXsSRs8vGkcvNqDr8cNvFQuOM1LT9RlF79rzoergiRFM0BgrVxK4eCzPPhIykcCGoHxrUJHJ+nhlBs2NJskpGiG8+A5RWOGY4rFOVTlLWT01bEC97JDML99G+jUFDPiq6vKIKuSg19j5uQwFE0YLzGNqBYNERyQNQZZ00QHYYvANPBM1qyeBqKKhj/nQQA9W6FjxFfS0ndD9QpYJ+wcAy94pszwZahoBihVkAmKyFhyQyovA1VdkrgOvlKBNn8cdHKK/T5HJhk+vCkcPOvmJHnwwYsnhJiEpOnJlUxI0fhJ7jdYjWjzx0FWAtqn1wOEwmmDeG2x5tfi+DJUNChJgUDDCBQT6tpDQLJhQ6NBQ4pGpWbJHTevv8KPI8UmSIEs0LRSsr3nXsPugWkGHLyaolF78GsrVSB68IVVNHyOmGYoQY5kkjkv+yIyyTSHp1TKfIbDl1VWAx1VXXmuCsp4QXMlnsoRoZoQ8N8CQdadQ9HEqiTmqGi6DqixO3+fupbdOUa8gVWmaSe1WtyLEg0SB9eOV6vMwE9Ng9YnoC0vZ8okQ25ZPE9xGeoU8eDj10l+iFnAMC3Iys5FazZBp3cBUHjwRbw2ft3K5eIySZ41aphRHZKg4QcRG34owBs28KbJhIA14W63E6qnQtB1FqANrl2iUUZasTE+GCA1VtC96jno75oFpUGsZ1VRTRIIu4rFdi1nag4KXY8avhSuRRM4OCbXwYuJTtqaEp2YgVf7oJSXjk6DabIYRdYLL0VFE6qCssaVIZMcqhnMOqHQbLAs63wAHwWwB8ACgFfZtn2/tM3bAPwcAA9AH8Bbbdv+l9EONwO+H9ffpi2TTCO91KcM3QC8AlUegejB7UsySdEgcQgUjTZ/HP6e2dCDp1WpIYWA8MUhGniBwyZOJ5eDj5VPVkX8easzlQ4+8Iq0+ePw954inG9cB59r4DmNomlJL0dU+YQ7pRHlIagjSKCDD5uzZIA3bOBwrrkW1V+/CTjvnKFq0ZBeV6BopCAr1+dnQOXB+z5w/S/vw7Env4X9h6v4/P/LPXiFp1utAe0Re/AiiiY68XsVGFwilirIymou4N2m6uCBILEqh4NfXYmqhwbNU2L7571dxc/CLOU8iqaATHILBFmLUjQfBPB+27bPB/B+AB9SbHMbgEO2bV8M4DUAPmlZVlWx3bqA+MU8eBp48EW0zzRL8sQj8/LHiYp1yfotrOFHQNEcfwp0YpIZ+NZydnp4goPXJA6+m6uiCeteA8pSBZTXQ1Et0YPkGnLyJHonV9npy40RCpSIJd1IXpr4zvOTS9+SGfLkNFYBkOvgJQObA98Hrvvti/Hx2y9E+zP/G74xjIHvpQdZs+gNPmf6vcTLmMcKnvD24sgRHSedWmotGt6TIIYRVi8sStFQXWeOFS8jIfUMTm0BqShHnYBhJpIMw+MG1StTx2WYzLHh15gH1UWoervqvAVhBkXDg6xpHLzrpfcE2GDkGnjLsuYAXArgE8FHnwBwqWVZDXE727b/xbZtPuPuBEDAPP6NgcTBZwVZSadgNcksA1+pqPtXSl6Uss9lQGvQShXa8eMsoFafyC9VwMcsVusTYg1MtimtAOTsU/FFqOlKpUxI0cgBWMMEOg4eX57Et7/SweHDCiNdRAffcdLb/KWod0JvWa54qPNEp+KdiLgh/f/oO1Dpt3BydUADTwgoIZGHK5dw6BcIUCrkoHKsYOYURiOpEr94yerYsIahm9JQlKLR9MhZ4tdDVLOlzQXPQ6KZuARqZlQ7Nc1MIwzTZHEioZMXceIGXs3Ba0GtqhwPnlJ1Qp4WCDzWWjZiRCjiwZ8B4DHbtj0ACP7/ePB5Gl4F4EHbth9d+xALwqfRGzMn0YkUadkX7CftQaWVqtpIuZKBUiVT8FT2ahBknWJBVi2nVAEIiS9b5QfI6SZ7jsrLRClWkdA6x2SS0vQoleA89BTs7n7U6UqgTJHGWICiId2o1WECKWWKQ77bjGSSJFCrsJdocd6TG9KmcQre8rTPYvrC0wr/NoSuCy8daZWWVmwsB5QCH/qQgzvuCJo7V9OLjSk9eHeNmayxfRVNdNKiY5oShZhFlaYltInIKGdNSzkevG6waxc8o7RaSXrUiuJ5TAKbI5MUi8wpQHw/KAe9uXVogHUIslqW9TwAvw/g2kF/u2fPRP5GKZjdVQWqZTQak4DhAjoJ/q2x/3PsmgC8PsyZOibEz1WoVYBKOf57jukJAF78u8k6cPIkGnNT0WdzM4ABVKV9NOamgH2zQLeLiX1zmDjrFGBlGdV6JbFtDKUSpnZNAI1Jdi4njeg8SgD2TKMu/168BqaG6uwU+/10Hej349tP1VGdCF4iE9VwLI3GJLB7EhPd76I/dxpKTy3gqqsIKitafLy1MirTFbb/NDR1YHpCfX9KGmp7JuO/r1WAUoltt3cG0Cg7JqGYPWUXUNUAHWjMVADTVN8vCd/4BjA/D8zN/cRwVKmuozZZQ60xCcxMADUjGnPVAKZT5hc/X+G8Gw1Wv/6aa4BbbgGuugr4ylcADQ1gdRW1ySo7joi9u4HF+fgxqIfGvt1r4+H5uCZKwFQtedxgvCFm6kApuOZzMwAQzc+pGjBRVs+FFoBKKfteTdeBXROYVG1Tr6I0XVeODwCg94FOG6hU2DGmJpLP8uw0sLzAriE/7yoBul1UJ2vpz+EMs1N75qYT5+b7QO/0s7Fn8ThIrVJoLooYdPs8FDHwjwA4zbIs3bZtz7IsHcC+4PMYLMu6EsDHALzUtm170MEsLKzAT+PsMtBoTGLh+BImPIrl+RbI8iqmnB6W5luYcX0szrfCbcsdF7XVNjqOC0f4XIUpH9CgxX7PMamZ0HQTS8J302YZ+nILJ4TP9FYPtVYbLeGzBqWYn29BW3WxB8ASSuh1KGaXluD0KVYyxrXHMNFa7aE330JppQdjuY12sH1lfhFwSeK8ZvpeeA6Tqw7aSw68+RaqHdZUvC1sX+9T9OaXANNEqedhdb6FRmMS8/MtlDsuKscexnNvuBDal3186lMtuNfGr+9E34ez0IKbcQ7GEwuoEAMrivszsdKBs9yN/X6KEsAnWJ5vQWv1UF/poDXfwkyni8WTHWgtBxNtB60HH8Ps9DTmc+4rh6YBzWahTROY1XV0ej5W51uodj34J1roBsctn2hB63roKMbBz5ffE35tjx8nuOWWOlyX4JZbKL7//VXsrbmY7fXQdlysSvsq9QGjeTJ272Y6XSwuOgDpyoctDD6+0kILRteL7R9AOF6OcruPCd3AwnwLequH3QCWV7roBvPLP7kSXhcRZHkJUz5iz4+MWt+Ht9pT/n4KGtxecnzh/lcc7F5uQatUMD/fwiR0GETHSWH7UseDcbKF9nwLMx5l87DTwazjwHHTn8NKx8UkgIXFDvxqtA1PqHvRrRfDvP9beNPZGpYLzkUgeW2LQNNIpmOcS9HYtn0cwFEArwg+egWAO2zbnhe3syzrEIBPArjBtu3bBxrlKCDou8NiY2J2K4dhsCBnkWCUbqQnrAilgjkSmnMgVt5WRljmYGoqCgblBZ5MM70WTacTJl5x+D7gehoopzDkhh+KIGsaBw/ThPbE46CNBgwjRSRQkIOPBRjFYLWKGjJLUTkEsWZ5LNHJBVlaBGZmso89IlAtunZUCvJm6uBTlgtKrT6fX2mJTrKKRlFWY2gMRNEEZZP59dAEiiaLg8+rN29klCrIC7LqBnsWQ4qmmqRMVL1ddZ3x6zkcPIBEfgKP7Ryll2DPQ7ejSzefoimqonkDgJssy7oPwE3B37As64uWZV0WbPMBAFUAH7Is62jw30UjH3EafD9m+IjvqxtH67xccAGFAC9Fq/quUk1IGmm9rgxMJiL1/CHkpYanphi/Xp/IlW/SUimVgyfdbiwuwD2K2+6Zws8fpizuLMoQjWQmaxgwTJFJao8/Dr8RxNdVUjc946EOxyno9cVKkIAy+BirSSKm08eqSXqsYYrQtWldIcZn5HucVmwsA1yrf/Qo498JAXt5GQaospqkItFphCBesky2EroYZDWiz4DsjHJBzZWKtGqSCJ6DHB08oVQIspYTzpqyt2uYvJb18hDEHAL4S/oe/SI8p/ZtlOqbb+ALcfC2bd8L4ArF5y8S/n1ohOMaHKpEp5TG0YV7sio8XA5aqSSUG7RWS3oJokFK7CPw4CcZZ696QSRgmFJJBjGTtRNbVXCPooUJ2N/poNmcwowgQ6SBt5IYL9fyK6pJakuL8GcbjOddXU1qpQtUEBTVPpQ3v+bXjXfWiZ2zEX4fa9fGmzQYBuvburyRBl6Lv3QcJ/rOdZPBbg5KWTGxieSyWtbqA8EcUQZZa4lEp5FiCA8+vIfhSjrLwCvKUUvovOqXYw3kYzDNbC+b75vfh3IlGYDmvV3FZ4CPPUuhE77I4i+oMKHuqVNw3nOPoWeel76PDcKOKVUQqyPOkw2Ukjs9vZazjCwPvlpNPMS0PpGQRmX2jzRNUE3DfG+aZS7W67njoiVTqkUjPECOAwilCrhH0SZ1XHnREmtjJ14TTUHRBDJJ4qlq0bBz82cboBMT0E6eSJS8LdTww3Gia1eK65NjiVgcpiSTlKQ7bMwuyNLShlE07NpF1IRcbCzLgdAefhj+mWcVO06loi5VoCoXPArwpumuWzDRKfLgo0S8qBRGWk5ELG8lBXT3HqBeV39XKmWPjyvOOEVTqST7OnC6T1zpE8LsSBb9I6uFBGgaMHeqBu/AgU3v5gTsIAMPn0IsUwrPVzatYFruYg0/qGGkv8mrVWVZgMT2gewwLFUrxAp8StBBFZf92Kk4fLgKvzaB1a6eneSXwcETqVQB9yiuPVzGB9+3wJb9ckJYwpga2bVoANC5OVZa4cRCvOE2AEp0nFzws8+h46DlVtlLrSy9AAvIJBOUV1CqgGwgRUN1PTIwphnVwgHUPQQE6D98GN5Z+4sdp1pN5eAhyyRHwb8HDWLYC75IsbHoRRdSILE8jei6xEo2F9DBZ8Is5csQDSOiaCqV5D3hOSLySl+knVTQJSpKAfeCCwfvFLYO2DkGXrxJfKIrPXgjP4jCoRvZOngpoElr9YREzdNM3HOnh4MH68yIdyKterNJcNKfxopXxW236bjrB5P4q7+usO1SVrbUzODgnU5Cm69pQHm2zjIigdg16V3zY+g9/wXS/pk3rGy6HVwzf/ce1gbtxAlQodCY7wM3/3MJb/hVM3YO4oPt+8Bf/omHd71vCocPVyOKJrxg6nsW15wr6oe4HrSlxQ3l4ONBVrEWTXbza/3YQ8UNfLmspjJqcQ7e99kQ1lrfimcyF6ZodD1MruIvBFWQlceDwuegX0AHnzXOkpkb56CGKVA05WSTc766lue6rhcKsmZVPXWffuFoChquETvMwEun4/nJz8LAWJFMVj0jyKpS0dQTE6O5XEav1Q9L1Z58Iqqf3mhQfGfuJ2EYwMGDHp5cnUSPmlFJWxXE7L6AitJ++DAqH/9b6A8+kBgTG9cESDso7ytQIP6ZZ8Hff7Z0zsED7nvKUgX+7t2MMqnXEx58s0nw2JMGqE/Dc5Af7Pl5gieP9bDi13DkiA4HlYQHv7AYX8WwgFopOmc5qSl4oZPl5Q2laFqdEhunFGQlWVmguhYY+LPV30uglarS02WN39lL2/eBnz5cwj33aJnOQSFwFdUgBt4QXr78M/7/YDByyeaTC7RYPajUceYEWQH2rIQUTTX5LAcqmsRKX9Ozyz3nJDoBgHv5M+GdcyB7fBuAnWPgfT9+k3hxIdkL5X8X4BfDNmSqw515Jrz9++Pb12qJidE4VcdUvR/K32YnIwNPCHDFnX+Ko0dX8YUvdFDeXQfVtFAmpxyTWYqCpEE9+PLH/w79W4+id/mVeKq2P+nFiQXH8jIIg6AwSZFJ+rNMQUMnJkFOxj34RoNi7z4NJc0Nz0F8sG+7jRn9805vo6+VceiQh/JkKfTgfR+498tP4fLrzokbKrFUQQYNsVEUje8DT84b+L1319g4dcmD72c0v9Z06D94EP5ZA3DwqvvFm86AGc/HjzyJR3B6tnNQBIGKiqloinDw2UFWHo+RZaB7Ztx8FU0GfLOEpVUje8WixykatQefrJxKczx4WoSiuegSdF7/a/knss7Y/DXEiJAI2lCa0jg6WF4VkoClUzTONT/Oys9SGtocVZCVaAQHDlAc/ftVVqr2kXg5AVE58ayfqOCiPT7+0+92Uu0YNUs4uaxjgoI9XK6Hu//6KG5o/Q2W66eg899I2LWIL15iJYN9P7MIEjUMaP0+aIpMMjTw9Tq0hbgHTwjw0z/r4+oDq6j+DDsH/mDfdpuOWo3i2mtr+MApDt7z/xNUf64DvDkKsjaPU9BWG4uYwpEj7OUwN0ejtnw50JaWNsTAN5sEZldHF2y1tdQuYU6sB+8pVj8cug7tycfhz+0tdCxarab3JQ2sW6NB8ULrARz7/tmZzkGh44UefHYcIdyeq5gApqjRtHipAt5kXCrZTG0fTs8YSrrv+8A/fKaGrz4+gR98vhqb6/K5iMXG1Bx8L7nS17X8csHAmiimjcLO8eBVQZt2G5BkVuGbuWixMcWNTvCJgafJgqzqiTE3x14EpNtNVBEMxzZRR31aS53wvg/cflcZr/ylCXZcosNZ9VBbehKP+fvQapF41yK+36BfbLiTPA8+pRaNNzmNldMtFhxNUdEQQ8fMpBeeA3+w//Vf27hm9Qu4zv0sTjzGWh0SEgRZAw/+lNUHcWLPgViyDxBw3AUUCRtF0TQaFKWqDl8zcOiQh+lZI57MlqGDp1w/X9Cq0Uol19MlBHjPr9p4+VtOjzT0w8IQOPgCBowSHV1aijxp04y4aamaJHdmKAXedJOB//nF8lCUUrNJcNvjZ+AJf2/2ikXg4GmlmqOikTj4IgZ+C5QDzsPOMfBiy74A+tGjWDz7kvgyTtQu5yCNolG2gAOnaHL221UUBOPHy9HBN5sE80tldD0DR47oWGwZmHj8AZzYfQ50nWJykiaMI9+vSNFkBYe4TJK6PlrtaAns+8BL33ge9n72Izh8uAqvNgFyYiFG0QBQFhvTNOBpT/PxK7M34134XZy9dxXTeyOZJKdojO/dhSte+7R4sg8Q0zyzYCJVLs03iqIhBDj9TIJ3v9dj4zSNeMMRz02fB7oO7/SsOn1x0HIVrdUcZRUA45GHULvwrDXbnNCDV8VgJPg+8Pbfq+H/fK0aGWrdiFaIKZmszSbB9+8G+lQfilJqNCjuvuLV+Jrx/Gw609BjiU7JTFamolFy8FndonR9bfGDDcTOMfCKDMgvveM7+IX3P0/icwehaNQ3WpVWDjBPOU+6JTepFkHrE5leU6NBMbnLANEZT79rVoN59HY848aD+O53V3HffatJ44jAwAtB1jwPnvb6+MCfa3jPe6MHV36pLfuT0E6cTMgk0yoIEgK8cN9RnPKyy/HT5j+Hen1aKoUUjXH3XfAuuihc7YTjN0wW4A1WTt+yd+MXf8pJHqO1DExNJT5fF+g6pnbrbBViGPEga7+fPr80vbCCxveBr9xaj92H1OE8fKxw4DYL1DBw4imvULngZpPge7YZEwaI1U4pz0eR0GhQXHRBDyBkKEpJmfWrgkjRVKvJ3geG2oOneTJJI6OM8RbDjjHw8lvYdQnOfPLbuNW/PO5lDxBkjcnzxGOlTDBvZjfatdmktyV8QDtdrHplpUfGEp3SbwkhwDOfp+EfPtVj5WR1HaTdhnfpMzA3R6HrSBhHgMk3I4omz8Ab6Cy76B17IlwCz88nX2qTp9aUHrzcCDxEpwMQwH/zb0B79JFI7VMus/Z3AIy774R74cXJ35ZMULMUvmR+QM/Gydt/mCxVzDNbNwBUE3ha3uCZw/XSg6y6Br+ggW82CR5dqKHnG2pPVyjzoD/8MLwzzhzwLOLwfeDLX6vg5S8z8MmPE/g5WdWNBsX5PwJ4xIwMtWnEev6qEp0IAf7rH7Vx+AaaaaBjunkJnO7JXLEIFE3/R5+B9o03xb/nklvPi7/MisgkxwZ+g+H7MQ7edNuYnPDQNepxL2EAmSTNaPorTzDfB1564zmY+/zfqr0t14XvA7/3VuD9f6XWuntPvwiu9bTMMTm//FpMX7qfHVfXQQmBe8nB7POQKJqsyUkNE7VSHy+e+Bq+qT8bhw55mJtLvtQwOQnt5ImkBy9I40QY37sL7oUXwz/nADo33gS/MceOJ2Sy6k88Af+UUxO/9XUTLcfE7Cx7uTys7ccLDjw4EplxlhHJhJDoRGt1kBWhCqCb3rKPGgbcM/YXOmajQTG9twyiqT1dWqlG5Qp6vfTyCAXRbBI80SyBeC6OP+ZhuZ2zGiXAe97r4oUvJaGhpoZQ4kKiaKof+UtoD/0AAFC6+7son74n07ir4lyDgAqJTqhUkpJgLrmVyybkePBUNzJpzq2EHaOikQ0XWV7G3pdcjTveuhp/08tp1VnQiwX3ADUvz9Ux3gVPh/G9u/D4qZfimN3HblpObAMA/WdelXsc95lXCuPT4J13PuhUNu8cq3IpeLmcegkbUQOsYmSnjUvOOoEvfWICjUYHhLAa1aLih9bryiBrWrEx47t3wD14KQBg9R3visZWZl11yPw8/D2zicCV7wOv+NzP4zt3mDjnS1V85jMdeB/dh5nVe4EvrM0/4UbkyBE9oTzKha6FNIx35lnQHz4WfsWqSaYEWTUdN/3J+fiHe5jj8Y1vpB+CEODFN5h41pwL8/VJT5dWq0C7A4Jg9bdGNBoUu+YMVJs9nD7Xh6/lq1xItYLK7ipcvo1hSEHWyDJX/u5/oPyP/4DV33s3Kh//KBY/+4XU/WY9T4VhGKl0aIhS0PlJXDlrWn4tmhwPXvlsbQJ2jgcvGHjfB+ZPGHjTJ5+L172uEk+a0Yt78DAUHY9SkMbLA0D/iithfuubaDQoLjw30oCvRc4GAH5jDp3X3pi7XcyDD57YVCWQYcL4zrfhXnIwcwns1ydYdqwqyBrsTPSOzTtuh3vwR5M7KldAut3Aw08WH202Cb509FQ85TVw5IiOEycI6heeBf2hB2OrK9LrJkol5yEtWF4IYqu6cpnpqflFzPDgH3nj7+OT37skPOb8vHKzCNUKJmdSlFXVGkinDe3YscK0TxYIAX7yOoL/8ZFlGHDxq2+YyPWe3Qsvxso73h19YAgUTVAMz/eB5kMr8Kem0X7zWzD16p9H6y8+DCgKrnFkPU9FQU0zd1XjHrwU5u3fjokbqJi8pdqvYWRSqaNYfYwKO8PAt9uxOufNJkGnp+Pr/rOSD65RnIPPKhcsIyvwwwz8rSAEePN/buF33l5Zu5wNAJ2ahvNLr8nfTkx0CpBq3EwDxp1Hc1cTtM4ezkSxsYCDd13g5S/s4/hF1+E3r30A+r3fh/sjFyT3EwRZjTuPwr34ksT3qgfdP+ss6A/9IK7yIBr8AQOsazIiUgDe27cP2hOPsz/cdAXK9OXn4bLLI7XT3Fz2YVg1SfVjSqtVEMcJAqz7i489A8Q0ofsumk966Po5WdUAm/iCEY0FWTUNcH1cf30Vr7vqIXz+4Yvh/NhPYuHO++Cdb2WPo2ggNQtikDUF/UNXwLz1loRMci1B1jU5DiPG9jfwnQ7w4hcHQVZ2Oo0GxT/tfyMe189IPriDJjoNUBEuLfDjnXse9AfuByiF8eB9mDzvlA1dtrEg60rsszTj5uusjnbvmc/K3mdACST60larIA8fw0teUsWL73gP/p1ehd++8zXoa2X1tQyCrOaRb6F/KFGRWvmg+3N7oT/2aGx/1DByqaoi+y4KKpWS9s49n91jMDVPs11XSzkHPGb3xS9B/9nPVY8h8OBHaeBhmpip97Bvrg/o+uAvPrGctaajverjyBEdF3h34cvzlzBjVzBWUCiQmoHu9TcAu3dnbtO/7HKYt92a4OAzJaJGNgc/itXHqLD9DXy1CrTbjEcLLjohwCtufR2OfredlAwORNEYxV4EeSAE3v6zYdx5FOV/+V/ADTesfZ+DQEhrF4aUNJw+8Ou/NYGHcSauu8nKXlrWaqCEJIqrOS/7GeBbt+OFt/8hnoVb8Hb8Ht568c3ovvUtyt3QUhnE6UB/5BH4KfrwxIPOa5CLD6Whs8YpA2JoIyJ78OedD/2B++C7Ph751lO48AXnKJfng3Kz/jkH4O9TNwX3KxUsPt6B9nDx2jZ5YKWPXbzwx7v46Mf7g7/4TBOUix00DbWyh0OHPBwk30X/aU/fUGPnvPKXcj14/8yzWB5GohZNTqmCDA9+McJ5FQAADPRJREFUJKuPEWH7G3gAuPJKGLfdGlvKpj64AwRZWQblaOLQ/SuuxOSvvQ6d17x2bU2R1wrhgsjXqNkk+PLdp+JDeH3+0lLTQGv1ZJC1UkHn4x/Di6e+jjdr78Olz6D4my/thnv189X7KZdg3Pt9uOeci+PzWmE1i3/GmXEvSx/cg18TNC328vfOPQ/GA/ejdcs9ONK5GK6nJa7hKLlZ3wc+/YUpvP01C3jsk99C/8CImksE1SSJ52JXQx/qxbewGCTI6Yyu+9znOnjVpd/Fu24+sPWSPwmBe+iKBAefK5PMicavdfUxKuwMA3/11Sh9/d+KN/EQ/5+B3vOvRfclh9c4OIb+Fc8EcRw4L//5kewPGFDiV2CjRoPi7Mt344+NtxRaWtKJiWSQFQAmJnC2/Wl86M6L8cUvZitTaKkM89+/hg/d9ayBDJ935v7YPaSmCX8jDbzA0/o+8OTM+dDvvx977W/gh2c/W7k8HyU322wSPPBEHX/ivwm/7bwb896eNZ8SECT/9HusIuaAOlTfB+55oIwXvjgqpQHqQyMUZacFTE8PL0tdB/Cx9C67PB40za1Fo4918BuK5zwH+n12sfRhTWPUQpEg69698E87fQQDBHoHL8P9H/tKsm3YkFiPSP2gS0taV3jwAYp6MLRUhnbiBP7x0WcPZPi8M8+KB8ANYyiKZljwmjL8Plx0zVk49u0FmLf8O37lo5crr+EoudlGg6J/7o/gHdo7MX/FC0dGfbgXXQzzm/9evFywgGaT4ORKKSqlsayBeB60Rx+Bd8YZG64u8X3gqafUvo04lhs/9yL0zxWCvjnlgqme78FvFWyPUWbA94Gn3D1wn/b04h1iRsWtF4TvA9e/rIaLnr9/ZBN7YG/QNEBWWsluSBIGWVrSicl8nXEeyiXQchn6ZRcPZPi8s86KS1h1HXSjmn3w4+l6dB88Dc32BMg93wc9/zzlNRwlN0sI8Btf+wn8pzt/caQ8b/9518A8chtIa3ngeiuNBkVtKiqlMbNHg3bsIZS+8q9wL3j6hqpLuAE//XQonzlxLJ+85yAeeekboi8LUDTjWjQbAPEmfu7E1cWzy4z0MsDrAXli52qfC2BQb5DWJ1D7oz+A84pfWPvBw33W19yWjJYrcA9eik/9kzeQ4fPPPieWRUsNY2CZ5FrgXngx6MxM7D6caJwHeuEFmZlBo+Rm14Xn1TR0f+o6lP7tKwM/I4QAF7zmR/GlW1hmq3fwR9F/7jUof/6f0H/WczdUXRI9c1C+TLLGkleLxtcMuDS/ANxWwLbOZBVv4p/OvxKH9p9EeupEBFa8auMa4vLJxDMm5+YMNJtr26dcX7sInVL6ty9j4UtfR/P4aDLsaH0CCysVTA1R05vDO3AuWn/wvliWbBG4F16MlT98X/SBYYBObpyBb7/5rQAAgug+nHnzBegPmGy1FeG84pWo/fEfDOUEdd7yNszyP0wTnRvfiM6NbwQQv1brneEZPXOspPOePRTHhXkvPj979lDMzwtjyvDgfR+4/oYJfOgHJbz+cHot+q2CLTy0fERvYQCXPwP1F2Vrt0OYxTi0UQWE1ks2NYgH5559Ln74G+/F9T87NTIVxz/ffS6ufflpa9tXqQRPkcGaC0IYRcSx0SoaAfw+OL/6eibN22CMOnDp7zsN7V//zXUJWm+UuoQ/c48+Cnz2sx287GVJ7l/TgNlZmviue/0NqXRfs0lw5NsG/hJv2PQkpiLY1gZevImDGE5aruS6nKMOCG2mbMr3gWuP/lecf+OL8c1vjk7F8fPNP8cx78wtMdFbv/1WPDF53uYumzVtw5tArFfgsv3Wt2eWEig6ts1UzGgasHcvsLCQzv2r4gLOL746VcrMncqPGDduehJTEWxrAw9EN3Gg56pAYHArpRuvFfxcPI+dg66PRsUxCj51WCMg/s73geve+gwcvGwaV1+tLGa5Y7FV5+lWqseSNVcHncdbKYmpCLa9gR8GtABPupXSjdcK8Vye+czBgplpGMVEH9YIyL+bn4+M3C23YNOM3GZ4rFt1nm6lF0/WXB1mHm+VJKYi2NZB1mGx+sbfiAVcVBg0iLmVsV7nMmhgVMawJWHl3wEIg9hXXUU2xcitqfTwGrBV56ksLNjsF0/WXJW/2yqlfkeB/3AevO8DL/zYqwt5jdvpTZ2HrXguw3qf8u/m5mjohX31q5vTC3kzPdateG+3G5XBsZWopVHgP5wHP5JGAmOMBMN6n6rfEbK5Rm6reaxbAWtd4W0Gdpp92DEefFH+c6tylv9RMaz3udW81u3qsY4Rx06zDzvCgx+E/9yqnOUY2x/b0WMdI46dZh8KGXjLss4H8FEAewAsAHiVbdv3S9voAP4MwE8CoAD+0LbtvxrtcNWYn8dAy6rxgzjGGGOkYSfZh6IUzQcBvN+27fMBvB/AhxTb/AKAcwGcB+BKAO+wLGv/KAaZh7k57Khl1RhjjDHGKJBr4C3LmgNwKYBPBB99AsCllmU1pE1fDuAjtm37tm3PA7gZwM+McrBpGPOfY4wxxhhJFPHgzwDwmG3bHgAE/388+FzEmQAeFv7+oWKbdcNWC7qNMcYYY2w2tlSQdc+e4WtfNBqT+RttIYzHu37YTmMFxuNdb2yn8Y56rEUM/CMATrMsS7dt2wuCqfuCz0X8EMBZAI4Ef8sefS4WFlbg+4Pz543GJObnWwP/brMwHu/6YTuNFRiPd72xncY7zFg1jWQ6xrkUjW3bxwEcBfCK4KNXALgj4NlFfArAay3L0gJ+/jCATw802jHGGGOMMUaGoiqaNwC4ybKs+wDcFPwNy7K+aFnWZcE2fwfgBwDuB3ArgHfatv3QiMc7xhhjjDFGQRTi4G3bvhfAFYrPXyT82wNw4+iGNsYYY4wxxlqwVYKsOsD4pGGxlt9uBsbjXT9sp7EC4/GuN7bTeAcdq7C9siE1oVujc+yzAXx9swcxxhhjjLFN8RwA35A/3CoGvgzgEIAnAHibPJYxxhhjjO0CHcCpYOrFrvzlVjHwY4wxxhhjjBg7plzwGGOMMcYYcYwN/BhjjDHGDsXYwI8xxhhj7FCMDfwYY4wxxg7F2MCPMcYYY+xQjA38GGOMMcYOxdjAjzHGGGPsUGyVUgVDo0i/2M2CZVl7wIqwHQDQAyvE9nrbtucty6IA7gLgB5v/om3bd23OSCNYlnUMgBP8BwC/Y9v2v1iW9UywVo1VAMcAvDKoNLopCNpB3ix8NANgyrbt3WnnsKEDBGBZ1vsA/DSA/QAusm377uDz1Dm7mfNZNd6sORz8ZlPmcca1PYaUe7+Zczjl2u5HyhwOfnMMa5zH297AI+oX+zHLsl4JdgOfv8lj4qAA/si27a8CgGVZfwzgDwH8SvD9VbZtr2zS2LJwA39gAMCyLA3AxwC82rbtb1iW9btg5/GazRqgbdvHABzkf1uW9aeIz+fYOWwSbgbw35Asw5E1ZzdzPqvGmzeHgc2Zx2nXFlDc+y0whxPjLTCHgTXO421N0QzQL3ZTYNv2Cf5gBLgVrCnKdsMzADi2bfNaFx8E8LObOJ4YLMsqgTV9/+vNHosI27a/Ydt2rDFO1pzd7PmsGu9WncOqseZgU+dw3njXaw5vawOP4v1iNx2BB3EjgH8WPv6qZVlHLcv6A8uyyps0NBU+blnWnZZlfcCyrBlI3bls224C0CzL2r1pI4zjOrB5cLvwmXwOWwVZc3ZLz+eUOQxsvXmsuvfbcQ4Da5zH293Abyf8OYAVAH8R/H2mbduXAXgugAsAvG2zBibhObZtXwJW/I0gGu9WxmsQ93y24zlsB8hzGNh683i73nt5DgMjOJftbuDDfrEAkNEvdlMRBFjOA/By27Z9AODLNdu2lwH8FYBnbd4IIwjj6gL4ANi4eL9dAIBlWbMAfNu2T2zKIAVYlnUagOcB+Dj/LOUctgqy5uyWnc+qOQxsvXmcce+31RwGRjOPt7WBH6Bf7KbBsqz3gPF/h4MbBcuydlmWVQ3+bQC4Aew8NhWWZdUty5oO/k0A/BzYuL4DoGpZ1rODTd8A1oN3K+CXAHzBtu0FIPMctgSy5uxWnc+qORx8vqXmcc693zZzGBjdPN725YIty/oRMFnZLgAnwWRl9uaOisGyrKcDuBvAfQA6wccPAfgjMHUEBWACuAXAmzZbUWNZ1jkAPgNWY1oHcA+AX7dt+wnLsq4CG3MFkcTsqc0aK0fQJ/jXbdv+X8HfqeewCWP7MwAvA3AKgCaABdu2n541ZzdzPqvGCxaITMxh27avtyzrSmzSPE4Z60uQce83cw6nzYXgu9gcDj4byTze9gZ+jDHGGGMMNbY1RTPGGGOMMUY6xgZ+jDHGGGOHYmzgxxhjjDF2KMYGfowxxhhjh2Js4McYY4wxdijGBn6MMcYYY4dibODHGGOMMXYoxgZ+jDHGGGOH4v8C1pdFLIrpSuMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14aFKBKy8zJe"
      },
      "source": [
        "The result from CNN model is very good, with a MSE of 0.3%. The plot of original VS predicted is at above."
      ]
    }
  ]
}